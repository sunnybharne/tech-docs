{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About Me","text":"<p>Loading GitHub README...</p>"},{"location":"#my-pinned-projects","title":"My Pinned Projects \ud83d\ude80","text":"nvim config <p>My personal Neovim configuration.</p> nvim-gh-actions-snippets <p>Neovim snippets for GitHub Actions.</p> Backstage Dev Portal <p>Backstage developer portal for my projects.</p> Papliba Website <p>Papliba website.</p>"},{"location":"blog/","title":"Welcome to My Blog","text":""},{"location":"blog/#about-this-blog","title":"About This Blog","text":"<p>Welcome to my personal blog, where I share insights, tutorials, and thoughts on various topics, including technology, programming, productivity, and more. Whether you're a developer, tech enthusiast, or just curious, there's something here for you!</p>"},{"location":"blog/#stay-connected","title":"Stay Connected","text":"<p>\ud83d\ude80 Thanks for stopping by! Keep exploring and happy reading! \ud83d\ude80</p>"},{"location":"blog/azure-landing-zone-naming/","title":"Creating an ADR for Naming Azure Landing Zones &amp; Resources in a Large Enterprise \ud83d\ude80","text":""},{"location":"blog/azure-landing-zone-naming/#why-naming-matters-in-large-enterprises","title":"Why Naming Matters in Large Enterprises","text":"<p>Naming conventions play a crucial role in managing Azure resources efficiently. In large enterprises, consistent naming helps with: - Governance &amp; Compliance \u2013 Easier tracking and auditing. - Automation &amp; Infrastructure as Code \u2013 Simplifies scripts and deployments. - Cost Management &amp; Billing \u2013 Enables accurate chargeback and budgeting.</p>"},{"location":"blog/azure-landing-zone-naming/#what-is-an-adr-architecture-decision-record","title":"What is an ADR (Architecture Decision Record)?","text":"<p>An Architecture Decision Record (ADR) documents the reasoning behind architectural decisions. It provides context, captures alternatives, and ensures future teams understand why choices were made.</p>"},{"location":"blog/azure-landing-zone-naming/#adr-structure-following-michael-nygards-template","title":"ADR Structure (Following Michael Nygard\u2019s Template)","text":"<pre><code># ADR 001: Naming Conventions for Azure Landing Zones &amp; Resources\n\n## Status\nAccepted / Proposed / Deprecated\n\n## Context\nOur enterprise has multiple teams deploying Azure resources. We need a clear naming convention to:\n- Ensure consistency across subscriptions.\n- Simplify automation &amp; monitoring.\n- Align with Microsoft\u2019s best practices.\n\n## Decision\nWe will use the following naming convention:\n\n**Landing Zones:** `lz-&lt;environment&gt;-&lt;business_unit&gt;`  \n**Resources:** `&lt;resource_type&gt;-&lt;business_unit&gt;-&lt;environment&gt;-&lt;region&gt;`  \n\n**Examples:**\n- `lz-prod-finance`\n- `vm-finance-prod-eastus`\n- `aks-marketing-dev-westeurope`\n\n## Consequences\n\u2705 **Pros**\n- Standardized and scalable.\n- Easier to manage across teams.\n\n\u274c **Cons**\n- Requires upfront documentation &amp; training.\n</code></pre>"},{"location":"blog/azure-landing-zone-naming/#azure-landing-zone-naming-best-practices","title":"Azure Landing Zone Naming Best Practices","text":"<p>To align with Microsoft\u2019s Cloud Adoption Framework (CAF), follow these best practices: - Use clear prefixes (<code>lz-</code>, <code>vm-</code>, <code>aks-</code>) for readability. - Include environment (<code>prod</code>, <code>dev</code>, <code>staging</code>) and business unit. - Keep names short &amp; meaningful to avoid hitting Azure's character limits.</p> <p>\ud83d\udccc Reference: Microsoft Naming Guidelines</p>"},{"location":"blog/azure-landing-zone-naming/#implementing-this-in-an-enterprise","title":"Implementing This in an Enterprise","text":"<ul> <li>Enforce Naming with Azure Policy \u2013 Automate compliance checks.</li> <li>Integrate with CI/CD Pipelines \u2013 Validate naming conventions in PRs.</li> <li>Centralize ADRs in a GitHub Repo or Azure DevOps Wiki \u2013 Ensure visibility across teams.</li> </ul>"},{"location":"blog/azure-landing-zone-naming/#final-thoughts-adrs-as-a-living-document","title":"Final Thoughts: ADRs as a Living Document","text":"<ul> <li>Keep ADRs focused and concise.</li> <li>Update ADRs as architecture evolves.</li> <li>Combine ADRs with C4 Diagrams to visualize resource structures.</li> </ul>"},{"location":"blog/azure-lz-environments/","title":"ADR: Defining Environments for Azure Landing Zones \ud83c\udf0d","text":""},{"location":"blog/azure-lz-environments/#why-define-environments-in-landing-zones","title":"Why Define Environments in Landing Zones?","text":"<p>Defining environments in Azure Landing Zones is crucial for scalability, security, and governance. A well-structured environment setup ensures: - Clear separation between workloads (Development, Testing, Production). - Compliance with security policies at different stages. - Streamlined cost allocation &amp; monitoring.</p>"},{"location":"blog/azure-lz-environments/#what-is-an-adr-architecture-decision-record","title":"What is an ADR (Architecture Decision Record)?","text":"<p>An Architecture Decision Record (ADR) captures key architectural decisions, providing transparency on why choices were made.</p>"},{"location":"blog/azure-lz-environments/#adr-structure-following-michael-nygards-template","title":"ADR Structure (Following Michael Nygard\u2019s Template)","text":"<pre><code># ADR 002: Defining Environments for Azure Landing Zones\n\n## Status\nAccepted / Proposed / Deprecated\n\n## Context\nOur enterprise requires a clear definition of environments within Azure Landing Zones to:\n- Ensure workload isolation for different stages of development.\n- Maintain compliance, security, and cost tracking.\n- Standardize deployment pipelines and governance.\n\n## Decision\nWe will define the following standard environments:\n\n| Environment | Purpose |\n|------------|------------------------------------------------|\n| **Sandbox**  | Personal experimentation; no governance enforcement. |\n| **Development (Dev)** | Active feature development; minimal restrictions. |\n| **Testing (Test)** | Pre-production validation; security policies applied. |\n| **Staging (Stage)** | Near-production environment for final validation. |\n| **Production (Prod)** | Live environment; highest security &amp; compliance. |\n\nNaming convention for landing zones:\n**`lz-&lt;environment&gt;-&lt;business_unit&gt;`**\n\nExamples:\n- `lz-dev-finance`\n- `lz-stage-marketing`\n- `lz-prod-sales`\n\n## Consequences\n\u2705 **Pros**\n- Ensures **consistent environment separation**.\n- Reduces security risks by applying **tiered policies**.\n- Simplifies **CI/CD workflows** across teams.\n\n\u274c **Cons**\n- Requires **documentation &amp; team training**.\n- Some overhead in maintaining **multiple environments**.\n</code></pre>"},{"location":"blog/azure-lz-environments/#best-practices-for-environment-structuring","title":"Best Practices for Environment Structuring","text":"<ul> <li>Align with Microsoft\u2019s Enterprise-Scale Landing Zone framework.</li> <li>Apply Azure Policy to enforce security compliance per environment.</li> <li>Use Management Groups for cost tracking and access control.</li> </ul> <p>\ud83d\udccc Reference: Microsoft Cloud Adoption Framework (CAF)</p>"},{"location":"blog/azure-lz-environments/#implementing-this-in-an-enterprise","title":"Implementing This in an Enterprise","text":"<ul> <li>Define subscription &amp; resource group structure for each environment.</li> <li>Automate environment setup using Terraform / Bicep.</li> <li>Store ADRs in a GitHub repo / Azure DevOps Wiki for visibility.</li> </ul>"},{"location":"blog/azure-lz-environments/#adrs-as-a-living-document","title":"ADRs as a Living Document","text":"<ul> <li>ADRs should evolve with business needs.</li> <li>Keep documentation concise &amp; relevant.</li> <li>Integrate ADRs with C4 Diagrams for architecture visualization.</li> </ul>"},{"location":"blog/my-dev-setup/","title":"Step-by-Step Guide to Using Nix on Asahi Linux (Arch Linux ARM) \ud83d\ude80","text":""},{"location":"blog/my-dev-setup/#introduction","title":"Introduction","text":"<p>Nix is a powerful package manager that ensures reproducibility, consistency, and ease of management. This guide will walk you through setting up Nix from scratch on Asahi Linux (Arch Linux ARM), using Home Manager with Flakes for optimal configuration management.</p>"},{"location":"blog/my-dev-setup/#1-setting-up-nix","title":"1. Setting Up Nix","text":""},{"location":"blog/my-dev-setup/#installing-nix","title":"Installing Nix","text":"<p>To install Nix and enable Flakes, run:</p> <pre><code>sh &lt;(curl -L https://nixos.org/nix/install)\n</code></pre>"},{"location":"blog/my-dev-setup/#enabling-flakes","title":"Enabling Flakes","text":"<pre><code>echo 'experimental-features = nix-command flakes' | sudo tee -a /etc/nix/nix.conf\n</code></pre>"},{"location":"blog/my-dev-setup/#loading-nix-environment","title":"Loading Nix Environment","text":"<pre><code>. ~/.nix-profile/etc/profile.d/nix.sh\n</code></pre> <p>If using <code>zsh</code>, add this to your <code>.zshrc</code>:</p> <pre><code>source ~/.nix-profile/etc/profile.d/nix.sh\n</code></pre>"},{"location":"blog/my-dev-setup/#2-setting-up-home-manager-with-flakes","title":"2. Setting Up Home Manager with Flakes","text":""},{"location":"blog/my-dev-setup/#installing-home-manager","title":"Installing Home Manager","text":"<pre><code>nix run nixpkgs#home-manager -- init\n</code></pre>"},{"location":"blog/my-dev-setup/#configuring-home-manager","title":"Configuring Home Manager","text":"<p>Create <code>~/.config/home-manager/flake.nix</code>:</p> <pre><code>{\n  description = \"Home Manager Configuration\";\n\n  inputs = {\n    nixpkgs.url = \"github:NixOS/nixpkgs/nixos-unstable\";\n    home-manager.url = \"github:nix-community/home-manager\";\n    home-manager.inputs.nixpkgs.follows = \"nixpkgs\";\n  };\n\n  outputs = { nixpkgs, home-manager, ... }@inputs: {\n    homeConfigurations.\"your-username\" = home-manager.lib.homeManagerConfiguration {\n      pkgs = import nixpkgs { system = \"aarch64-linux\"; };\n      modules = [\n        {\n          home.username = \"your-username\";\n          home.homeDirectory = \"/home/your-username\";\n\n          home.packages = [ pkgs.git pkgs.neovim pkgs.zsh ];\n\n          programs.zsh.enable = true;\n          programs.git.enable = true;\n\n          home.stateVersion = \"23.11\";\n        }\n      ];\n    };\n  };\n}\n</code></pre>"},{"location":"blog/my-dev-setup/#applying-home-manager-configuration","title":"Applying Home Manager Configuration","text":"<pre><code>nix run .#home-manager switch\n</code></pre>"},{"location":"blog/my-dev-setup/#3-using-ad-hoc-shell-environments","title":"3. Using Ad-Hoc Shell Environments","text":"<p>To temporarily use a package:</p> <pre><code>nix shell nixpkgs#git\n</code></pre>"},{"location":"blog/my-dev-setup/#4-creating-a-reproducible-script","title":"4. Creating a Reproducible Script","text":"<p>To ensure scripts always have the required dependencies:</p> <pre><code>#!/usr/bin/env nix-shell\n#!nix-shell -i bash -p curl jq\ncurl --version\njq --version\n</code></pre>"},{"location":"blog/my-dev-setup/#5-setting-up-a-declarative-shell-environment","title":"5. Setting Up a Declarative Shell Environment","text":"<p>Create <code>shell.nix</code>:</p> <pre><code>{ pkgs ? import &lt;nixpkgs&gt; {} }:\npkgs.mkShell {\n  buildInputs = [ pkgs.git pkgs.curl ];\n}\n</code></pre> <p>Run <code>nix-shell</code> in this directory to load the environment.</p>"},{"location":"blog/my-dev-setup/#6-pinning-nixpkgs-for-consistency-with-flakes","title":"6. Pinning Nixpkgs for Consistency with Flakes","text":"<p>Modify your <code>flake.nix</code> to pin a version:</p> <pre><code>{\n  inputs.nixpkgs.url = \"github:NixOS/nixpkgs/&lt;commit-hash&gt;\";\n}\n</code></pre>"},{"location":"blog/my-dev-setup/#7-understanding-the-nix-language","title":"7. Understanding the Nix Language","text":""},{"location":"blog/my-dev-setup/#variables","title":"Variables:","text":"<pre><code>myVar = \"Hello, Nix!\";\n</code></pre>"},{"location":"blog/my-dev-setup/#lists","title":"Lists:","text":"<pre><code>myList = [ \"nix\" \"is\" \"awesome\" ];\n</code></pre>"},{"location":"blog/my-dev-setup/#functions","title":"Functions:","text":"<pre><code>add = x: y: x + y;\nresult = add 2 3;  # result = 5\n</code></pre>"},{"location":"blog/my-dev-setup/#8-creating-your-first-nix-package","title":"8. Creating Your First Nix Package","text":""},{"location":"blog/my-dev-setup/#writing-defaultnix","title":"Writing <code>default.nix</code>","text":"<pre><code>derivation {\n  name = \"hello-nix\";\n  builder = \"/bin/sh\";\n  args = [ \"-c\" \"echo Hello, Nix! &gt; $out\" ];\n}\n</code></pre>"},{"location":"blog/my-dev-setup/#building-the-package","title":"Building the Package","text":"<pre><code>nix-build\n</code></pre>"},{"location":"blog/my-dev-setup/#conclusion","title":"Conclusion","text":"<p>Nix simplifies package management, scripting, and system configuration. With Home Manager and Flakes, personal configurations become declarative and reproducible.</p> <p>In future posts, we\u2019ll explore advanced topics like overlays, Flakes customization, and optimizing Nix usage on Asahi Linux (Arch Linux ARM).</p> <p>Stay tuned and happy hacking with Nix! \ud83d\ude80</p>"},{"location":"blog/y-statement/","title":"Understanding the Y-Statement for Architectural Decision Records (ADR)","text":""},{"location":"blog/y-statement/#introduction","title":"Introduction","text":"<p>Architectural decisions play a crucial role in the development of software systems. They impact scalability, maintainability, and overall system quality. However, documenting these decisions can be challenging, especially when balancing depth with brevity. The Y-Statement provides a structured yet lightweight approach to capturing Architectural Decision Records (ADRs) in a concise and effective manner.</p>"},{"location":"blog/y-statement/#what-is-a-y-statement","title":"What is a Y-Statement?","text":"<p>The Y-Statement is a structured template designed to document architectural decisions by capturing the context, concern, decision, desired quality, and trade-offs. It ensures that decisions are documented in a way that is easy to understand and trace.</p>"},{"location":"blog/y-statement/#short-form-of-the-y-statement","title":"Short Form of the Y-Statement","text":"<pre><code>In the context of &lt;use case/user story&gt;, facing &lt;concern&gt;, we decided for &lt;option&gt; to achieve &lt;quality&gt;, accepting &lt;downside&gt;.\n</code></pre>"},{"location":"blog/y-statement/#long-form-of-the-y-statement","title":"Long Form of the Y-Statement","text":"<pre><code>In the context of &lt;use case/user story&gt;, facing &lt;concern&gt;, we decided for &lt;option&gt; and neglected &lt;other options&gt;, \nto achieve &lt;system qualities/desired consequences&gt;, accepting &lt;downside/undesired consequences&gt;, \nbecause &lt;additional rationale&gt;.\n</code></pre>"},{"location":"blog/y-statement/#why-use-y-statements-for-adrs","title":"Why Use Y-Statements for ADRs?","text":""},{"location":"blog/y-statement/#1-clarity-and-brevity","title":"1. Clarity and Brevity","text":"<p>The Y-Statement provides a structured way to communicate complex architectural decisions without unnecessary details. It ensures that key aspects of the decision are immediately clear to stakeholders.</p>"},{"location":"blog/y-statement/#2-tradeoff-analysis","title":"2. Tradeoff Analysis","text":"<p>Every architectural decision involves trade-offs. The Y-Statement explicitly highlights both the benefits and drawbacks of a decision, making it easier to evaluate alternatives in the future.</p>"},{"location":"blog/y-statement/#3-context-awareness","title":"3. Context Awareness","text":"<p>Many decisions are made in response to specific challenges. The Y-Statement ties each decision to its relevant context, ensuring that future reviewers understand why a choice was made.</p>"},{"location":"blog/y-statement/#4-lightweight-documentation","title":"4. Lightweight Documentation","text":"<p>Unlike verbose ADR templates, the Y-Statement offers a concise yet effective format that can be quickly created, reviewed, and maintained.</p>"},{"location":"blog/y-statement/#example-y-statements","title":"Example Y-Statements","text":"<p>Here are some practical examples to illustrate how Y-Statements can be applied to real-world architectural decisions:</p>"},{"location":"blog/y-statement/#example-1-api-architecture-choice","title":"Example 1: API Architecture Choice","text":"<p>Short Form:</p> <pre><code>In the context of high-traffic API services, facing scalability concerns, we decided for a microservices architecture \nto achieve better load distribution, accepting the complexity of distributed systems.\n</code></pre> <p>Long Form:</p> <pre><code>In the context of high-traffic API services, facing scalability concerns, we decided for a microservices architecture \nand neglected a monolithic approach, to achieve better load distribution and fault isolation, accepting the complexity \nof distributed systems, because the business requires independent scaling of services.\n</code></pre>"},{"location":"blog/y-statement/#example-2-database-selection","title":"Example 2: Database Selection","text":"<p>Short Form:</p> <pre><code>In the context of an analytics-heavy application, facing performance bottlenecks, we decided for a NoSQL database \nto achieve faster read performance, accepting the lack of ACID transactions.\n</code></pre> <p>Long Form:</p> <pre><code>In the context of an analytics-heavy application, facing performance bottlenecks, we decided for a NoSQL database \nand neglected a traditional relational database, to achieve faster read performance and horizontal scalability, \naccepting the lack of ACID transactions, because analytics queries require high-speed access to denormalized data.\n</code></pre>"},{"location":"blog/y-statement/#y-statements-vs-other-adr-formats","title":"Y-Statements vs. Other ADR Formats","text":"<p>There are multiple ADR formats available, each with its strengths and weaknesses. Here\u2019s how Y-Statements compare to other common ADR templates:</p> ADR Format Structure Strengths Weaknesses Y-Statement Context, Concern, Decision, Quality, Trade-offs Concise, clear tradeoffs, easy to maintain May not capture in-depth details MADR Full and minimal templates Well-structured, Markdown-friendly Slightly verbose Nygard ADR Title, Status, Context, Decision, Consequences Widely adopted, focuses on impact Can be too generic"},{"location":"blog/y-statement/#how-to-adopt-y-statements-in-your-team","title":"How to Adopt Y-Statements in Your Team","text":"<ol> <li>Standardize Documentation: Encourage your team to adopt the Y-Statement format for recording key architectural decisions.</li> <li>Integrate with ADR Tools: Use markdown files in repositories to maintain a history of decisions.</li> <li>Review Periodically: Regularly review and update ADRs to reflect evolving architectural understanding.</li> <li>Use as a Communication Tool: Share Y-Statements in design discussions to ensure alignment.</li> </ol>"},{"location":"blog/y-statement/#conclusion","title":"Conclusion","text":"<p>The Y-Statement is a powerful yet simple tool for documenting architectural decisions. Its structured approach ensures clarity, tradeoff awareness, and maintainability, making it an excellent choice for teams looking to implement lightweight ADRs. By adopting Y-Statements, organizations can improve their decision-making process while keeping documentation manageable.</p> <p>What are your thoughts on Y-Statements? Have you used them before? Share your experience in the comments!</p>"},{"location":"decision/adr_platform_landing_zones/","title":"ADR 005: Defining Platform Landing Zones","text":""},{"location":"decision/adr_platform_landing_zones/#status","title":"Status","text":"<p>Accepted / Proposed / Deprecated</p>"},{"location":"decision/adr_platform_landing_zones/#context","title":"Context","text":"<p>Platform Landing Zones serve as the foundational layer for governance, security, and operational controls. These environments host critical services such as security monitoring, logging, and compliance enforcement, ensuring a well-managed cloud ecosystem.</p>"},{"location":"decision/adr_platform_landing_zones/#decision","title":"Decision","text":"<p>We will define the following environments for Platform Landing Zones:</p> Environment Type Purpose Example Naming Development (Dev) Platform service development &amp; configuration. <code>lz-platform-dev</code> Testing (Test) Pre-production validation of platform controls. <code>lz-platform-test</code> Pre-Production (PreProd) Final validation before production deployment. <code>lz-platform-preprod</code> Production (Prod) Live environment enforcing governance and security. <code>lz-platform-prod</code>"},{"location":"decision/adr_platform_landing_zones/#implementation","title":"Implementation","text":"<ol> <li>Azure Policy &amp; Security Controls:</li> <li>Enforce governance through Azure Policy and Management Groups.</li> <li>Apply security baselines to protect platform resources.</li> <li>Integration with ServiceNow CMDB:</li> <li>All platform services are registered for tracking.</li> <li>Automated updates for configuration changes.</li> <li>Monitoring &amp; Compliance:</li> <li>Centralized logging and monitoring.</li> <li>Continuous compliance checks against regulatory standards.</li> <li>Access &amp; Role-Based Controls (RBAC):</li> <li>Restricted access to platform administrators.</li> <li>Business units consume platform services via defined interfaces.</li> </ol>"},{"location":"decision/adr_platform_landing_zones/#consequences","title":"Consequences","text":"<p>\u2705 Pros - Provides a secure and controlled cloud foundation. - Ensures consistency in governance across all landing zones. - Enables centralized compliance tracking and enforcement.</p> <p>\u274c Cons - Requires continuous monitoring and maintenance. - Needs coordination between security and platform teams.</p>"},{"location":"decision/adr_platform_landing_zones/#adrs-as-a-living-document","title":"ADRs as a Living Document","text":"<ul> <li>Keep ADRs updated as platform services evolve.</li> <li>Integrate ADRs with C4 Diagrams for architecture visualization.</li> </ul>"},{"location":"decision/adr_shared_landing_zones/","title":"ADR 004: Defining Shared Landing Zones","text":""},{"location":"decision/adr_shared_landing_zones/#status","title":"Status","text":"<p>Accepted / Proposed / Deprecated</p>"},{"location":"decision/adr_shared_landing_zones/#context","title":"Context","text":"<p>Shared Landing Zones provide a centralized space for hosting shared services such as networking, identity, and monitoring. These environments serve multiple business units, ensuring consistency, security, and cost efficiency.</p>"},{"location":"decision/adr_shared_landing_zones/#decision","title":"Decision","text":"<p>We will define the following environments for Shared Landing Zones:</p> Environment Type Purpose Example Naming Development (Dev) Shared service development &amp; configuration. <code>lz-shared-dev</code> Testing (Test) Pre-production validation; security policies enforced. <code>lz-shared-test</code> Pre-Production (PreProd) Near-production environment for final validation. <code>lz-shared-preprod</code> Production (Prod) Hosting shared services for all business units. <code>lz-shared-prod</code>"},{"location":"decision/adr_shared_landing_zones/#implementation","title":"Implementation","text":"<ol> <li>Azure Policy Enforcement: Naming rules and security policies enforced via Azure Policy.</li> <li>Integration with ServiceNow CMDB:</li> <li>Each shared landing zone is registered in CMDB.</li> <li>Automated tracking of shared resource lifecycle in ServiceNow.</li> <li>Role-Based Access Control (RBAC):</li> <li>Restricted access with least privilege.</li> <li>Business units consume shared services via defined interfaces.</li> <li>Management Groups &amp; Tagging: Standardized grouping for governance and cost management.</li> </ol>"},{"location":"decision/adr_shared_landing_zones/#consequences","title":"Consequences","text":"<p>\u2705 Pros - Reduces duplication of shared resources across business units. - Improves security and governance consistency. - Enables cost optimization by consolidating services.</p> <p>\u274c Cons - Requires strict governance to prevent unauthorized changes. - Needs effective service level agreements (SLAs) between teams.</p>"},{"location":"decision/adr_shared_landing_zones/#adrs-as-a-living-document","title":"ADRs as a Living Document","text":"<ul> <li>Keep ADRs updated as shared services evolve.</li> <li>Integrate ADRs with C4 Diagrams for architecture visualization.</li> </ul>"},{"location":"decision/adr_standard_landing_zones/","title":"ADR 003: Defining Standard Landing Zones","text":""},{"location":"decision/adr_standard_landing_zones/#status","title":"Status","text":"<p>Accepted / Proposed / Deprecated</p>"},{"location":"decision/adr_standard_landing_zones/#context","title":"Context","text":"<p>Standard Landing Zones are dedicated to business unit-specific applications. These environments are designed to host workloads with appropriate security, compliance, and governance policies while allowing teams the flexibility to manage their own resources.</p>"},{"location":"decision/adr_standard_landing_zones/#decision","title":"Decision","text":"<p>We will define the following environments for Standard Landing Zones:</p> Environment Type Purpose Example Naming Development (Dev) Active feature development; limited security policies. <code>lz-dev-finance</code> Testing (Test) Pre-production validation; security policies enforced. <code>lz-test-marketing</code> Pre-Production (PreProd) Near-production environment for final validation. <code>lz-preprod-sales</code> Production (Prod) Live production workloads; highest security &amp; compliance. <code>lz-prod-hr</code>"},{"location":"decision/adr_standard_landing_zones/#implementation","title":"Implementation","text":"<ol> <li>Azure Policy Enforcement: Naming rules and security policies enforced via Azure Policy.</li> <li>Integration with ServiceNow CMDB:</li> <li>Each standard landing zone is registered in CMDB.</li> <li>Automated tracking of environment lifecycle in ServiceNow.</li> <li>Management Groups &amp; Tagging: Standardized grouping for governance and cost management.</li> </ol>"},{"location":"decision/adr_standard_landing_zones/#consequences","title":"Consequences","text":"<p>\u2705 Pros - Ensures business unit autonomy while maintaining governance. - Provides clear workload isolation for application teams. - Allows easy cost tracking and billing segregation.</p> <p>\u274c Cons - Requires governance policies to prevent security misconfigurations. - Needs periodic auditing to ensure compliance.</p>"},{"location":"decision/adr_standard_landing_zones/#adrs-as-a-living-document","title":"ADRs as a Living Document","text":"<ul> <li>Keep ADRs updated as requirements evolve.</li> <li>Integrate ADRs with C4 Diagrams for architecture visualization.</li> </ul>"},{"location":"tech-notes/","title":"\ud83d\ude80 Welcome to My Tech Notes!","text":"<p>Hey there! \ud83d\udc4b This is my personal brain dump for all things tech. I\u2019m constantly learning, breaking things (on purpose, mostly), and jotting down notes along the way. Instead of letting them sit in a dusty corner of my drive, I\u2019m sharing them here!  </p>"},{"location":"tech-notes/#whats-inside","title":"\ud83d\udcc2 What's Inside?","text":"<ul> <li>A bunch of tech notes organized into folders.  </li> <li>They\u2019re not perfect (and probably never will be).  </li> <li>Just raw, honest documentation of what I\u2019ve learned.  </li> </ul>"},{"location":"tech-notes/#want-to-add-your-own-notes","title":"\ud83d\udca1 Want to Add Your Own Notes?","text":"<p>Awesome! The more, the merrier! \ud83c\udf89 Just follow these simple steps:  </p> <ol> <li>Create a new folder with the topic name.  </li> <li>Drop your notes inside (Markdown preferred, but you do you).  </li> <li>Submit a pull request\u2014I\u2019ll check it out and merge it in!  </li> </ol> <p>No formalities, no judgment. Just learning and sharing.  </p> <p>Enjoy! \ud83d\ude80  </p>"},{"location":"tech-notes/adr/","title":"\ud83d\udcd6 Architecture Decision Records (ADR)","text":"<p>Welcome to the ADR repository, where architectural decisions are documented, organized, and structured to align with best practices, governance, and business needs.</p>"},{"location":"tech-notes/adr/#well-architected-framework","title":"\ud83c\udfd7 Well-Architected Framework","text":"<p>The Well-Architected Framework provides a structured approach to designing secure, high-performing, resilient, and efficient cloud infrastructure while balancing cost and performance.</p>"},{"location":"tech-notes/adr/#five-pillars-of-the-framework","title":"\ud83d\udd39 Five Pillars of the Framework:","text":"<ol> <li>Reliability - Designing for fault tolerance and resilience.</li> <li>Security - Protecting data, applications, and infrastructure.</li> <li>Cost Optimization - Balancing performance with budget constraints.</li> <li>Operational Excellence - Enabling efficient processes and automation.</li> <li>Performance Efficiency - Optimizing resources and architecture.</li> </ol> <p>Key Principle: Every design decision must balance across these five pillars.</p>"},{"location":"tech-notes/adr/#layers-of-decision-making","title":"\ud83d\udccc Layers of Decision-Making","text":""},{"location":"tech-notes/adr/#pillars-design-principles-specific-goals","title":"\ud83c\udfaf Pillars \u2192 Design Principles \u2192 Specific Goals","text":"<ul> <li>Example: Design for Resilience</li> <li>Define the workload's tolerance for downtime.</li> <li>Define the workload's tolerance for data loss.</li> <li>Define the workload's tolerance for performance degradation.</li> </ul>"},{"location":"tech-notes/adr/#checklists-for-architecture-decision-making","title":"\u2705 Checklists for Architecture Decision-Making","text":"<ul> <li>Identify critical user and system flows in your workload.</li> <li>Perform Failure Mode Analysis (FMA) to identify risks.</li> <li>Define reliability and recovery targets (RTO, RPO).</li> <li>Map decisions to relevant cloud design patterns.</li> </ul>"},{"location":"tech-notes/adr/#architecture-documentation-checklist","title":"\ud83d\udcdd Architecture Documentation Checklist","text":"<p>A well-documented architecture should include the following:</p> <p>1\ufe0f\u20e3 Workload Architecture Design Specification    - A detailed document that justifies design choices with diagrams.    - Must address functional and non-functional requirements.</p> <p>2\ufe0f\u20e3 Workload Architectural Design Diagram    - Visual representation of the architecture.</p> <p>3\ufe0f\u20e3 Functional Specification    - What &amp; Why of the system (not how).    - Defines the problem statement, expected solution, and impact.    - Topics include scope, user flows, accessibility, compliance, performance, privacy, and security.</p> <p>4\ufe0f\u20e3 Technical Specification    - How the system or feature is built.    - Covers technology choices, API contracts, rollout plans, monitoring strategies, and alternative designs.</p> <p>5\ufe0f\u20e3 Disaster Recovery Plan    - Ensures system recovery within RTO (Recovery Time Objective) and RPO (Recovery Point Objective).    - Includes failover, backup, restore, and data replication strategies.</p> <p>6\ufe0f\u20e3 Security &amp; Compliance Documentation    - Covers policies, risk assessments, and controls.</p> <p>7\ufe0f\u20e3 Consistency in Documentation    - Use templates and include the following:      - State: Draft, In Review, Approved.      - Work Item Link: Reference to the backlog item.      - Key Individuals: Decision-makers (e.g., Architect, Product Owner).      - Cross-Links: Related specifications for reference.</p>"},{"location":"tech-notes/adr/#design-diagrams","title":"\ud83d\udcca Design Diagrams","text":"<p>Different types of diagrams used in architecture decisions:</p> <ul> <li>System Diagram (High-Level Architecture)</li> <li>Block Diagram (Component-Based)</li> <li>Deployment Diagram</li> <li>Dataflow Diagram</li> <li>Sequence Diagram (Interaction Flows)</li> <li>User Flow Diagram</li> <li>Entity-Relationship Diagram (ERD)</li> <li>Network Diagram</li> <li>State Diagram</li> <li>Flowcharts</li> </ul>"},{"location":"tech-notes/adr/#architecture-decision-records-adr-guidelines","title":"\ud83d\udd16 Architecture Decision Records (ADR) Guidelines","text":"<p>To maintain consistency across ADRs:</p> <ul> <li>Use a standardized template for every decision.</li> <li>Include the following:</li> <li>Problem Statement &amp; Context</li> <li>Options Considered</li> <li>Decision Outcome<ul> <li>Trade-offs made.</li> <li>Confidence level in the decision.</li> </ul> </li> <li>Break large decisions into multiple records if they span multiple phases (short-term, mid-term, long-term).</li> <li>Be transparent about risks and trade-offs.</li> <li>Keep it concise \u2013 ADRs are not design guides but should be self-explanatory.</li> </ul> <p>\ud83d\udccc Storage: ADRs should be kept in the same repository as the workload's documentation (e.g., GitHub, Confluence).</p>"},{"location":"tech-notes/adr/#collaboration-workload-team-coordination","title":"\ud83e\udd1d Collaboration &amp; Workload Team Coordination","text":"<ul> <li>Provide clarity on architecture decisions.</li> <li>Review implementation checkpoints to track progress.</li> <li>Communicate with stakeholders regularly.</li> <li>Recommend appropriate environments (e.g., PreProd).</li> <li>Use Proof of Concept (PoC) before finalizing decisions.</li> </ul>"},{"location":"tech-notes/adr/#workloads-components","title":"Workloads &amp; Components","text":"<ul> <li>A single application architecture can contain multiple workloads.</li> <li>Every workload undergoes Component &amp; Topology Design.</li> <li>Azure Architects are responsible for component and topology design.</li> </ul>"},{"location":"tech-notes/adr/#decision-making-framework","title":"\ud83d\udccc Decision-Making Framework","text":"<ul> <li>Log every architectural decision.</li> <li>Evaluate decisions based on:</li> <li>Limitations, constraints, trade-offs, efforts, reversibility, and risks.</li> <li>Use decision trees and feature matrices as guidance (but rely on expert judgment).</li> <li>Justify every decision in documentation.</li> </ul>"},{"location":"tech-notes/adr/#cloud-design-patterns","title":"\ud83c\udf10 Cloud Design Patterns","text":"<ul> <li>Leverage existing Cloud Design Patterns for scalability, resilience, and efficiency.</li> <li>Avoid design cliffs and anticipate future growth.</li> </ul>"},{"location":"tech-notes/adr/#forward-thinking-architecture","title":"\ud83d\ude80 Forward-Thinking Architecture","text":"<ul> <li>Change is expensive after implementation\u2014design with flexibility.</li> <li>Consider:</li> <li>Future scaling needs</li> <li>Compliance changes</li> <li>Multi-region deployments</li> </ul>"},{"location":"tech-notes/adr/#design-for-supportability","title":"\ud83d\udee0 Design for Supportability","text":"<ul> <li>Cloud Provider Support</li> <li>Operational Visibility</li> <li>Customer Support Capabilities</li> </ul>"},{"location":"tech-notes/adr/#togaf-the-open-group-architectural-framework","title":"\ud83c\udfdb TOGAF (The Open Group Architectural Framework)","text":"<p>The Architect\u2019s Role: - Design, deliver, and plan while translating functional &amp; non-functional requirements into cloud design patterns. - Ensure the design is:   - Operationally sound (observability, supportability, disaster recovery).   - Cost-effective &amp; scalable.   - Aligned with business, financial, compliance, and organizational constraints.</p>"},{"location":"tech-notes/adr/#key-deliverables","title":"\ud83d\udccc Key Deliverables","text":"<ul> <li>\ud83d\udcdc Architecture Decision Records (ADR)</li> <li>\ud83d\udcc2 Workload Design Specifications</li> <li>\ud83d\udee0 Technical &amp; Functional Specifications</li> <li>\ud83d\udda5 Design Diagrams</li> <li>\ud83d\udd04 Disaster Recovery &amp; Compliance Documentation</li> <li>\ud83d\udcca Monitoring &amp; Alerting Strategies</li> </ul> <p>\ud83d\ude80 Stay structured, be transparent, and build for the future!</p>"},{"location":"tech-notes/backstage/","title":"Backstage","text":""},{"location":"tech-notes/backstage/#imp-points","title":"Imp points","text":"<ul> <li>Build developer portals</li> <li>Backstage components<ul> <li>Core (Base software)</li> <li>App (Twiking base software according to the company needs)</li> <li>PLugins (Self explainatory)<ul> <li>Standalone plugins(Static page)</li> <li>Service backed plugins(UI with backend database)</li> <li>Third party backed plugins (UI with backend outside the org ex circleCI)</li> </ul> </li> </ul> </li> </ul>"},{"location":"tech-notes/backstage/#software-catalog","title":"Software catalog","text":"<ul> <li>Template to software components</li> <li>Tech docs</li> </ul>"},{"location":"tech-notes/github-actions/","title":"Github Actions","text":""},{"location":"tech-notes/github-actions/#git-basics","title":"Git Basics","text":"<pre><code># Config\ngit config user.name # Get the username\ngit config user.email # Get the email\ngit config --global user.name \"Sunny Bharne\" # Set username \ngit config --global user.email \"example@email\" # Set github email\n\n# Git imp commands\ngit init # Initialise the git repo\ngit status\ngit add file1 file2\ngit commit -m \"commit message\"\ngit push\ngit log --all\ngit rm --cached File.name # Remove unstaged files\ngit restore --staged File.name # Remove unstaged files\ngit checkout -b branchName # Create and move to a new branch\ngit branch branchName # Create a new branch\ngit branch # List all branches\ngit branch -d branchName # Delete branch\ngit checkout commitHash # Move to a commit\ngit merge BranchName # move to main and then merge the code from Branch\ngit remote add origin https:/github.git # add remote repo\ngit clone https https:/github.git\ngit pull # get changes from remote (Can have conflicts)\n\n# Make chagnes to the last commit\ngit revert \"commitHash\" # Create a new commit with the changes , without deleting the last commit\ngit reset --soft \"commitHash\" # Remove the last commit and keep the changes\ngit reset --hard \"commitHash\" # Remove the last commit and changes\n\n### Stash\ngit stash # Stash the changes\ngit stash list # List all the stashes\ngit stash apply stash@{0} # Apply the stash\ngit stash drop stash@{0} # Drop the stash\n\n### Gitignore\n# Ignore all files in the root of the directory\n*\n# Except this file\n\n### Rebase\ngit rebase branchName # Rebase the branch\ngit rebase --continue # Continue the rebase\ngit rebase --abort # Abort the rebase\n</code></pre>"},{"location":"tech-notes/github-actions/#github-actions_1","title":"Github Actions","text":""},{"location":"tech-notes/github-actions/#basics","title":"Basics","text":"<ul> <li>Workflow conatins one or more jobs (Can run in parallel)</li> <li>job runs on a separate VM<ul> <li>Each job runs a scipt or an action</li> <li>Actions is a reusable unit of code</li> <li>steps run in sequence</li> </ul> </li> <li>Events trigger the workflow<ul> <li>Push, Pull request, Issue, etc</li> </ul> </li> <li>Runner is the VM that runs the job<ul> <li>Types<ul> <li>Repository runner</li> <li>Org runner</li> <li>Enterprise runner</li> </ul> </li> <li>Self-hosted runner</li> <li>Github-hosted runner</li> </ul> </li> </ul>"},{"location":"tech-notes/github-actions/#interesting-facts","title":"Interesting facts","text":"<ul> <li>Workflow runtime -&gt; 35 days</li> <li>Job execution time -&gt; 5 days</li> <li>Job queue time -&gt; 24 hours</li> <li>Api requests limt - 1000 requests per hour per repo</li> <li>Job matrix -&gt; 256 jobs per workflow</li> <li>Workflow runs queue -&gt; 500 workflows runs can be queued in a 10 sec interval pre repo</li> <li>Registering self-hosted runners - You can have a maximum of 10,000 self-hosted runners in one runner group.</li> <li>If GitHub Actions services are temporarily unavailable, then a workflow run is discarded if it has not been queued within 30 minutes of being triggered. For example, if a workflow is triggered and the GitHub Actions services are unavailable for 31 minutes or longer, then the workflow run will not be processed.</li> </ul>"},{"location":"tech-notes/github-actions/#choose-when-the-workflow-runs","title":"Choose when the workflow runs","text":""},{"location":"tech-notes/github-actions/#choose-where-the-workflow-runs","title":"Choose where the workflow runs","text":""},{"location":"tech-notes/github-actions/#choose-what-workflow-do","title":"Choose what workflow do","text":""},{"location":"tech-notes/github-actions/#workflow-syntax","title":"Workflow syntax","text":"<p>```YAML workflow = pipeline</p>"},{"location":"tech-notes/github-actions/#githubworkflowsmainyml","title":".github/workflows/main.yml","text":"<p>```</p>"},{"location":"tech-notes/terraform/","title":"Terraform","text":""},{"location":"tech-notes/terraform/#intro-to-terraform-httpsdeveloperhashicorpcomterraformintrophases-0","title":"Intro to Terraform (https://developer.hashicorp.com/terraform/intro/phases ) 0","text":"<ol> <li>Iac for cloud and onprem infra</li> <li>Terraform -&gt; Providers -&gt; Target API's</li> <li>Providers are stored in terraform registry.</li> <li>Terraform stages.</li> <li>Write (main.tf, statefile)</li> <li>Plan (terraform plan , equelent to whatif equivalent)</li> <li>Apply (terraform apply , deploy the infra)</li> </ol> <p>--</p>"},{"location":"tech-notes/terraform/#usecases","title":"usecases","text":"<ol> <li>Multicloud depoyments.</li> <li>Multi tier application scaling.</li> <li>Self service clusters. ie. landing zone deployments</li> <li>Policy compliance and management</li> <li>Paas application setup.</li> <li>Software defined networking.</li> <li>Kubernates management.</li> <li>Parallel environments. (Quickly spinup and destroy the resources as needed for testing)</li> <li>Software demos.</li> </ol>"},{"location":"tech-notes/terraform/#terraform-community-edition","title":"Terraform community edition.","text":"<p>Normal terraform</p>"},{"location":"tech-notes/terraform/#hcp-terraform","title":"HCP Terraform","text":"<ol> <li>Run terraform on cloud.</li> <li>State files on terraform cloud and much more.</li> </ol>"},{"location":"tech-notes/terraform/#terraform-enterprice-plan","title":"Terraform enterprice plan","text":"<ol> <li>Self hosted HCP terraform.</li> </ol>"},{"location":"tech-notes/terraform/#terraform-workflow","title":"Terraform workflow","text":"<ol> <li>Create main.tf file </li> <li>terraform init -&gt; Downloads the necessary files</li> <li>updated the main.tf </li> <li>terraform plan -&gt; Checks for any erros</li> <li>terraform apply -&gt; whatif and run the deployment</li> </ol>"},{"location":"tech-notes/terraform/#hcp-terraform_1","title":"HCP terraform","text":"<ol> <li>More fancy way of doing things </li> </ol>"},{"location":"tech-notes/terraform/#ignoring-below-files","title":"Ignoring below files","text":"<ol> <li>terraform.tfstafe</li> <li>secure values</li> <li>credentials</li> </ol>"},{"location":"tech-notes/terraform/#modules","title":"Modules","text":"<ol> <li>Create modules for reusable code </li> </ol>"},{"location":"tech-notes/terraform/#secrets","title":"Secrets","text":"<ol> <li>Use Hashicorp valut for storing secrets</li> </ol>"},{"location":"tech-notes/terraform/#remotestate-backend","title":"Remotestate backend","text":"<ol> <li>Remote state storage should be used for seemless colaboration</li> <li>saving state file in HCP terraform </li> <li>state locking , prevents concurrent terraform operation on one state file.</li> <li>Executing terraform in HCP cloud</li> </ol>"},{"location":"tech-notes/terraform/#policy-as-code-for-governance","title":"Policy as code for governance","text":""},{"location":"tech-notes/terraform/#tutorials","title":"Tutorials","text":""},{"location":"tech-notes/terraform/#fundamentals-0","title":"Fundamentals 0","text":""},{"location":"tech-notes/terraform/#azure","title":"Azure","text":""},{"location":"tech-notes/terraform/#docker-0","title":"Docker 0","text":""},{"location":"tech-notes/terraform/#hcp-terraform_2","title":"HCP Terraform","text":""},{"location":"tech-notes/terraform/#documentation","title":"Documentation","text":""},{"location":"tech-notes/test-automation-basics/","title":"Test Automation Basics","text":""},{"location":"tech-notes/test-automation-basics/#selenium-basics","title":"Selenium Basics","text":"<ul> <li> <p>Guru99</p> </li> <li> <p>Selenium HQ</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#the-same-origin-policy-issue","title":"The Same Origin Policy Issue","text":"<ul> <li>SOP</li> </ul> <p>Same Origin policy prohibits JavaScript code from accessing elements from a domain that is different from where it was launched.  Example, the HTML code in www.google.com uses a JavaScript program \u201crandomScript.js\u201d.  The same origin policy will only allow randomScript.js to access pages within google.com such as google.com/mail, google.com/login, or google.com/signup. However,  it cannot access pages from different sites such as yahoo.com/search or guru99.com because they belong to different domains.</p>"},{"location":"tech-notes/test-automation-basics/#drivers","title":"Drivers","text":""},{"location":"tech-notes/test-automation-basics/#locators","title":"Locators","text":"<ul> <li>WebDriver does not support the \u201ccontains\u201d keyword when used in the By.cssSelector() method.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#get-commands","title":"Get Commands","text":""},{"location":"tech-notes/test-automation-basics/#navigate-commands","title":"Navigate Commands","text":""},{"location":"tech-notes/test-automation-basics/#css-selector","title":"CSS Selector","text":"<ul> <li><code>css=tag#id</code></li> <li><code>css=tag.class</code></li> <li><code>css=tag[attribute=value]</code></li> <li><code>css=tag.class[attribute=value]</code></li> <li><code>css=tag:contains(\"inner text\")</code></li> <li>[src$='/images/Toolsqa.jpg']</li> <li><code>select#oldSelectMenu&gt;option:nth-of-type(2)</code></li> <li><code>input[id^='userN']</code></li> <li><code>input[id$='ame']</code></li> <li><code>input[id*='ame']</code></li> </ul>"},{"location":"tech-notes/test-automation-basics/#xpath","title":"Xpath","text":"<ul> <li><code>Xpath=//tagname[@attribute='value']</code></li> <li><code>Xpath=//td[text()='UserID']</code></li> <li><code>/html/body/div[2]/div[1]/div/h4[1]/b/html[1]/body[1]/div[2]/div[1]/div[1]/h4[1]/b[1]</code>- Absolute Xpath.</li> <li><code>Relative XPath: //div[@class='featured-box cloumnsize1']//h4[1]//b[1]</code> - Relative Xpath.</li> <li><code>Xpath=//*[contains(@type,'sub')]</code></li> <li><code>Xpath=//*[contains(text(),'here')]</code></li> <li><code>Xpath=//*[@type='submit' or @name='btnReset']</code></li> <li><code>Xpath=//input[@type='submit' and @name='btnLogin']</code></li> <li><code>Xpath=//label[starts-with(@id,'message')]</code></li> <li><code>Xpath=//*[@type='text']//following::input</code></li> <li><code>Xpath=//*[text()='Enterprise Testing']//ancestor::div</code></li> <li><code>Xpath=//*[@id='java_technologies']//child::li</code></li> <li><code>Xpath=//*[@type='submit']//preceding::input</code></li> <li><code>xpath=//*[@type='submit']//following-sibling::input</code></li> <li><code>Xpath=//*[@id='rt-feature']//parent::div</code></li> <li><code>Xpath =//*[@type='password']//self::input</code></li> <li><code>Xpath=//*[@id='rt-feature']//descendant::a</code></li> </ul>"},{"location":"tech-notes/test-automation-basics/#locating-by-dom","title":"Locating By DOM","text":"<p><code>document.getElementById(\"id of the element\")</code> <code>document.getElementByIds(\"id of the elements\")</code> <code>document.getElementByName(\"Name of the element\")</code> <code>document.getElementByNames(\"Name of the elements\")</code> <code>document.getElementsByName(\u201cname\u201c)[index]</code></p>"},{"location":"tech-notes/test-automation-basics/#alerts","title":"Alerts","text":"<pre><code>- driver.switchTo().alert().dismiss();\n- driver.switchTo().alert().accept();\n- driver.switchTo().alert().getText();\n- driver.switchTo().alert().sendKeys(\"Text\");\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#dropdowns","title":"DropDowns","text":""},{"location":"tech-notes/test-automation-basics/#window-handles","title":"Window Handles","text":""},{"location":"tech-notes/test-automation-basics/#tooltip","title":"ToolTip","text":"<ul> <li> <p>Basic Attribute validation. </p> </li> <li> <p>Using Actions API</p> </li> </ul> <p></p>"},{"location":"tech-notes/test-automation-basics/#broken-links","title":"Broken Links","text":""},{"location":"tech-notes/test-automation-basics/#test-practice-site","title":"Test Practice site","text":"<ul> <li><code>http://demo.guru99.com/test/newtours/</code></li> <li><code>https://demoqa.com/</code></li> <li>practice</li> </ul>"},{"location":"tech-notes/test-automation-basics/#selectorshub","title":"SelectorsHub","text":"<ul> <li>Used for identifying elements on web page in web development tools. ```Elements from test site css-&gt; a:contains(SIGN-ON)</li> </ul> <pre><code>\n### WebElements Conditions\n</code></pre> <p>WebElement.isEnabled() WebElement.isDesplayed() WebElement.isSelected()</p> <pre><code>\n### Expected Conditions\n</code></pre> <p>Wait.until(ExpectedConditions.alertIsPresent() Wait.until(ExpectedConditions.elementToBeClickable() Wait.until(ExpectedConditions.frameToBeAvailableAndSwitchToIt()</p> <pre><code>\n### Selenium Exceptions\n**1. ElementNotVisibleException:** This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.\n\n**2. ElementNotSelectableException:** This Selenium exception occurs when an element is presented in the [DOM](https://www.guru99.com/understanding-dom-fool-guide.html), but you can be able to select. Therefore, it is not possible to interact.\n\n**3. NoSuchElementException:** This Exception occurs if an element could not be found.\n\n**4. NoSuchFrameException:** This Exception occurs if the frame target to be switched to does not exist.\n\n**5. NoAlertPresentException:** This Exception occurs when you switch to no presented alert.\n\n**6. NoSuchWindowException:** This Exception occurs if the window target to be switch does not exist.\n\n**7. StaleElementReferenceException:** This Selenium exception occurs happens when the web element is detached from the current DOM.\n\n**8. SessionNotFoundException:** The WebDriver is acting after you quit the browser.\n\n**9. TimeoutException:** Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn\u2019t found in the specified time.\n\n**10. WebDriverException:** This Exception takes place when the WebDriver is acting right after you close the browser.\n\n**11. ConnectionClosedException:** This type of Exception takes place when there is a disconnection in the driver.\n\n**12. ElementClickInterceptedException:** The command may not be completed as the element receiving the events is concealing the element which was requested clicked.\n\n**13. ElementNotInteractableException:** This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.\n\n**14. ErrorInResponseException:** This happens while interacting with the Firefox extension or the remote driver server.\n\n**15. ErrorHandler.UnknownServerException:** Exception is used as a placeholder in case if the server returns an error without a stack trace.\n\n**16. ImeActivationFailedException:** This expectation will occur when IME engine activation has failed.\n\n**17. ImeNotAvailableException:** It takes place when IME support is unavailable.\n\n**18. InsecureCertificateException:** Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.\n\n**19. InvalidArgumentException:** It occurs when an argument does not belong to the expected type.\n\n**20. InvalidCookieDomainException:** This happens when you try to add a cookie under a different domain instead of current URL.\n\n**21. InvalidCoordinatesException:** This type of Exception matches an interacting operation that is not valid.\n\n**22. InvalidElementStateException:** It occurs when command can\u2019t be finished when the element is invalid.\n\n**23. InvalidSessionIdException:** This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.\n\n**24. InvalidSwitchToTargetException:** This occurs when the frame or window target to be switched does not exist.\n\n**25. JavascriptException:** This issue occurs while executing JavaScript given by the user.\n\n**26. JsonException:** It occurs when you afford to get the session when the session is not created.\n\n**27. NoSuchAttributeException:** This kind of Exception occurs when the attribute of an element could not be found.\n\n**28. MoveTargetOutOfBoundsException:** It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.\n\n**29. NoSuchContextException:** ContextAware does mobile device testing.\n\n**30. NoSuchCookieException:** This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.\n\n**31. NotFoundException:** This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.\n\n**32. RemoteDriverServerException:** This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.\n\n**33. ScreenshotException:** It is not possible to capture a screen.\n\n**34. SessionNotCreatedException:** It happens when a new session could not be successfully created.\n\n**35. UnableToSetCookieException:** This occurs if a driver is unable to set a cookie.\n\n**36. UnexpectedTagNameException:** Happens if a support class did not get a web element as expected.\n\n**37. UnhandledAlertException:** This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.\n\n**38. UnexpectedAlertPresentException:** It occurs when there is the appearance of an unexpected alert.\n\n**39. UnknownMethodException:** This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.\n\n**40. UnreachableBrowserException:** This Exception occurs only when the browser is not able to be opened or crashed because of some reason.\n\n**41. UnsupportedCommandException:** This occurs when remote WebDriver doesn\u2019t send valid commands as expected.\n### Exceptions\n\n- NoSuchElementException\n- TimeoutException\n\n### FindElements\n</code></pre> <p>WebElement loginLink = driver.findElement(By.linkText(\"Login\")); List listOfElements = driver.findElements(By.xpath(\"//div\")); driver.findElement(By.className(\"className\")); driver.findElement(By.cssSelector(\".className\")); driver.findElement(By.id(\"elementId\")); driver.findElement(By.linkText(\"linkText\")); driver.findElement(By.name(\"elementName\")); driver.findElement(By.partialLinkText(\"partialText\")); driver.findElement(By.tagName(\"elementTagName\")); driver.findElement(By.xpath(\"xPath\")); <pre><code>\n### Timeouts\n</code></pre> <p>driver.manage().timeouts().implicitlyWait(Duration.ofSeconds(10)); driver.manage().timeouts().scriptTimeout(Duration.ofMinutes(2)); driver.manage().timeouts().pageLoadTimeout(Duration.ofSeconds(10));</p> <pre><code>\n### Wait \n</code></pre> <p>new WebDriverWait(driver, Duration.ofSeconds(3))   .until(ExpectedConditions.elementToBeClickable(By.cssSelector(\"#id\")));</p> <p>Wait wait = new FluentWait(driver)   .withTimeout(Duration.ofSeconds(30))   .pollingEvery(Duration.ofSeconds(5))   .ignoring(NoSuchElementException.class); <pre><code>\n```java\nWait&lt;WebDriver&gt; wait = new FluentWait&lt;WebDriver&gt;(driver)\n  .withTimeout(Duration.ofSeconds(30))\n  .pollingEvery(Duration.ofSeconds(5))\n  .ignoring(NoSuchElementException.class);\n</code></pre> <pre><code>        //Declare and initialise a fluent wait\n        FluentWait wait = new FluentWait(driver);\n        //Specify the timout of the wait\n        wait.withTimeout(5000, TimeUnit.MILLISECONDS);\n        //Sepcify polling time\n        wait.pollingEvery(250, TimeUnit.MILLISECONDS);\n        //Specify what exceptions to ignore\n        wait.ignoring(NoSuchElementException.class)\n\n        //This is how we specify the condition to wait on.\n        //This is what we will explore more in this chapter\n        wait.until(ExpectedConditions.alertIsPresent());\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#action-class","title":"Action Class","text":""},{"location":"tech-notes/test-automation-basics/#upload-files","title":"Upload Files","text":"<pre><code>        // enter the file path onto the file-selection input field\n        uploadElement.sendKeys(\"C:\\\\newhtml.html\");\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#download-files","title":"Download Files","text":"<p> <code>wget</code> is a command-line utility for downloading files from the web. It is available on most Unix-like operating systems and can be used to retrieve files using various protocols, including HTTP, HTTPS, and FTP. Here are some common use cases and examples:</p>"},{"location":"tech-notes/test-automation-basics/#basic-wget-usage","title":"Basic Wget Usage:","text":"<ol> <li>Download a File: <code>bash    wget [URL]</code>    Replace <code>[URL]</code> with the actual URL of the file you want to download.</li> </ol> <p>Example:    <code>bash    wget https://example.com/file.zip</code></p> <ol> <li>Save with a Different Name: <code>bash    wget -O [output-file] [URL]</code>    Replace <code>[output-file]</code> with the desired name for the downloaded file.</li> </ol> <p>Example:    <code>bash    wget -O myfile.zip https://example.com/file.zip</code></p>"},{"location":"tech-notes/test-automation-basics/#advanced-wget-usage","title":"Advanced Wget Usage:","text":"<ol> <li>Resuming Downloads: <code>bash    wget -c [URL]</code>    This option allows you to resume an interrupted download.</li> </ol> <p>Example:    <code>bash    wget -c https://example.com/largefile.zip</code></p> <ol> <li>Limit Download Speed: <code>bash    wget --limit-rate=[speed] [URL]</code>    Replace <code>[speed]</code> with the desired download speed limit.</li> </ol> <p>Example:    <code>bash    wget --limit-rate=100k https://example.com/largefile.zip</code></p> <ol> <li>Download in the Background: <code>bash    wget -b [URL]</code>    This runs <code>wget</code> in the background.</li> </ol> <p>Example:    <code>bash    wget -b https://example.com/file.zip</code></p> <ol> <li>Download Entire Website: <code>bash    wget --recursive --no-clobber --page-requisites --html-extension --convert-links --domains example.com --no-parent [URL]</code>    This command downloads a complete website.</li> </ol> <p>Example:    <code>bash    wget --recursive --no-clobber --page-requisites --html-extension --convert-links --domains example.com --no-parent https://example.com</code></p>"},{"location":"tech-notes/test-automation-basics/#desired-capabilities","title":"Desired Capabilities","text":"<pre><code>FirefoxOptions browserOptions = new FirefoxOptions();\nbrowserOptions.setPlatformName(\"Windows 10\");\nbrowserOptions.setBrowserVersion(\"92\");\nMap&lt;String, Object&gt; cloudOptions = new HashMap&lt;&gt;();\ncloudOptions.put(\"build\", myTestBuild);\ncloudOptions.put(\"name\", myTestName);\nbrowserOptions.setCapability(\"cloud:options\", cloudOptions);\nWebDriver driver = new RemoteWebDriver(new URL(cloudUrl), browserOptions);\n</code></pre> <pre><code>ChromeOptions options = new ChromeOptions()\noptions.addArgument(\"start-maximized\");\nChromeDriver driver = new ChromeDriver(options);\n</code></pre> <pre><code>// Create an object of desired capabilities class with Chrome driver\nDesiredCapabilities SSLCertificate = DesiredCapabilities.chrome();\n// Set the pre defined capability \u2013 ACCEPT_SSL_CERTS value to true\nSSLCertificate.setCapability(CapabilityType.ACCEPT_SSL_CERTS, true);\n// Open a new instance of chrome driver with the desired capability\nWebDriver driver = new ChromeDriver(SSLCertificate);\n</code></pre> <p>Below are the list of available and most commonly used arguments for ChromeOptions class</p> <ul> <li>start-maximized: Opens Chrome in maximize mode</li> <li>incognito: Opens Chrome in incognito mode</li> <li>headless: Opens Chrome in headless mode</li> <li>disable-extensions: Disables existing extensions on Chrome browser</li> <li>disable-popup-blocking: Disables pop-ups displayed on Chrome browser</li> <li>make-default-browser: Makes Chrome default browser</li> <li>version: Prints chrome browser version</li> <li>disable-infobars: Prevents Chrome from displaying the notification \u2018Chrome is being controlled by automated software Browser Options</li> </ul>"},{"location":"tech-notes/test-automation-basics/#new-mutable-capabilities","title":"New Mutable Capabilities","text":"<pre><code>MutableCapabilities capabilities = new MutableCapabilities();\ncapabilities.setCapability(\"platformVersion\", \"Windows 10\");\nFirefoxOptions options = new FirefoxOptions();\noptions.setHeadless(true);\noptions = .merge(capabilities);\n\n// The result of the `merge` call needs to be assigned to an object.\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#screenshots","title":"ScreenShots","text":"<pre><code>public static void takeSnapShot(WebDriver webdriver,String fileWithPath) throws Exception{\n//Convert web driver object to TakeScreenshot\nTakesScreenshot scrShot =((TakesScreenshot)webdriver);\n//Call getScreenshotAs method to create image file\nFile SrcFile=scrShot.getScreenshotAs(OutputType.FILE);\n//Move image file to new destination\nFile DestFile=new File(fileWithPath);\n//Copy file at destination\nFileUtils.copyFile(SrcFile, DestFile);\n}\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#desgin-patterns","title":"Desgin Patterns","text":"<ul> <li>Design Patterns </li> </ul>"},{"location":"tech-notes/test-automation-basics/#singleton-design-pattern","title":"Singleton Design Pattern","text":"<p>Singleton Design Pattern is one of the easiest and straightforward patterns to be implemented in an automation framework. This design is used when we need to use the same object of a class across the automation framework. It restricts the instantiation of a class to a single instance.\u00a0</p> <p>Steps to follow to create singleton class:</p> <ol> <li>Declare the constructor of the class as \u2018private\u2019 so that no one can instantiate the class outside of it</li> <li>Declare a static reference variable of class</li> <li>Declare a static method with return type as an object of this singleton class which should check if the class is already instantiated once.</li> </ol> <pre><code>public class SingletonBaseClass {\n\nprivate static WebDriver driver = null;\nprivate static String browserName= \"chrome\";\n\npublic static void init() {\nif (driver == null) {\nif (browserName.equalsIgnoreCase(\"chrome\")) {\nWebDriverManager.chromedriver().setup();\ndriver = new ChromeDriver();\n} else if (browserName.equalsIgnoreCase(\"firefox\")) {\nWebDriverManager.firefoxdriver().setup();\ndriver = new FirefoxDriver();\n}\n}\ndriver.manage().deleteAllCookies();\ndriver.manage().window().maximize();\n} \npublic static WebDriver getDriver() {\nreturn driver;\n} \npublic static void quit() {\ndriver.quit();\ndriver=null;\n}\n}\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#page-object-model","title":"Page Object Model","text":"<ul> <li>Base Class </li> </ul> <pre><code>public class BaseClass {\nstatic WebDriver driver;\nstatic String browserName = \"chrome\";\nstatic String url = \"http://automationpractice.com/index.php\";\n\npublic static WebDriver init() {\nif (browserName.equalsIgnoreCase(\"chrome\")) {\nWebDriverManager.chromedriver().setup();\ndriver = new ChromeDriver();\n} else if (browserName.equalsIgnoreCase(\"firefox\")) {\nWebDriverManager.firefoxdriver().setup();\ndriver = new FirefoxDriver();\n}\ndriver.manage().deleteAllCookies();\ndriver.manage().window().maximize();\ndriver.get(url);\nreturn driver;\n} \n}\n</code></pre> <ul> <li>HomePage</li> </ul> <pre><code>public class HomePage{\nWebDriver driver;\n\n@FindBy(css = \"a.login\")\n@CacheLookup\nprivate WebElement signIn;\n\n@FindBy(css = \"input#search_query_top\")\nprivate WebElement search;\n\n@FindBy(xpath = \"//button[@name='submit_search']\")c\nprivate WebElement seacrhIcon;\n\n@FindBy(css = \"a.logout\")\nprivate WebElement signOut;\n\npublic LoginPage clickSignIn() {\nsignIn.click();\nreturn new LoginPage(driver);\n} \npublic SearchPage search(String text) {\nsearch.sendKeys(text);\nseacrhIcon.click();\nreturn new SearchPage(driver);\n} \npublic boolean logoutisDisplayed() {\nreturn signOut.isDisplayed();\n} \npublic HomePage(WebDriver driver) {\nPageFactory.initElements(driver, this);\n}\n\n}\n</code></pre> <pre><code>import java.time.Duration;\nimport java.util.Properties;\nimport org.openqa.selenium.By;\nimport org.openqa.selenium.Keys;\nimport org.openqa.selenium.WebDriver;\nimport com.qa.hubspot.base.BasePage;\nimport com.qa.hubspot.util.Constants;\nimport com.qa.hubspot.util.ElementActions;\n\npublic class LoginPage extends BasePage {\n\nWebDriver driver;\nElementActions elementActions;\n\n//1. Create OR/Page objects -&gt; using by locator\n\nBy userinputbox = By.xpath(\"//input[@id='react-select-2-input']\");\nBy paaswordinputbox = By.xpath(\"//input[@id='react-select-3-input']\");\nBy loginBtn = By.xpath(\"//button[@id='login-btn']\");\n\n//2. Define a constructor\npublic LoginPage(WebDriver driver)\n{\nthis.driver = driver;\nelementActions = new ElementActions(driver);\n}\n\n//3. Page Actions/Methods\npublic String getLoginPageTitle()\n{\nreturn elementActions.waitForPageTitle(Constants.LOGIN_PAGE_TITLE);\n}\n\npublic HomePage doLogin(String username,String pwd) {\n\nelementActions.doSendkeys(userinputbox, username);\ndriver.findElement(userinputbox).sendKeys(Keys.TAB);\nelementActions.doSendkeys(paaswordinputbox, pwd);\ndriver.findElement(paaswordinputbox).sendKeys(Keys.TAB);\ndriver.manage().timeouts().implicitlyWait(Duration.ofSeconds(30));\nelementActions.doClick(loginBtn);\nreturn new HomePage(driver);\n} \n}\n\nHomePage -\nimport java.util.Properties;\nimport org.openqa.selenium.By;\nimport org.openqa.selenium.WebDriver;\nimport com.qa.hubspot.base.BasePage;\nimport com.qa.hubspot.util.Constants;\nimport com.qa.hubspot.util.ElementActions;\n\npublic class HomePage extends BasePage{\n\nWebDriver driver;\nProperties prop;\nElementActions elementActions;\n\n//locators\nBy BSLogo = By.xpath(\"//a[@class='Navbar_logo__26S5Y']\");\nBy accountName = By.xpath(\"//span[contains(text(),'demouser')]\");\n\npublic HomePage(WebDriver driver)\n{\nthis.driver = driver;\nelementActions = new ElementActions(driver);\n}\n\n//Page Actions\npublic String getHomePageTitle()\n{\nreturn elementActions.waitForPageTitle(Constants.HOME_PAGE_TITLE);\n}\n\npublic boolean isHomePageLogoVisible()\n{\nreturn elementActions.isElementDisplayed(BSLogo);\n}\npublic boolean isAccountNameVisible()\n{\nreturn elementActions.isElementDisplayed(accountName);\n}\npublic String getAccountNameText()\n{\nreturn elementActions.doGetText(accountName);\n}\n}\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#fluent-page-object-model","title":"Fluent Page Object Model","text":"<ul> <li>provides method chaining</li> </ul> <pre><code>import org.openqa.selenium.By;\nimport org.openqa.selenium.Keys;\nimport org.openqa.selenium.WebDriver;\n\npublic class BSLoginPage {\nWebDriver driver;\nBy usernm = By.xpath(\"//input[@id='react-select-2-input']\");\nBy password = By.xpath(\"//input[@id='react-select-3-input']\");\nBy loginBtn = By.xpath(\"//button[@id='login-btn']\");\n\npublic BSLoginPage(WebDriver driver)\n{\nthis.driver = driver;\n}\n\npublic BSLoginPage enterUsername(String username)\n{\ndriver.findElement(usernm).sendKeys(username);\ndriver.findElement(usernm).sendKeys(Keys.TAB);\nreturn this;\n}\n\npublic BSLoginPage enterPassword(String passwd)\n{\ndriver.findElement(password).sendKeys(passwd);\ndriver.findElement(password).sendKeys(Keys.TAB);\nreturn this;\n} \npublic HomePage clickLoginBtn()\n{\ndriver.findElement(loginBtn).click();\nreturn new HomePage(driver);\n} \n}\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#factory-design-pattern","title":"Factory Design Pattern","text":"<p>Factory Design Pattern is one of the most used creational patterns as it provides one of the best ways to create\u00a0 an object. The term factory here means that there should be a class with a factory method which deals with all the creational stuff.</p> <p>In this pattern, there is a superclass with multiple subclasses and based on the user input at test class level, it returns one of the subclasses. In other words, it is used to create an object from one of the possible classes that extends a common parent class/ implements an interface. The instantiation logic would be the responsibility of the class that is extending the parent class thereby it hides the complex code at test level. As a user, we just need to create an object of this class and use it in the test class to call the appropriate method holding the business logic.</p> <p></p> <pre><code>public abstract class DriverManager {\nprotected WebDriver driver;\npublic WebDriver getDriver() {\nreturn driver;\n}\n}\n</code></pre> <pre><code>public class ChromeDriverManager extends DriverManager {\n\npublic ChromeDriverManager() {\nWebDriverManager.chromedriver().setup();\ndriver = new ChromeDriver();\n}\n}\n</code></pre> <pre><code>public class DriverManagerFactory {\n\npublic static DriverManager getManager(DriverType type) {\nDriverManager driverManager = null;\n\nswitch (type) {\ncase CHROME:\ndriverManager = new ChromeDriverManager(); \ncase FIREFOX:\ndriverManager = new FirefoxDriverManager(); \ncase EDGE:\ndriverManager = new EdgeDriverManager(); \ndefault:\nbreak;\n}\nreturn driverManager;\n}\n}\n</code></pre> <pre><code>public enum DriverType {\nCHROME,\nFIREFOX,\nEDGE,\nSAFARI;\n}\n</code></pre> <pre><code>@BeforeTest\npublic void beforeTest() {\ndriverManager = DriverManagerFactory.getManager(DriverType.CHROME);\ndriver=driverManager.getDriver();\n}\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#facade-design-pattern","title":"Facade Design Pattern","text":"<p>Facade design pattern comes under structural design patterns. It provides a simple interface to deal with complex code. In this pattern we create a facade class which has methods that combine actions executed on different pages. This is an extension to the Page Object Model pattern.</p> <p>Following example can help you under Facade in a layman sense.</p> <p>When we visit any restaurant to order our favourite food, we are not aware of what cuisine the restaurant serves unless we see the menu card or ask the waiter about it. We are just interested in ordering the food by using a waiter/menu card as the interface(facade) and do not worry about how it is actually being prepared in the kitchen.\u00a0</p> <p></p>"},{"location":"tech-notes/test-automation-basics/#pagefactory","title":"PageFactory","text":""},{"location":"tech-notes/test-automation-basics/#parameterization","title":"Parameterization","text":"<ul> <li>Stratagy Desgin Pattern</li> </ul>"},{"location":"tech-notes/test-automation-basics/#apache-poi","title":"Apache POI","text":""},{"location":"tech-notes/test-automation-basics/#robot-class","title":"Robot Class","text":"<ul> <li>Robot Class</li> </ul>"},{"location":"tech-notes/test-automation-basics/#sikuli","title":"Sikuli","text":"<ul> <li>Sikuli Basics</li> </ul>"},{"location":"tech-notes/test-automation-basics/#scrolling","title":"Scrolling","text":"<pre><code>JavascriptExecutor js = (JavascriptExecutor) driver;  \n   js.executeScript(Script,Arguments);\n   js.executeScript(\"window.scrollBy(0,1000)\");\n\n//This will scroll the page Horizontally till the element is found      \njs.executeScript(\"arguments[0].scrollIntoView();\", Element);\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#property-file-object-repository","title":"Property File Object Repository","text":"<pre><code>Properties obj = new Properties();\nFileInputStream objfile = new FileInputStream(System.getProperty(\"user.dir\")+\"\\\\application.properties\");\nobj.load(objfile);\nString mobileTesting = obj.getProperty(\"MobileTesting\");\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#practice-web-sites","title":"Practice Web Sites","text":"<ol> <li>https://the-internet.herokuapp.com/</li> <li>https://demoqa.com/</li> <li>https://candymapper.com/</li> <li>https://the-internet.herokuapp.com/dynamic_loading</li> <li>https://www.saucedemo.com/</li> <li>https://www.demoblaze.com</li> <li>https://the-internet.herokuapp.com/upload</li> <li>https://formy-project.herokuapp.com/</li> <li>https://the-internet.herokuapp.com/floating_menu</li> </ol>"},{"location":"tech-notes/test-automation-basics/#soupui","title":"SoupUI","text":""},{"location":"tech-notes/test-automation-basics/#api-application-programming-interface-basic-concepts","title":"API (Application Programming Interface) Basic Concepts","text":"<p>APIs, or Application Programming Interfaces, are essential components of software and system development, enabling applications to communicate and interact with each other. Here are some fundamental concepts related to APIs:</p>"},{"location":"tech-notes/test-automation-basics/#what-is-an-api","title":"What is an API?","text":"<ul> <li> <p>An API is a set of rules and protocols that allows different software applications to communicate and interact with each other.</p> </li> <li> <p>It defines the methods and data formats that applications can use to request and exchange information.</p> </li> <li> <p>APIs can be used to access functionality or data from services, libraries, or external systems.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#types-of-apis","title":"Types of APIs","text":"<ol> <li> <p>Web APIs: Web APIs, often referred to as REST or SOAP APIs, are accessed over the internet using standard HTTP methods. They allow applications to communicate over the web.</p> </li> <li> <p>Library APIs: Library APIs are sets of functions and procedures that developers can use to perform specific tasks or operations within a program.</p> </li> <li> <p>Operating System APIs: These APIs provide access to the underlying functions and services of an operating system, such as file management, hardware control, and process management.</p> </li> <li> <p>Database APIs: Database APIs enable applications to interact with databases, allowing data retrieval, modification, and management.</p> </li> </ol>"},{"location":"tech-notes/test-automation-basics/#key-concepts","title":"Key Concepts","text":"<ul> <li> <p>Endpoints: Endpoints are specific URLs or URIs that represent different functionalities or resources provided by a web API. Each endpoint corresponds to a specific action.</p> </li> <li> <p>HTTP Methods: APIs use HTTP methods (e.g., GET, POST, PUT, DELETE) to perform operations on resources. For example, GET retrieves data, while POST creates new data.</p> </li> <li> <p>Request and Response: An API request is made by a client to access a resource, and the server responds with data or the result of the requested operation.</p> </li> <li> <p>Authentication: Many APIs require authentication, ensuring that only authorized users or applications can access the data or services.</p> </li> <li> <p>Rate Limiting: APIs may have rate limits to control the number of requests a client can make within a specific time frame to prevent abuse.</p> </li> <li> <p>Versioning: API versions are used to maintain compatibility. When changes are made, older versions can still be used by existing clients.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#use-cases","title":"Use Cases","text":"<ul> <li> <p>Integration: APIs are crucial for integrating services and systems, allowing them to work together and share data.</p> </li> <li> <p>Third-Party Services: Developers use APIs to access services and data provided by external organizations, such as social media platforms or payment gateways.</p> </li> <li> <p>Mobile Apps: Mobile apps often use APIs to access server-side functionality, such as retrieving data from a remote server.</p> </li> <li> <p>Automation: APIs are used for automating tasks, enabling software to interact with other software without manual intervention.</p> </li> <li> <p>Data Access: APIs provide structured access to data, making it easier to retrieve and manipulate information.</p> </li> </ul> <p>APIs are the building blocks of modern software development, enabling interoperability and data exchange between a wide range of applications and systems.</p>"},{"location":"tech-notes/test-automation-basics/#structure-of-a-soap-message","title":"Structure of a SOAP message","text":"<p>A SOAP message is encoded as an XML document, consisting of an \"Envelope\" element, which contains an optional \"Header\" element, and a mandatory \"Body\" element. The \"Fault\" element, contained in the \"Body\", is used for reporting errors.</p>"},{"location":"tech-notes/test-automation-basics/#1-envelope","title":"1 Envelope","text":"<p>The SOAP \"Envelope\" is the root element in every SOAP message. It contains two child elements, an optional \"Header\", and a mandatory \"Body\".</p>"},{"location":"tech-notes/test-automation-basics/#2-header","title":"2 Header","text":"<p>The SOAP \"Header\" is an optional subelement of the SOAP envelope. It is used to pass application-related information that is to be processed by SOAP nodes along the message path.</p>"},{"location":"tech-notes/test-automation-basics/#3-body","title":"3 Body","text":"<p>The SOAP \"Body\" is a mandatory subelement of the SOAP envelope. It contains information intended for the ultimate recipient of the message.</p>"},{"location":"tech-notes/test-automation-basics/#4-fault","title":"4 Fault","text":"<p>The SOAP \"Fault\" is a subelement of the SOAP body, which is used for reporting errors.</p> <p>With the exception of the \"Fault\" element, which is contained in the \"Body\" of a SOAP message, XML elements in the \"Header\" and the \"Body\" are defined by the applications that make use of them. However, the SOAP specification imposes some constraints on their structure.</p>"},{"location":"tech-notes/test-automation-basics/#structure-of-a-soap-message_1","title":"Structure of a SOAP message","text":""},{"location":"tech-notes/test-automation-basics/#example-of-a-soap-message","title":"example of a SOAP message","text":"<pre><code>&lt;soap:Envelope xmlns:soap=\"http://www.w3.org/2003/05/soap-envelope\" xmlns:tem=\"http://tempuri.org/\"&gt;\n   &lt;soap:Header/&gt;\n   &lt;soap:Body&gt;\n      &lt;tem:Add&gt;\n         &lt;tem:a&gt;7&lt;/tem:a&gt;\n         &lt;tem:b&gt;6&lt;/tem:b&gt;\n      &lt;/tem:Add&gt;\n   &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre> <pre><code>&lt;?xml version='1.0' ?&gt;\n&lt;env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\"&gt; \n &lt;env:Header&gt;\n  &lt;m:reservation xmlns:m=\"http://travelcompany.example.org/reservation\" \n          env:role=\"http://www.w3.org/2003/05/soap-envelope/role/next\"\n           env:mustUnderstand=\"true\"&gt;\n   &lt;m:reference&gt;uuid:093a2da1-q345-739r-ba5d-pqff98fe8j7d&lt;/m:reference&gt;\n   &lt;m:dateAndTime&gt;2001-11-29T13:20:00.000-05:00&lt;/m:dateAndTime&gt;\n  &lt;/m:reservation&gt;\n  &lt;n:passenger xmlns:n=\"http://mycompany.example.com/employees\"\n          env:role=\"http://www.w3.org/2003/05/soap-envelope/role/next\"\n           env:mustUnderstand=\"true\"&gt;\n   &lt;n:name&gt;\u00c5ke J\u00f3gvan \u00d8yvind&lt;/n:name&gt;\n  &lt;/n:passenger&gt;\n &lt;/env:Header&gt;\n &lt;env:Body&gt;\n  &lt;p:itinerary\n    xmlns:p=\"http://travelcompany.example.org/reservation/travel\"&gt;\n   &lt;p:departure&gt;\n     &lt;p:departing&gt;New York&lt;/p:departing&gt;\n     &lt;p:arriving&gt;Los Angeles&lt;/p:arriving&gt;\n     &lt;p:departureDate&gt;2001-12-14&lt;/p:departureDate&gt;\n     &lt;p:departureTime&gt;late afternoon&lt;/p:departureTime&gt;\n     &lt;p:seatPreference&gt;aisle&lt;/p:seatPreference&gt;\n   &lt;/p:departure&gt;\n   &lt;p:return&gt;\n     &lt;p:departing&gt;Los Angeles&lt;/p:departing&gt;\n     &lt;p:arriving&gt;New York&lt;/p:arriving&gt;\n     &lt;p:departureDate&gt;2001-12-20&lt;/p:departureDate&gt;\n     &lt;p:departureTime&gt;mid-morning&lt;/p:departureTime&gt;\n     &lt;p:seatPreference/&gt;\n   &lt;/p:return&gt;\n  &lt;/p:itinerary&gt;\n  &lt;q:lodging\n   xmlns:q=\"http://travelcompany.example.org/reservation/hotels\"&gt;\n   &lt;q:preference&gt;none&lt;/q:preference&gt;\n  &lt;/q:lodging&gt;\n &lt;/env:Body&gt;\n&lt;/env:Envelope&gt;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#wsdl-web-services-description-language","title":"WSDL (Web Services Description Language)","text":"<p>WSDL is an XML-based language used to describe web services and their functionality.</p> <ul> <li> <p>Service: Describes the service's name and location (URL).</p> </li> <li> <p>Ports: Define the endpoints for the service.</p> </li> <li> <p>Operations: Specify the functions or methods that can be called on the service.</p> </li> <li> <p>Messages: Describe the data exchanged between the client and the service.</p> </li> <li> <p>Data Types: Define the data structures used by the service.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#wsdl-purpose","title":"WSDL Purpose","text":"<ul> <li> <p>WSDL is essential in web service development for integrating different systems and allowing them to communicate over a network.</p> </li> <li> <p>It defines the contract between service providers and consumers, ensuring both parties understand how to interact.</p> </li> <li> <p>When used with SOAP (Simple Object Access Protocol), it creates platform-independent web services.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#example-wsdl-structure","title":"Example WSDL Structure","text":"<pre><code>&lt;definitions name=\"MyService\"\n    targetNamespace=\"http://example.com/myservice.wsdl\"\n    xmlns=\"http://schemas.xmlsoap.org/wsdl/\"\n    xmlns:soap=\"http://schemas.xmlsoap.org/wsdl/soap/\"\n    xmlns:tns=\"http://example.com/myservice.wsdl\"&gt;\n\n    &lt;service name=\"MyService\"&gt;\n        &lt;port name=\"MyServicePort\" binding=\"tns:MyServiceBinding\"&gt;\n            &lt;soap:address location=\"http://example.com/myservice\"/&gt;\n        &lt;/port&gt;\n    &lt;/service&gt;\n\n    &lt;binding name=\"MyServiceBinding\" type=\"tns:MyServicePortType\"&gt;\n        &lt;soap:binding style=\"rpc\" transport=\"http://schemas.xmlsoap.org/soap/http\"/&gt;\n        &lt;operation name=\"doSomething\"&gt;\n            &lt;soap:operation soapAction=\"http://example.com/myservice#doSomething\"/&gt;\n            &lt;input&gt;\n                &lt;soap:body use=\"encoded\" namespace=\"urn:example\" encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"/&gt;\n            &lt;/input&gt;\n            &lt;output&gt;\n                &lt;soap:body use=\"encoded\" namespace=\"urn:example\" encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"/&gt;\n            &lt;/output&gt;\n        &lt;/operation&gt;\n    &lt;/binding&gt;\n\n    &lt;portType name=\"MyServicePortType\"&gt;\n        &lt;operation name=\"doSomething\"&gt;\n            &lt;input message=\"tns:doSomethingIn\"/&gt;\n            &lt;output message=\"tns:doSomethingOut\"/&gt;\n        &lt;/operation&gt;\n    &lt;/portType&gt;\n\n    &lt;message name=\"doSomethingIn\"&gt;\n        &lt;part name=\"parameters\" element=\"tns:doSomething\"/&gt;\n    &lt;/message&gt;\n\n    &lt;message name=\"doSomethingOut\"&gt;\n        &lt;part name=\"parameters\" element=\"tns:doSomethingResponse\"/&gt;\n    &lt;/message&gt;\n\n    &lt;element name=\"doSomething\" type=\"xsd:string\"/&gt;\n\n    &lt;element name=\"doSomethingResponse\" type=\"xsd:string\"/&gt;\n&lt;/definitions&gt;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#wsdl-usage","title":"WSDL Usage","text":"<ul> <li> <p>WSDL files can be used to generate client code (proxy classes) or server code (skeleton classes) in various programming languages to interact with web services.</p> </li> <li> <p>They play a crucial role in enabling the interoperability of web services in a standardized way.</p> </li> </ul> <p>WSDL is fundamental in building and accessing web services in a structured and consistent manner. Understanding its structure and usage is essential for web service development and integration.</p>"},{"location":"tech-notes/test-automation-basics/#message-structure","title":"Message Structure","text":"<p>SOAP (Simple Object Access Protocol) is a protocol used for exchanging structured information in the implementation of web services. A SOAP message consists of several key elements that define its structure:</p>"},{"location":"tech-notes/test-automation-basics/#envelope","title":"Envelope","text":"<ul> <li> <p>The <code>&lt;Envelope&gt;</code> element is the root element of a SOAP message.</p> </li> <li> <p>It encapsulates the entire SOAP message and defines the XML namespace for SOAP.</p> </li> </ul> <pre><code>&lt;soapenv:Envelope\n    xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\"\n    xmlns:web=\"http://www.example.com/webservice\"&gt;\n    &lt;!-- Body and Header elements go here --&gt;\n&lt;/soapenv:Envelope&gt;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#header","title":"Header","text":"<ul> <li> <p>The optional <code>&lt;Header&gt;</code> element contains additional metadata about the SOAP message.</p> </li> <li> <p>It can include information like authentication credentials, routing instructions, or application-specific data.</p> </li> </ul> <pre><code>&lt;soapenv:Header&gt;\n    &lt;!-- Header data goes here --&gt;\n&lt;/soapenv:Header&gt;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#body","title":"Body","text":"<ul> <li> <p>The <code>&lt;Body&gt;</code> element contains the actual content of the SOAP message.</p> </li> <li> <p>It defines the payload, which typically includes the request or response data for a web service operation.</p> </li> </ul> <pre><code>&lt;soapenv:Body&gt;\n    &lt;!-- Request or response data goes here --&gt;\n&lt;/soapenv:Body&gt;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#fault","title":"Fault","text":"<ul> <li> <p>In the event of an error or exception, a SOAP message may contain a <code>&lt;Fault&gt;</code> element within the <code>&lt;Body&gt;</code>.</p> </li> <li> <p>The <code>&lt;Fault&gt;</code> element provides information about the error, including a fault code, fault string, and optional details.</p> </li> </ul> <pre><code>&lt;soapenv:Fault&gt;\n    &lt;faultcode&gt;soapenv:Server&lt;/faultcode&gt;\n    &lt;faultstring&gt;Invalid input&lt;/faultstring&gt;\n    &lt;detail&gt;\n        &lt;!-- Error details go here --&gt;\n    &lt;/detail&gt;\n&lt;/soapenv:Fault&gt;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#namespace-prefixes","title":"Namespace Prefixes","text":"<ul> <li> <p>SOAP messages typically use namespace prefixes to define namespaces and reference elements.</p> </li> <li> <p>Commonly used prefixes include <code>soapenv</code> for the SOAP envelope and <code>web</code> for the web service namespace.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#example-soap-message","title":"Example SOAP Message","text":"<p>Here's an example of a simple SOAP message structure:</p> <pre><code>&lt;soapenv:Envelope\n    xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\"\n    xmlns:web=\"http://www.example.com/webservice\"&gt;\n    &lt;soapenv:Header&gt;\n        &lt;!-- Header data goes here --&gt;\n    &lt;/soapenv:Header&gt;\n    &lt;soapenv:Body&gt;\n        &lt;!-- Request or response data goes here --&gt;\n    &lt;/soapenv:Body&gt;\n&lt;/soapenv:Envelope&gt;\n</code></pre> <p>The structure of a SOAP message is well-defined and allows for the exchange of structured data in a standardized manner, making it a key technology for web service communication.</p>"},{"location":"tech-notes/test-automation-basics/#structure-of-a-soap-message_2","title":"Structure of a SOAP message","text":""},{"location":"tech-notes/test-automation-basics/#properties","title":"Properties","text":""},{"location":"tech-notes/test-automation-basics/#types-of-properties","title":"Types of Properties","text":"<ol> <li>Test Case Properties: These properties are specific to a particular test case and are used to store data or values that are needed within that test case. Test case properties can be set and accessed only within the scope of that test case.</li> <li>Test Suite Properties: Test suite properties are at the test suite level and can be accessed by all the test cases within the same test suite. They are valuable for sharing data among test cases within a specific test suite.</li> <li>Project Properties: Project properties are accessible to all test cases within a project, making them suitable for storing data that needs to be shared across multiple test cases within the same project.</li> <li>Test Step Properties: Test step properties are specific to an individual test step within a test case. They are used to store data or values required for a particular test step's operation.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#common-uses-of-properties","title":"Common Uses of Properties","text":"<ul> <li> <p>Data-Driven Testing: You can use properties to parameterize test data, making it easy to run the same test with different input values.</p> </li> <li> <p>Dynamic Endpoints: When testing services with variable endpoints, properties allow you to change the endpoint dynamically based on the test case's requirements.</p> </li> <li> <p>Assertions and Validation: Properties are useful for storing expected values to compare with actual responses during test execution.</p> </li> <li> <p>Environment Configuration: You can store environment-specific configurations, such as server URLs or authentication credentials, as properties.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#property-expansion","title":"Property Expansion","text":"<ul> <li> <p>SoapUI supports property expansion, which allows you to reference and use property values within various parts of your test steps, request parameters, and response assertions.</p> </li> <li> <p>Property expansion is done by enclosing the property name in double curly braces, like <code>${#TestCase#Property}</code> or <code>${#Project#Property}</code>.</p> </li> <li> <p>For example, you can use property expansion to inject dynamic data into a request or to specify the expected outcome in an assertion.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#property-transfer","title":"Property Transfer","text":"<ul> <li> <p>Property transfer is a feature in SoapUI that allows you to extract data from one part of a response and store it in a property for later use in the test case.</p> </li> <li> <p>It's commonly used to capture values from a response (e.g., an authentication token) and reuse them in subsequent requests.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#scripting-and-properties","title":"Scripting and Properties","text":"<ul> <li>Properties can be manipulated using Groovy or JavaScript scripting within SoapUI. This allows you to perform dynamic operations on property values during test execution.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#property-steps","title":"Property Steps","text":"<ul> <li> <p>SoapUI provides specific test steps, such as \"Property Transfer\" and \"Property Loop,\" to work with properties efficiently.</p> </li> <li> <p>\"Property Transfer\" steps allow you to extract and set property values.</p> </li> <li> <p>\"Property Loop\" steps enable you to iterate over a range of property values, making it easy to repeat test steps multiple times with different data.</p> </li> </ul> <p>Properties in SoapUI are a powerful tool for building flexible and data-driven test cases, enhancing the reusability and efficiency of your API and web service testing efforts.</p>"},{"location":"tech-notes/test-automation-basics/#assertions","title":"Assertions","text":"<p>Assertions in SoapUI are used to validate the responses and behavior of web services during testing. They help ensure that the service meets the expected criteria.</p>"},{"location":"tech-notes/test-automation-basics/#types-of-assertions","title":"Types of Assertions","text":"<p>SoapUI supports various types of assertions, including:</p>"},{"location":"tech-notes/test-automation-basics/#response-assertion","title":"Response Assertion","text":"<p>Compares the response against expected values, status codes, or patterns. </p> <ol> <li>XPath Assertion: Validates elements or attributes in XML responses using XPath expressions.</li> </ol> <p></p>"},{"location":"tech-notes/test-automation-basics/#tag-existence","title":"Tag existence","text":""},{"location":"tech-notes/test-automation-basics/#tag-counts","title":"Tag Counts","text":""},{"location":"tech-notes/test-automation-basics/#entire-xml-validation","title":"Entire XML validation","text":""},{"location":"tech-notes/test-automation-basics/#allow-wildcards-in-xpath","title":"Allow Wildcards in Xpath","text":"<p> 3. Script Assertion: Allows you to write custom scripts (e.g., Groovy scripts) to define complex validation logic.</p> <ol> <li>JSONPath Assertion: Similar to XPath but for JSON responses, it uses JSONPath expressions for validation.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#sla-assertion","title":"SLA Assertion","text":""},{"location":"tech-notes/test-automation-basics/#status-code-assertion","title":"Status Code Assertion","text":""},{"location":"tech-notes/test-automation-basics/#contains-assertion","title":"Contains Assertion","text":""},{"location":"tech-notes/test-automation-basics/#token-validation","title":"Token validation","text":""},{"location":"tech-notes/test-automation-basics/#not-contains-assertion","title":"Not Contains Assertion","text":"<p> 8. Length Assertion: Verifies the length of the response content.</p> <ol> <li>SOAP Fault Assertion: Ensures that a response contains a SOAP fault when expected.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#using-assertions","title":"Using Assertions","text":"<p>To use assertions in SoapUI:</p> <ol> <li> <p>Create a test step in your test case (e.g., a REST or SOAP request).</p> </li> <li> <p>Open the test step and navigate to the \"Assertions\" tab.</p> </li> <li> <p>Add the desired assertion type based on what you want to validate.</p> </li> <li> <p>Configure the assertion's settings, such as expected values or patterns.</p> </li> <li> <p>Run the test case, and SoapUI will report whether the assertions pass or fail.</p> </li> </ol>"},{"location":"tech-notes/test-automation-basics/#importance-of-assertions","title":"Importance of Assertions","text":"<ul> <li> <p>Assertions help automate the validation process, making it easier to detect issues and changes in web service behavior.</p> </li> <li> <p>They play a critical role in regression testing, ensuring that new updates don't break existing functionality.</p> </li> <li> <p>By specifying expected outcomes, assertions provide clear pass/fail criteria for testing.</p> </li> <li> <p>They improve the reliability and accuracy of testing by reducing manual verification efforts.</p> </li> <li> <p>Assertions are an essential part of SoapUI's functionality, making it a powerful tool for testing and quality assurance.</p> </li> </ul> <p>Using assertions in SoapUI is crucial for robust testing of web services, enabling thorough verification of expected results and service behavior.</p>"},{"location":"tech-notes/test-automation-basics/#wsdl","title":"WSDL","text":""},{"location":"tech-notes/test-automation-basics/#wsdl-web-services-description-language_1","title":"WSDL (Web Services Description Language)","text":"<p>WSDL is an XML-based language used to describe web services and their functionality.</p> <ul> <li> <p>Service: Describes the service's name and location (URL).</p> </li> <li> <p>Ports: Define the endpoints for the service.</p> </li> <li> <p>Operations: Specify the functions or methods that can be called on the service.</p> </li> <li> <p>Messages: Describe the data exchanged between the client and the service.</p> </li> <li> <p>Data Types: Define the data structures used by the service.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#wsdl-purpose_1","title":"WSDL Purpose","text":"<ul> <li> <p>WSDL is essential in web service development for integrating different systems and allowing them to communicate over a network.</p> </li> <li> <p>It defines the contract between service providers and consumers, ensuring both parties understand how to interact.</p> </li> <li> <p>When used with SOAP (Simple Object Access Protocol), it creates platform-independent web services.</p> </li> </ul>"},{"location":"tech-notes/test-automation-basics/#example-wsdl-structure_1","title":"Example WSDL Structure","text":"<pre><code>&lt;definitions name=\"MyService\"\n    targetNamespace=\"http://example.com/myservice.wsdl\"\n    xmlns=\"http://schemas.xmlsoap.org/wsdl/\"\n    xmlns:soap=\"http://schemas.xmlsoap.org/wsdl/soap/\"\n    xmlns:tns=\"http://example.com/myservice.wsdl\"&gt;\n\n    &lt;service name=\"MyService\"&gt;\n        &lt;port name=\"MyServicePort\" binding=\"tns:MyServiceBinding\"&gt;\n            &lt;soap:address location=\"http://example.com/myservice\"/&gt;\n        &lt;/port&gt;\n    &lt;/service&gt;\n\n    &lt;binding name=\"MyServiceBinding\" type=\"tns:MyServicePortType\"&gt;\n        &lt;soap:binding style=\"rpc\" transport=\"http://schemas.xmlsoap.org/soap/http\"/&gt;\n        &lt;operation name=\"doSomething\"&gt;\n            &lt;soap:operation soapAction=\"http://example.com/myservice#doSomething\"/&gt;\n            &lt;input&gt;\n                &lt;soap:body use=\"encoded\" namespace=\"urn:example\" encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"/&gt;\n            &lt;/input&gt;\n            &lt;output&gt;\n                &lt;soap:body use=\"encoded\" namespace=\"urn:example\" encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"/&gt;\n            &lt;/output&gt;\n        &lt;/operation&gt;\n    &lt;/binding&gt;\n\n    &lt;portType name=\"MyServicePortType\"&gt;\n        &lt;operation name=\"doSomething\"&gt;\n            &lt;input message=\"tns:doSomethingIn\"/&gt;\n            &lt;output message=\"tns:doSomethingOut\"/&gt;\n        &lt;/operation&gt;\n    &lt;/portType&gt;\n\n    &lt;message name=\"doSomethingIn\"&gt;\n        &lt;part name=\"parameters\" element=\"tns:doSomething\"/&gt;\n    &lt;/message&gt;\n\n    &lt;message name=\"doSomethingOut\"&gt;\n        &lt;part name=\"parameters\" element=\"tns:doSomethingResponse\"/&gt;\n    &lt;/message&gt;\n\n    &lt;element name=\"doSomething\" type=\"xsd:string\"/&gt;\n\n    &lt;element name=\"doSomethingResponse\" type=\"xsd:string\"/&gt;\n&lt;/definitions&gt;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#wsdl-usage_1","title":"WSDL Usage","text":"<ul> <li> <p>WSDL files can be used to generate client code (proxy classes) or server code (skeleton classes) in various programming languages to interact with web services.</p> </li> <li> <p>They play a crucial role in enabling the interoperability of web services in a standardized way.</p> </li> </ul> <p>WSDL is fundamental in building and accessing web services in a structured and consistent manner. Understanding its structure and usage is essential for web service development and integration.</p>"},{"location":"tech-notes/test-automation-basics/#wsdl_1","title":"WSDL","text":""},{"location":"tech-notes/test-automation-basics/#1-creating-a-test-case-and-making-a-request","title":"1. Creating a Test Case and Making a Request","text":"<pre><code>// Create a new Test Case\ndef testCase = testRunner.testCase.createTestStep(\"MyTestCase\")\n\n// Create a new Test Request\ndef testRequest = testCase.addTestRequest(\"MyTestRequest\")\n\n// Set the endpoint URL\ndef endpoint = \"https://api.example.com\"\ntestRequest.setPropertyValue(\"Endpoint\", endpoint)\n\n// Set the request body\ndef requestBody = \"\"\"\n&lt;soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:web=\"http://www.example.com\"&gt;\n    &lt;soapenv:Header/&gt;\n    &lt;soapenv:Body&gt;\n        &lt;web:MyRequest&gt;\n            &lt;web:Parameter1&gt;Value1&lt;/web:Parameter1&gt;\n            &lt;web:Parameter2&gt;Value2&lt;/web:Parameter2&gt;\n        &lt;/web:MyRequest&gt;\n    &lt;/soapenv:Body&gt;\n&lt;/soapenv:Envelope&gt;\n\"\"\"\ntestRequest.setRequestContent(requestBody)\n\n// Execute the request\ndef response = testRequest.run(null, true)\nlog.info(\"Response: \" + response.getResponseContent())\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#2-data-driven-testing","title":"2. Data-Driven Testing","text":"<pre><code>import com.eviware.soapui.support.GroovyUtils\n\n// Load data from an external source (e.g., CSV file)\ndef csvFile = \"data.csv\"\ndef data = new GroovyUtils(context).getXmlHolder(csvFile)\n\n// Loop through the data rows and execute requests for each row\nwhile (data[\"//row\"]) {\n    def parameter1 = data.getNodeValues(\"Parameter1\").join()\n    def parameter2 = data.getNodeValues(\"Parameter2\").join()\n\n    // Create a new Test Case for each data row\n    def testCase = testRunner.testCase.createTestStep(\"Data-Driven-Test\")\n\n    // Create a new Test Request\n    def testRequest = testCase.addTestRequest(\"Data-Driven-Request\")\n\n    // Set the endpoint URL\n    def endpoint = \"https://api.example.com\"\n    testRequest.setPropertyValue(\"Endpoint\", endpoint)\n\n    // Set the request body with parameters from the data source\n    def requestBody = \"\"\"\n    &lt;soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:web=\"http://www.example.com\"&gt;\n        &lt;soapenv:Header/&gt;\n        &lt;soapenv:Body&gt;\n            &lt;web:MyRequest&gt;\n                &lt;web:Parameter1&gt;${parameter1}&lt;/web:Parameter1&gt;\n                &lt;web:Parameter2&gt;${parameter2}&lt;/web:Parameter2&gt;\n            &lt;/web:MyRequest&gt;\n        &lt;/soapenv:Body&gt;\n    &lt;/soapenv:Envelope&gt;\n    \"\"\"\n    testRequest.setRequestContent(requestBody)\n\n    // Execute the request and log the response\n    def response = testRequest.run(null, true)\n    log.info(\"Response for Parameter1: ${parameter1}, Parameter2: ${parameter2}: \" + response.getResponseContent())\n\n    // Move to the next row in the data source\n    data = data.getNextSibling()\n}\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#3-adding-assertions","title":"3. Adding Assertions","text":"<pre><code>// Create a new Test Case\ndef testCase = testRunner.testCase.createTestStep(\"Assertions-Test\")\n\n// Create a new Test Request\ndef testRequest = testCase.addTestRequest(\"Assertions-Request\")\n\n// Set the endpoint URL\ndef endpoint = \"https://api.example.com\"\ntestRequest.setPropertyValue(\"Endpoint\", endpoint)\n\n// Set the request body\ndef requestBody = \"\"\"\n&lt;soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:web=\"http://www.example.com\"&gt;\n    &lt;soapenv:Header/&gt;\n    &lt;soapenv:Body&gt;\n        &lt;web:MyRequest&gt;\n            &lt;web:Parameter1&gt;Value1&lt;/web:Parameter1&gt;\n            &lt;web:Parameter2&gt;Value2&lt;/web:Parameter2&gt;\n        &lt;/web:MyRequest&gt;\n    &lt;/soapenv:Body&gt;\n&lt;/soapenv:Envelope&gt;\n\"\"\"\ntestRequest.setRequestContent(requestBody)\n\n// Execute the request\ndef response = testRequest.run(null, true)\ndef responseContent = response.getResponseContent()\n\n// Add an assertion to check if a specific element exists in the response\ndef assertion = testRequest.addAssertion(\"Response Contains\")\nassertion.setConfiguration(\"&lt;XPath Match='//web:SomeElement'/&gt;\")\nassertion.setMessageContent(responseContent)\n\n// Execute the assertion\nassertion.assertResponse()\n</code></pre> <p>These code examples provide a practical demonstration of creating test cases, making requests, performing data-driven testing, and adding assertions in SoapUI using Groovy scripting. You can adapt and expand these examples to suit your specific testing needs.</p>"},{"location":"tech-notes/test-automation-basics/#project","title":"Project","text":""},{"location":"tech-notes/test-automation-basics/#service-descriptionwsdl","title":"Service Description(Wsdl)","text":"<pre><code>http://216.10.245.166:8080/axis2/services/EmployeeManagementService?wsdl\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#rest-assured","title":"Rest Assured","text":"<p>ToolsQA</p> <p>QA Automation Expert</p> <p>Rest Assured Official site</p>"},{"location":"tech-notes/test-automation-basics/#api-flow","title":"API Flow","text":""},{"location":"tech-notes/test-automation-basics/#http-basics","title":"Http Basics","text":""},{"location":"tech-notes/test-automation-basics/#http-methods","title":"HTTP methods","text":"<p>GET     Asks to get the resource at the requested URL. POST    Asks the server to accept the body info attached. It is like GET request with extra info sent with the request. HEAD    Asks for only the header part of whatever a GET would return. Just like GET but with no body. TRACE Asks for the loopback of the request message, for testing or troubleshooting. PUT   Says to put the enclosed info (the body) at the requested URL. DELETE  Says to delete the resource at the requested URL. OPTIONS     Asks for a list of the HTTP methods to which the thing at the request URL can respond PATCH: For partial updates.</p> <ol> <li>1xx (100 \u2013 199): The response is informational</li> <li>2xx (200 \u2013 299): Assures successful response</li> <li>3xx (300 \u2013 399): You are required to take further action to fulfill the request</li> <li>4xx (400 \u2013 499): There\u2019s a bad syntax and the request cannot be completed</li> <li>5xx (500 \u2013 599): The server entirely fails to complete the request</li> </ol>"},{"location":"tech-notes/test-automation-basics/#example","title":"Example","text":"<pre><code>https://domain.com/?key1=value1&amp;key2=value2\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#http-request","title":"HTTP Request","text":""},{"location":"tech-notes/test-automation-basics/#request-line","title":"Request Line","text":"<ul> <li>The HTTP method used</li> <li>The request URI</li> <li>The HTTP protocol version</li> </ul>"},{"location":"tech-notes/test-automation-basics/#zero-or-more-headers","title":"Zero or more headers","text":"<ul> <li>User-Agent: lets the server identify the application, operating system, vendor, and version.</li> <li>Connection: controls the network connection. In other words, kill or continues the connection after the transaction.</li> <li>Cache-Control: specifies browser caching policies.</li> <li>Accept-Language: indicates what all languages(natural) the client can understand.</li> <li>Accept-Charset</li> <li>Accept-Encoding</li> <li>Authorization</li> <li>Content-Length</li> <li>Content-Type</li> <li>Cookie</li> <li>Expect</li> <li>From</li> <li>Host</li> <li>If-Match</li> <li>If-Modified-Since</li> <li>In-None-Match</li> <li>If-Range</li> <li>If-Unmodified-Since</li> <li>Max-Forwards</li> <li>Proxy-Authorization</li> <li>Range</li> <li>Referer</li> <li>TE</li> </ul>"},{"location":"tech-notes/test-automation-basics/#an-optional-request-body","title":"An optional request body","text":"<ul> <li>_Request body may either be in the form of XML or JSON</li> </ul>"},{"location":"tech-notes/test-automation-basics/#https-response","title":"HTTPS Response","text":"<ol> <li>A status.</li> <li>Collection of Headers.</li> <li>A Body.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#restassured-without-static-imports","title":"RestAssured without Static imports","text":"<pre><code>import org.testng.Assert;\nimport org.testng.annotations.Test;\nimport io.restassured.RestAssured;\nimport io.restassured.response.Response;\nimport io.restassured.response.ValidatableResponse;\nimport io.restassured.specification.RequestSpecification;\n\npublic class WithoutBDDStyle {\n\nstatic RequestSpecification requestSpecification;\nstatic Response response;\nstatic ValidatableResponse validatableResponse;\n\n@Test\npublic void oldMethodOfRestAssured() {\nRestAssured.baseURI = \"http://dummy.restapiexample.com/api/v1/employees\";\n// Create a request specification\nrequestSpecification = RestAssured.given();\n// Calling GET method\nresponse = requestSpecification.get();\n// Let's print response body.\nSystem.out.println(response.prettyPrint());\n// Validate Response\nvalidatableResponse = response.then();\n// Get status code\nvalidatableResponse.statusCode(200);\n// Check status line is as expected\nvalidatableResponse.statusLine(\"HTTP/1.1 200 OK\");\n}\n\n@Test\npublic void oldMethodOfRestAssuredUsingTestNG() {\nRestAssured.baseURI = \"http://dummy.restapiexample.com/api/v1/employees\";\n// Create a request specification\nrequestSpecification = RestAssured.given();\n// Calling GET method\nresponse = requestSpecification.get();\n// Let's print response body.\nSystem.out.println(response.prettyPrint());\n// Get status line\nAssert.assertEquals(response.getStatusLine(), \"HTTP/1.1 200 OK\");\n// Get status code\nAssert.assertEquals(response.getStatusCode(), 200);\n}\n}\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#restassured-withstatic-imports-bdd-style","title":"RestAssured withStatic imports BDD style","text":""},{"location":"tech-notes/test-automation-basics/#example_1","title":"Example","text":"<ul> <li>Resource URL: https://bookstore.toolsqa.com/</li> <li>Parameter: BookStore/v1/Books</li> </ul>"},{"location":"tech-notes/test-automation-basics/#characteristics-of-rest","title":"Characteristics of REST","text":"<ul> <li>Uniform interface</li> <li>Client Server separation</li> <li>Stateless</li> <li>Layered System</li> <li>Cacheable</li> <li>Code-on-demand(Eg - Flash Video Player)</li> </ul>"},{"location":"tech-notes/test-automation-basics/#rest-api-connectors","title":"Rest API Connectors","text":"<ol> <li>_Client </li> <li>_Server </li> <li>_Cache </li> <li>_Resolver </li> <li>_Tunnel </li> </ol>"},{"location":"tech-notes/test-automation-basics/#components-in-rest","title":"Components in Rest","text":"<ol> <li>_Origin Server </li> <li>_User Agent </li> <li>_Gateway </li> <li>_Proxy </li> </ol>"},{"location":"tech-notes/test-automation-basics/#rest-data-elements","title":"Rest Data Elements","text":"<ol> <li>Resource</li> <li>Resource Identifier(URI)</li> <li>Resource Metadata</li> <li>Representation (Entire Request or Response)</li> <li>Representation Metadata(Headers- content-type, content-length, User-Agent, Connection, Accept-Encodin)</li> </ol> <p>Query Parameter And Path Parameter JsonPath  XmlPath</p>"},{"location":"tech-notes/test-automation-basics/#create-json-object-with-json-simple","title":"Create Json Object with Json Simple","text":"<pre><code>&lt;!-- https://mvnrepository.com/artifact/com.googlecode.json-simple/json-simple --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;com.googlecode.json-simple&lt;/groupId&gt;\n    &lt;artifactId&gt;json-simple&lt;/artifactId&gt;\n    &lt;version&gt;1.1.1&lt;/version&gt;\n&lt;/dependency&gt;\n\n</code></pre> <pre><code>JSONObject requestParams = new JSONObject(); \nrequestParams.put(\"userId\", \"TQ123\"); \nrequestParams.put(\"isbn\", \"9781449325862\"); \nJSONObject.toJSONString()\nrequest.header(\"Content-Type\", \"application/json\"); \nrequest.body(requestParams.toJSONString());\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#serialization","title":"Serialization","text":"<p>Serialization is a process where you convert an Instance of a Class (Object of a class) into a Byte Stream. This Byte Stream can then be stored as a file on the disk or can also be sent to another computer via the network. Deserialisation in Opposite of Serialization.</p> <p></p> <pre><code>ObjectOutputStream o = new ObjectOutputStream(new FileOutputStream(\"//File Name\"));\n\nAnimal animal = new Animal(\"Cow\");\n\no.writeObject(animal);\no.close();\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#deserialization","title":"Deserialization","text":"<pre><code>FileInputStream fileStream = new FileInputStream(new File(fileName));\nObjectInputStream objectStream = new ObjectInputStream(fileStream);\nObject deserializeObject = objectStream.readObject();\nobjectStream.close();\nfileStream.close();\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#authentication","title":"Authentication","text":"<ul> <li>Being able to authenticate with Credentials</li> </ul>"},{"location":"tech-notes/test-automation-basics/#basic-authenticationauth","title":"Basic Authentication(Auth)","text":"<ul> <li>Does using Authentication headers. ie username and Password is sent in the URL.</li> </ul> <pre><code>given().auth().basic(\"your username\", \"your password\").get(\"your end point URL\");\n</code></pre> <p>Challenge Response Mechanism This means that it waits for the server to challenge rather than send the credentials directly.</p> <pre><code>given().auth().preemptive().basic(\"your username\", \"your password\").get(\"your end point URL\");\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#digest-authentication","title":"Digest Authentication","text":"<p>It uses a digestive key in subsequent requests. If at all it is intercepted by an eavesdropper, he will get access only to the transaction performed and not the user password.</p> <pre><code>given().auth().digest(\"your username\", \"your password\").get(\"your end point URL\")\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#form-authentication","title":"Form Authentication","text":"<pre><code>given() .auth().form(\"your username\", \"your password\").post(\"your end point URL\")\n</code></pre> <pre><code>given().auth().form(\"your username\", \"your password\", new FormAuthConfig(\"/perform_signIn\",\"user\",\"password\"))\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#oauth-authentication","title":"OAuth Authentication","text":"<pre><code>//Oauth 1\ngiven().auth().oauth(consumerKey, consumerSecret, accessToken, tokenSecret).get(\"your end point URL\")\n// Oauth 2 \ngiven().auth().oauth2(\"Access token\").get(\"your end point URL\")\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#authorisation","title":"Authorisation","text":"<ul> <li>Being able to provide valid access. ie (Admin and Employee users )</li> </ul>"},{"location":"tech-notes/test-automation-basics/#put-request","title":"Put Request","text":"<p>OST request</p> <ul> <li>201 with a location header pointing to the new resource.</li> <li>400 if the new item is not created.</li> </ul> <p>PUT request</p> <ul> <li>204 for OK/SUCCESS (but no content).</li> <li>200 for OK with Content Body (Updated response).</li> <li>400 if the data sent was invalid. https://toolsqa.com/rest-assured/put-request-using-rest-assured/</li> </ul>"},{"location":"tech-notes/test-automation-basics/#to-be-continued","title":"To Be continued","text":"<p>https://toolsqa.com/rest-assured/delete-request-using-rest-assured/ https://qaautomation.expert/2023/10/12/rest-assured-tutorials/</p>"},{"location":"tech-notes/test-automation-basics/#jira-practice-apis","title":"Jira Practice Api's","text":"<p>Jira Api's for practice</p> <p>Jira Docker Image</p> <p>Cookie-based authentication Api</p> <p>API Reference</p> <p>Session Filter explanation </p> <p>Attachment and Multipart upload </p> <p>Extract Response as using extract().asString()</p> <p>HTTPs relaxed https certifications</p>"},{"location":"tech-notes/test-automation-basics/#oaath-20","title":"OAath 2.0","text":"<p>Access token clinet ID , google sign in  Grant type(autherisation code and client credentials)</p> <ol> <li>Hitting the Access Code URL and getting the access code </li> <li>Hitting the Access Token URL and getting the Access Token </li> <li>Hitting the actual request with the access token</li> </ol> <p></p> <p>TOken in Response  </p> <p></p> <p> </p> <p> Access Code</p> <p></p> <p>Access Token </p> <p></p> <p>Actual Request </p> <p>Client Credential </p> <p></p> <p></p> <pre><code>https://qaautomation.expert/2023/10/12/rest-assured-tutorials/\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#serialisation-and-deserialisation-using-pojo","title":"Serialisation and Deserialisation using POJO","text":""},{"location":"tech-notes/test-automation-basics/#request-response-spec-builder","title":"Request Response Spec Builder","text":""},{"location":"tech-notes/test-automation-basics/#jwt-token-restassured","title":"JWT token RestAssured","text":""},{"location":"tech-notes/test-automation-basics/#form-data","title":"Form data","text":"<p>Using Rest Assured  </p> <p></p> <p>Loggig  </p>"},{"location":"tech-notes/test-automation-basics/#rest-assured-framework","title":"Rest Assured Framework","text":""},{"location":"tech-notes/test-automation-basics/#dependency","title":"Dependency","text":"<ol> <li>Rest Assured dependency includes JsonPath and XmlPath</li> <li> <p>Rest Assured's dependency declaration comes before (JUnit or TestNG) dependency to make sure that the correct version of Hamcrest is used </p> </li> <li> <p>JsonPath: Used for parsing and extracting data from JSON responses.</p> </li> <li>XmlPath: Used for parsing and manipulating XML responses.</li> <li>Hamcreast is used for assertions.</li> <li>json-schema-validator is used for validating Json Schema    Jacson     Gson</li> </ol>"},{"location":"tech-notes/test-automation-basics/#static-imports","title":"Static Imports","text":"<pre><code>import io.restassured.RestAssured.*;\nimport io.restassured.matcher.RestAssuredMatchers.*;\nimport org.hamcrest.Matchers.*;\nimport io.restassured.module.jsv.JsonSchemaValidator.*;\n\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#robot-framework","title":"Robot Framework","text":"<ul> <li>Getting Started guide</li> <li>Reference Documentation</li> </ul>"},{"location":"tech-notes/test-automation-basics/#installation","title":"Installation","text":"<pre><code>cd ~/MyProject\npyenv global 3.10.6 # use specific python version \npyenv local 3.10.6 \n# Create Environment\npython -m venv .venv\n# Activate Environment\nsource .venv/bin/activate\n# deactivate Environment\nsource .venv/bin/deactivate\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#poetry-maven-for-python","title":"Poetry Maven for Python","text":"<ul> <li>Introduction</li> <li>Poetry Commands</li> </ul> <p>Poetry is a tool for dependency management and packaging in Python. It allows you to declare the libraries your project depends on and it will manage (install/update) them for you. Poetry offers a lockfile to ensure repeatable installs, and can build your project for distribution.</p> <pre><code>pipx install poetry # Install Poetry\npoetry new poetry-demo # Create Poetry Project\npoetry run # runnning files ising poetry \npoetry init # Make a folder poetry project\npoetry shell # installs dependencies and activates environment\ndeactivate # when run in poetry shell deactivates the evironment\nexit # Removes the poetry shell\npoetry build\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#ui-libraries","title":"UI Libraries","text":"<ul> <li>Selenium Library<ul> <li>explicit locator strategy or implicit XPath strategy,</li> <li>Chaining locators ie: css:.bar &gt;&gt; xpath://a</li> </ul> </li> </ul> <p>In Robot Framework, which is a keyword-driven test automation framework, you can use SeleniumLibrary to interact with web browsers, and when dealing with web elements, locators play a crucial role. Chaining locators in Robot Framework with SeleniumLibrary allows you to create more specific and flexible locators by combining multiple locator strategies.</p> <p>Here's an example to illustrate chaining locators in Robot Framework using SeleniumLibrary:</p> <pre><code>*** Settings ***\nLibrary           SeleniumLibrary\n\n*** Test Cases ***\nChaining Locators Example\n    Open Browser    https://example.com    chrome\n    ${element}=    Chain Locators    css:div#container    xpath://a[@id='link']\n    Click Element    ${element}\n    Capture Page Screenshot\n    Close Browser\n</code></pre> <p>In this example:</p> <ol> <li><code>Open Browser</code> opens the Chrome browser and navigates to the specified URL.</li> <li><code>Chain Locators</code> is used to create a more specific locator by chaining two locators together. The first part of the chain is a CSS locator (<code>css:div#container</code>), and the second part is an XPath locator (<code>xpath://a[@id='link']</code>). The resulting <code>${element}</code> will be a combination of these locators.</li> <li><code>Click Element</code> uses the <code>${element}</code> locator to click on the specific element on the web page.</li> <li><code>Capture Page Screenshot</code> takes a screenshot for verification purposes.</li> <li><code>Close Browser</code> closes the browser.</li> </ol> <p>This is just a basic example, and you can chain different types of locators based on your needs. Keep in mind that while chaining locators can be powerful, it's essential to ensure that the combined locators uniquely identify the desired element on the web page. Additionally, consider the maintainability of your tests, as overly complex locators can make your test scripts harder to understand and maintain.</p> <ul> <li>Browser Library</li> </ul>"},{"location":"tech-notes/test-automation-basics/#rest-libraries","title":"Rest Libraries","text":"<ul> <li>Requests Library</li> </ul>"},{"location":"tech-notes/test-automation-basics/#desktop-libraries","title":"Desktop Libraries","text":"<ul> <li>FlaUI</li> <li>Sikuli Library</li> <li>White Library</li> <li>RPA Framework</li> <li>ImageHorizon Library</li> <li>Zoomba Library</li> <li>AutoIT Library</li> <li> <ul> <li>RemoteSwing Library</li> </ul> </li> <li>Swing Library</li> <li>Eclipse Library</li> <li>RPA Framework JavaAccessBridge</li> </ul>"},{"location":"tech-notes/test-automation-basics/#mobile-libraries","title":"Mobile Libraries","text":"<ul> <li>Appium Library</li> </ul>"},{"location":"tech-notes/test-automation-basics/#database-library","title":"Database Library","text":"<ul> <li>Database Library</li> </ul>"},{"location":"tech-notes/test-automation-basics/#standard-library","title":"Standard Library","text":"<ul> <li>Standard Library</li> </ul>"},{"location":"tech-notes/test-automation-basics/#project-structure","title":"Project Structure","text":"<ul> <li><code>pyproject.toml</code> - Python dependencies</li> <li><code>Readme.md</code> - Project description</li> <li><code>.gitignore</code> - Lists files and folders to be ignored by git</li> <li><code>tests/</code> - Test Suites folder      <code>search.robot</code> - Test Suite for Search functionality      <code>login.robot</code> - Test Suite for Log In functionality      <code>checkout/</code> - Folder containing Test Suites for Checkout          <code>checkout_basic.robot</code> - Test Suites for standard Checkout          <code>checkout_premium.robot</code> - Test Suites for premium Checkout</li> <li><code>resources/</code> - Reusable keywords      <code>common.robot</code> - General Keywords (e.g. Login/Logout, Navigation, ...) are stored here      <code>search.robot</code> - Keywords for searching are stored here      <code>utils.py</code> - Python helper keywords are stored here</li> </ul>"},{"location":"tech-notes/test-automation-basics/#my_project-structure","title":"my_project Structure","text":"<pre><code>\u251c\u2500\u2500 tests\n\u2502   \u251c\u2500\u2500 suiteA.robot\n\u2502   \u251c\u2500\u2500 suiteB.robot\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \n\u251c\u2500\u2500 resources\n\u2502   \u251c\u2500\u2500 common.resource\n\u2502   \u251c\u2500\u2500 some_other.resource\n\u2502   \u251c\u2500\u2500 custom_library.py\n\u2502   \u251c\u2500\u2500 variables.py\n\u2502   \u251c\u2500\u2500 ...\n\u2502\n\u251c\u2500\u2500 .gitlab-ci.yml\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#import-custom-keywords","title":"Import custom keywords","text":"<p>*** Settings *** Resource  resources/common.resource Resource  resources/some_other.resource Library   resources/custom_library.py Variables resources/variables.py ...</p>"},{"location":"tech-notes/test-automation-basics/#running-python-tests","title":"Running Python Tests","text":"<pre><code>robot --pythonpath . tests/suiteA.robot\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#using-pythonpath-environment-variable","title":"Using <code>PYTHONPATH</code> environment variable","text":"<pre><code>$ export PYTHONPATH=$PYTHONPATH:.\n$ robot tests/suiteA.robot\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#file-and-folders","title":"File and Folders","text":"<ul> <li>A test case file automatically creates a test suite containing the test cases in that file.</li> <li>Test libraries containing the lowest-level keywords.</li> <li>Resource files with variables and higher-level user keywords.</li> <li>Variable files to provide more flexible ways to create variables than resource files.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#robot-documentation-using-restructuredtext","title":"Robot Documentation using RestructuredText","text":"<ul> <li>.robot, rst extension can be used to create restructured text</li> </ul> <pre><code>reStructuredText example\n------------------------\n\nThis text is outside code blocks and thus ignored.\n\n.. code:: robotframework\n\n   *** Settings ***\n   Documentation    Example using the reStructuredText format.\n   Library          OperatingSystem\n\n   *** Variables ***\n   ${MESSAGE}       Hello, world!\n\n   *** Test Cases ***\n   My Test\n       [Documentation]    Example test.\n   Log    ${MESSAGE}\n   My Keyword    ${CURDIR}\n\n   Another Test\n   Should Be Equal    ${MESSAGE}    Hello, world!\n\nAlso this text is outside code blocks and ignored. Code blocks not\ncontaining Robot Framework data are ignored as well.\n\n.. code:: robotframework\n\n   # Both space and pipe separated formats are supported.\n\n   | *** Keywords ***  |                        |         |\n   | My Keyword        | [Arguments]            | ${path} |\n   |                   | Directory Should Exist | ${path} |\n\n.. code:: python\n\n   # This code block is ignored.\n   def example():\n       print('Hello, world!')\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#variables","title":"Variables","text":"<p>1.\u00a0Scalar\u00a0(Identifier: $) \u2013 The most common way to use variables in Robot Framework test data is using the scalar variable syntax like\u00a0${var}. When this syntax is used, the variable name is replaced with its value as-is.</p> <p>2.\u00a0List\u00a0(Identifier: @) \u2013 If a variable value is a list or list-like, a list variable like\u00a0@{EXAMPLE}\u00a0is used. In this case, the list is expanded, and individual items are passed in as separate arguments.</p> <p>3.\u00a0Dictionary\u00a0(Identifier: &amp;) \u2013 A variable containing a Python dictionary or a dictionary-like object can be used as a dictionary variable like\u00a0&amp;{EXAMPLE}. In practice, this means that the dictionary is expanded and individual items are passed as named arguments to the keyword.</p> <p>4.\u00a0Environment\u00a0(Identifier: %) \u2013 Robot Framework allows using environment variables in the test data using the syntax\u00a0%{ENV_VAR_NAME}. They are limited to string values.</p> <pre><code>`*** Variables ***`\n\n`${STRING}\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 cute name\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 #Scalar`\n\n`${INT_AS_STRING}`\u00a0\u00a0\u00a0 `1`\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 `#Scalar`\n\n`${INT_AS_INT}\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ${``1``}\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 #Scalar`\n\n`${FLOAT}\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ${``3.14``}\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 #Scalar`\n\n`@{LIST}\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 one\u00a0\u00a0\u00a0 two\u00a0\u00a0\u00a0 three`\n\n`&amp;{DICTIONARY}\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 string=name`\u00a0\u00a0\u00a0 `int``=${``1``}\u00a0\u00a0\u00a0 list=@{LIST}`\n\n`${ENVIRONMENT}\u00a0\u00a0\u00a0\u00a0\u00a0 %{PATH}`\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#jira","title":"Jira","text":""},{"location":"tech-notes/test-automation-basics/#agile-projects","title":"Agile Projects","text":""},{"location":"tech-notes/test-automation-basics/#agile-workflow","title":"Agile Workflow","text":""},{"location":"tech-notes/test-automation-basics/#agile-key-points","title":"Agile Key points","text":"<ol> <li>Interaction over tools. </li> <li>working software over documentation.</li> <li>Customer collaboration over budget negotiation.</li> <li>Responding to change as per plan changes.</li> <li>Delivering software quickly in incremental model.</li> <li>Business folks and Developer works closely.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#sprint-artifacts","title":"Sprint Artifacts","text":"<ol> <li>Product Backlog</li> <li>Sprint Backlog</li> <li>Burn down chart</li> </ol>"},{"location":"tech-notes/test-automation-basics/#sprint-ceremonies","title":"Sprint Ceremonies","text":"<ol> <li>Sprint Planning</li> <li>Daily Scrum Meeting</li> <li>Sprint Review</li> <li>Sprint Retro</li> </ol>"},{"location":"tech-notes/test-automation-basics/#kanban-vs-scrum","title":"Kanban vs Scrum","text":"<ol> <li>No Sprint backlog in Kanban</li> <li>There is no process in Kanban </li> <li>Scrum has a fixed timeline</li> </ol>"},{"location":"tech-notes/test-automation-basics/#issue-workflow","title":"Issue WorkFlow","text":"<ol> <li>New </li> <li>InProgress</li> <li>Done</li> </ol>"},{"location":"tech-notes/test-automation-basics/#issue-estimates","title":"Issue Estimates","text":"<ol> <li>by hours </li> <li>by story points</li> </ol>"},{"location":"tech-notes/test-automation-basics/#jira-roles","title":"Jira Roles","text":"<ol> <li>Global</li> <li>Project Specific roles</li> </ol>"},{"location":"tech-notes/test-automation-basics/#createing-custom-issue-type-called-scheme","title":"Createing custom issue type called scheme","text":""},{"location":"tech-notes/test-automation-basics/#createing-custom-fileds","title":"Createing custom fileds","text":""},{"location":"tech-notes/test-automation-basics/#createing-custom-workflows","title":"Createing custom workflows","text":""},{"location":"tech-notes/test-automation-basics/#default-assignee-can-be-set-too","title":"Default Assignee can be set too","text":""},{"location":"tech-notes/test-automation-basics/#componenets-can-be-created-to-device-the-responsibility-to-specific-team-its-exactly-like-a-configuration-item","title":"Componenets can be created to device the responsibility to specific team (Its exactly like a configuration Item)","text":""},{"location":"tech-notes/test-automation-basics/#edge-test-cases","title":"Edge Test cases","text":"<ol> <li>Out of the box test cases</li> </ol>"},{"location":"tech-notes/test-automation-basics/#jira-introduction","title":"Jira Introduction","text":"<ol> <li>Bug Tracking</li> <li>Issue Tracking</li> <li>Project Management</li> <li>Requirements Management</li> <li>HelpDesk</li> <li>Generate Reports</li> <li>Customised Issues </li> <li>Customs Notifications</li> <li>Powerfull Search functionality</li> <li>Extensible</li> </ol>"},{"location":"tech-notes/test-automation-basics/#waterfall-project","title":"Waterfall Project","text":""},{"location":"tech-notes/test-automation-basics/#waterfall-key-points","title":"Waterfall key points","text":"<ol> <li>Time to market is high</li> <li>Final application might not be what customer wanted. </li> <li>Changing the requirements midway is difficult.</li> <li>Not suitable for project where requirements keeps on changing.</li> <li>Better Documentation.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#issue-workflow_1","title":"Issue WorkFlow","text":"<ol> <li>New </li> <li>Work</li> </ol>"},{"location":"tech-notes/test-automation-basics/#issue-estimates_1","title":"Issue Estimates","text":"<ol> <li>by hours </li> <li>by story points</li> </ol>"},{"location":"tech-notes/test-automation-basics/#roles","title":"Roles","text":"<ol> <li>Global</li> <li>Project Specific roles</li> </ol>"},{"location":"tech-notes/test-automation-basics/#createing-custom-issue-type-called-scheme_1","title":"Createing custom issue type called scheme","text":""},{"location":"tech-notes/test-automation-basics/#createing-custom-fileds_1","title":"Createing custom fileds","text":""},{"location":"tech-notes/test-automation-basics/#createing-custom-workflows_1","title":"Createing custom workflows","text":""},{"location":"tech-notes/test-automation-basics/#default-assignee-can-be-set-too_1","title":"Default Assignee can be set too","text":""},{"location":"tech-notes/test-automation-basics/#componenets-can-be-created-to-device-the-responsibility-to-specific-team-its-exactly-like-a-configuration-item_1","title":"Componenets can be created to device the responsibility to specific team (Its exactly like a configuration Item)","text":""},{"location":"tech-notes/test-automation-basics/#edge-test-cases_1","title":"Edge Test cases","text":""},{"location":"tech-notes/test-automation-basics/#jira-introduction_1","title":"Jira Introduction","text":"<ol> <li>Bug Tracking</li> <li>Issue Tracking</li> <li>Project Management</li> <li>Requirements Management</li> <li>HelpDesk</li> <li>Generate Reports</li> <li>Customized Issues </li> <li>Custome Notifications</li> <li>Powerfull Search functionality</li> <li>Extincible</li> </ol> <p>xray  zaphyr</p> <p>AGILE + JIRA : Agenda: Tester/Developer day to day role in Agile Scrum Projects How to Use Jira tool for Project Management and its related activities</p> <p>We shall assume Credit card online Banking Application to Demonstrate above topics</p> <p>Features to Develop:     \u2022   Develop Login Module     \u2022   Credit card Dashboard      \u2022   Profile</p> <p>Install Jira into Machines</p> <pre><code>\u2022   What Constitutes Agile Team?\n</code></pre> <p>Product owner,Scrum Master, Development team(Dev,QA,BA)     \u2022   Create Scrum Project in Jira.     \u2022   what is epic?\u2028An\u00a0epic\u00a0user story is a large that cannot be delivered as defined within a single iteration or is large enough that it can be split into smaller user stories     \u2022   What is User story?     \u2022   A user story is the smallest unit of work in an agile framework.     \u2022   Epics are large work items broken down into a set of stories,      \u2022   The purpose of a user story is articulate how a piece of work will deliver a particular value back to the customer.     \u2022   User stories are a few sentences in simple language that outline the desired outcome     \u2022   Requirements are added later, once agreed upon by the team.     \u2022   User stories are often expressed in a simple sentence, structured as follows:</p> <p>\u201cAs a [persona], I [want to], [so that How to create Stories and Epics in JIRA? What are components and how to create them in JIRA? What are release versions?</p> <p>What is backlog refinement/Grooming? And how it is done? 1 week before sprint starts Have it in the middle of sprint and make stories for next sprint 1 week before Sprint 2 starts      \u2022   How to define Acceptance criteria to Story?     \u2022   Create SubTasks for Story     \u2022   Size the story based on its complexity</p> <pre><code>\u2022   what is Sprint?\n</code></pre> <p>25 userstories to complete login epic 2 months \u2013 6 Sprints Sprint duration of 10days: 5 user Sprint 2: 5 us SPrin3 : 5us Sprint 4 : 5 Sprint 5 : 5 Sprint 6 : Regression testing </p> <pre><code>\u2022   What is Sprint planning?\n</code></pre> <p>Sprint starts :Tuesday </p> <pre><code>\u2022   Exploring Scrum Board \n\u2022   Daily Stand ups.\n\u2022   How story will undergo different status and get closed?\n\u2022   Reports after Sprint is completed.\n</code></pre> <p>info@qaclickacademy.com</p> <pre><code>   Reporting Bugs in Jira\n\u2022   Retrospective\n</code></pre> <p>What went well in this sprint What did not go well in this sprint Grooming      \u2022   Kanban Board</p> <p>Software Testing Life Cycle \u2013 STLC Testing is not only limited just to find bugs but has a wider scope and is required right from the beginning of the project when the requirements are not even finalized. Since testing is also standardized. Just like development of software has a lifecycle, Testing too has a lifecycle Requirement Analysis The QA team will interact with various stakeholders (Client, Business Analyst, Technical Leads, System Architects etc.) to understand the requirements in detail. Test Planning Test Planning is most important phase of Software testing life cycle where all testing strategy is defined. How to prepare Test Plan &amp; Strategy? Test Case Development: This is the phase of STLC where testing team write down the detailed test cases. Along with test cases testing team also prepare the test data if any required for testing. Once the test cases are ready then these test cases are reviewed by peer members or QA lead. Also, the Requirement Traceability Matrix (RTM) is prepared. The Requirement Traceability Matrix is an industry-accepted format for tracking requirements where each test case is mapped with the requirement. Using this RTM, we can track backward &amp; forward traceability. Test Environment Setup Test environment decides the software and hardware conditions under which a work product is tested. Test environment set-up is one of the critical aspects of testing process Test Execution During this phase, the testers will carry out the testing based on the test plans and the test cases prepared. Bugs will be reported back to the development team for correction and retesting will be performed. Test Closure Activities Test closure activities are done mostly after the product is delivered Test closure activities mainly comprise of four types: Ensure Test Completion Handover Test Artifacts Project Retrospectives Archive Test Work Products What is Test Plan? Test plan is a document which contains the plan related to all testing activities which needs to be done to deliver a quality product. This document is prepared after analyzing Business requirements of the Project It is usually prepared by the Test Lead or Senior QA in Agile team The focus of the document is to describe what to test, (In Scope for testing) what cannot be tested, Tools used for Testing, Environments/Infrastructure required to Test Staffing and Training Needs Testing Duration Risks and contingencies plan Business Requirements: Req 1: Submit the Form Req 2: Navigate to the tabs present on home page Req 3: select the products and add to cart Req 4: Added items in cart should display in Checkout page Req 5: Select the country to deliver before Purchase Req 6: Complete purchase by providing payment details and generate receipt</p>"},{"location":"tech-notes/test-automation-basics/#testing","title":"Testing","text":""},{"location":"tech-notes/test-automation-basics/#ad-hoc-testing","title":"Ad-hoc Testing","text":"<ul> <li>Purpose: Ad-hoc testing is an informal, unscripted approach to testing where testers explore the application without any predefined test cases or plans. The primary goal is to find defects and understand the system's behavior quickly.</li> <li>Scope: Ad-hoc testing is not structured and does not follow a specific test script or test case. Testers rely on their experience and intuition to uncover issues in the software.</li> <li>Execution Time: Ad-hoc testing can be performed at any stage of the testing process. It is often used for quick, unplanned checks to identify issues that might have been missed during structured testing.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#exploratory-testing","title":"Exploratory Testing","text":"<ul> <li>Purpose: Exploratory testing is a testing approach where testers simultaneously design and execute test cases based on their real-time understanding of the application. It is a dynamic and flexible way of exploring the software.</li> <li>Scope: In exploratory testing, testers create test cases on the fly, using their domain knowledge and experience to investigate the application thoroughly. The focus is on uncovering defects, understanding the system's behavior, and identifying risks.</li> <li>Execution Time: Exploratory testing can be performed throughout the testing process. Testers adapt their testing approach based on what they discover as they explore the application.</li> </ul> <p>In summary, both ad-hoc testing and exploratory testing are unscripted, informal testing approaches that rely on the tester's intuition and experience. Ad-hoc testing is often unplanned and used to quickly identify issues, while exploratory testing is a more structured approach where testers design and execute test cases in real-time to gain a deeper understanding of the software's behavior and uncover defects.</p>"},{"location":"tech-notes/test-automation-basics/#black-box-testing","title":"Black Box Testing","text":"<ul> <li>Purpose: Black Box Testing is a testing approach that focuses on evaluating the functionality of a software application without examining its internal code, structure, or logic. Testers treat the software as a \"black box\" and assess it based on its inputs, outputs, and behavior.</li> <li>Scope: Black Box Testing is concerned with testing the software from the user or end-user perspective. It assesses whether the software functions as expected and delivers the desired results without understanding the internal workings.</li> <li>Test Cases: Test cases in black box testing are designed based on requirements, specifications, or user stories. Testers validate that the software performs the correct functions and produces the expected outputs.</li> <li>Types: Common types of black box testing include Functional Testing, Non-Functional Testing (e.g., usability, performance, security), and Acceptance Testing.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#white-box-testing","title":"White Box Testing","text":"<ul> <li>Purpose: White Box Testing, also known as Glass Box Testing or Structural Testing, examines the internal structure, code, and logic of the software application. Testers assess how well the code is written and whether it meets coding standards and design specifications.</li> <li>Scope: White Box Testing focuses on the internal workings of the software, including code paths, statements, and data flows. Testers assess the logical aspects of the software to identify coding errors, vulnerabilities, and areas that need improvement.</li> <li>Test Cases: Test cases in white box testing are designed based on knowledge of the internal code structure. Testers assess code coverage, branch conditions, and logical paths to ensure thorough testing of the software's logic.</li> <li>Types: White Box Testing includes techniques like Statement Coverage, Branch Coverage, Path Coverage, and Code Review.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#key-differences","title":"Key Differences","text":"<ul> <li>Black Box Testing assesses the software's functionality from a user's perspective, while White Box Testing examines the internal code and structure of the software.</li> <li>Black Box Testers do not need knowledge of the internal code, whereas White Box Testers require in-depth knowledge of the code to design test cases.</li> <li>Test cases in Black Box Testing are based on requirements and specifications, while test cases in White Box Testing focus on code coverage and logical paths.</li> <li>Both types of testing are essential, with Black Box Testing ensuring that the software meets user requirements and White Box Testing verifying the quality of the code and logic.</li> </ul> <p>In summary, Black Box Testing evaluates the functionality of the software without considering its internal code, while White Box Testing examines the internal structure, logic, and code of the software to ensure it is well-structured and adheres to coding standards. Both types of testing are integral to ensuring software quality and reliability.</p>"},{"location":"tech-notes/test-automation-basics/#component-vs-integration-testing","title":"Component vs Integration Testing","text":"<p>Integration Testing and Component Testing are two essential levels of testing in the software development process, each with a specific focus and purpose. Here are notes on both integration testing and component testing:</p> <p>Component Testing: - Purpose: Component Testing, also known as Unit Testing, focuses on testing individual software components or units in isolation to verify their correctness and functionality. - Scope: Component Testing is concerned with testing a specific module, class, or function without considering its interactions with other parts of the system. - Test Cases: Test cases in component testing are designed to test the smallest units of code, ensuring that they produce the expected results when provided with specific inputs. - Environment: Component testing typically takes place in a controlled and isolated development or testing environment. - Testing Tools: Automated testing tools are often used to run unit tests to validate the behavior of code components. - Benefits: Component testing helps identify and fix bugs at an early stage, ensuring that individual code units work correctly. It is essential for maintaining code quality.</p> <p>Integration Testing: - Purpose: Integration Testing is focused on verifying that multiple software components or modules work correctly when combined or integrated. It ensures that the interactions between components do not introduce defects. - Scope: Integration Testing examines the interaction between various modules, subsystems, or components to verify that they function as a cohesive whole. - Test Cases: Test cases in integration testing are designed to assess the interfaces and interactions between components, testing how data and control flow between them. - Environment: Integration testing often requires a more comprehensive testing environment that simulates the entire system or at least a substantial portion of it. - Types: Common types of integration testing include Top-Down Integration, Bottom-Up Integration, and Big Bang Integration, each focusing on a different approach to integrating components. - Benefits: Integration testing helps identify issues related to component interactions, such as data flow, interface mismatches, and communication problems. It ensures that the integrated system behaves as expected.</p> <p>Key Differences: - Component testing evaluates individual code components in isolation, while integration testing assesses the interactions and interfaces between these components. - Component testing is typically conducted by developers during the coding phase, while integration testing is performed as part of the broader testing process. - Component testing helps ensure that the building blocks of the software are sound, while integration testing ensures that these building blocks work together harmoniously.</p> <p>In summary, component testing focuses on individual code units, ensuring their correctness and functionality, while integration testing verifies that multiple components interact correctly when integrated into a larger system. Both types of testing are critical for ensuring that a software system operates as intended.</p>"},{"location":"tech-notes/test-automation-basics/#defect-lifecycle","title":"Defect LifeCycle","text":"<p>The Defect Lifecycle, also known as the Bug Lifecycle or Issue Lifecycle, outlines the stages a defect or issue goes through from its discovery to its resolution. Understanding this lifecycle is crucial for efficient defect management. Here are notes on the typical stages of the Defect Lifecycle:</p> <p>1. Defect Identification: - Discovery: A defect is discovered during testing, user feedback, or any phase of software development. - Logging: The defect is logged in a defect tracking system, often referred to as a bug tracking tool or issue tracking tool. It includes details like the defect's description, steps to reproduce, and its severity.</p> <p>2. Defect Triage: - Assessment: The defect is assessed to determine its validity and severity. It may be assigned a priority based on its impact on the software. - Assignment: The defect is assigned to the responsible individual or team (usually a developer or tester) who will investigate and address it.</p> <p>3. Defect Resolution: - Investigation: The assigned person investigates the defect to understand its root cause. This may involve reviewing code, system logs, and relevant documents. - Fixing: Once the cause is identified, the developer fixes the defect by modifying the code, configuration, or other relevant aspects. - Verification: The tester verifies the fix by retesting the software to ensure that the defect is resolved. - Validation: The defect is validated to ensure that the fix does not introduce new issues or negatively impact other parts of the software.</p> <p>4. Defect Closure: - Documentation: If the defect is fixed and verified successfully, it is marked as \"closed\" in the defect tracking system. This includes documenting details of the fix and verification. - Closure Report: A closure report may be generated, summarizing the defect's history and resolution, to help in knowledge sharing and future reference.</p> <p>5. Defect Reopening (if necessary): - Rejection: If the defect reappears or is not fixed correctly, it may be reopened with detailed information about the regression. - Repeat Process: The defect is reassigned for investigation, fixing, and retesting. The lifecycle stages may be repeated until the defect is finally resolved and verified.</p> <p>6. Defect Reporting: - Communication: The status of defects and their resolutions are communicated to relevant stakeholders, including project managers, developers, testers, and other team members.</p> <p>Key Points: - Defects may vary in severity, priority, and complexity, which impacts the time they spend in each lifecycle stage. - A well-organized defect tracking system and effective communication are essential for managing defects throughout their lifecycle. - Documentation is crucial at each stage to maintain a record of the defect's history and resolution.</p> <p>In summary, the Defect Lifecycle ensures a systematic approach to managing defects, from their identification to their resolution and closure. This process helps maintain software quality and provides transparency in defect management.</p>"},{"location":"tech-notes/test-automation-basics/#functional-vs-non-functional","title":"Functional vs Non Functional","text":"<p>Functional Testing and Non-Functional Testing are two essential categories of software testing, each serving a distinct purpose. Here are notes about both types of testing:</p>"},{"location":"tech-notes/test-automation-basics/#functional-testing","title":"Functional Testing","text":"<ul> <li>Purpose: Functional Testing is focused on verifying that the software's functions work as intended and conform to the specified requirements. It aims to ensure that the system performs its intended operations correctly.</li> <li>Scope: Functional Testing tests the application's features, such as user interfaces, data processing, business logic, and functionality. It is concerned with \"what\" the software should do.</li> <li>Test Cases: Test cases in functional testing are designed based on the functional specifications and use cases, checking whether the software meets the expected behavior and produces correct outputs.</li> <li>Types: Common types of functional testing include Unit Testing, Integration Testing, System Testing, and Acceptance Testing. Each type of functional testing covers different levels of the application, from individual units to the entire system.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#non-functional-testing","title":"Non-Functional Testing","text":"<ul> <li>Purpose: Non-Functional Testing focuses on evaluating the non-functional aspects of software, such as performance, usability, security, and reliability. It assesses how well the system performs its operations under different conditions.</li> <li>Scope: Non-Functional Testing addresses \"how\" the software operates, considering attributes like speed, efficiency, user experience, security, and scalability.</li> <li>Test Cases: Test cases in non-functional testing are designed to measure and assess the qualities mentioned above. These test cases do not typically involve functionality but rather focus on metrics and characteristics of the software.</li> <li>Types: Non-Functional Testing includes various types, such as Performance Testing (including load, stress, and scalability testing), Usability Testing, Security Testing, Reliability Testing, and Compatibility Testing. Each type assesses specific non-functional attributes of the software.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#key-differences_1","title":"Key Differences","text":"<ul> <li>Functional testing ensures that the software performs its intended functions correctly, while non-functional testing assesses how well the software operates under various conditions.</li> <li>Functional testing focuses on specific features and functionality, while non-functional testing evaluates characteristics like performance, security, and user experience.</li> <li>Test cases in functional testing check what the software should do, while test cases in non-functional testing assess how well it does it.</li> <li>Both types of testing are essential for comprehensive quality assurance, as they ensure that the software not only functions correctly but also meets the necessary performance, security, and user experience standards.</li> </ul> <p>In summary, functional testing concentrates on the features and functionality of the software, whereas non-functional testing evaluates non-functional attributes like performance, usability, and security. Both types of testing are vital to ensuring that the software meets user expectations and quality standards.</p>"},{"location":"tech-notes/test-automation-basics/#load-vs-stress-testing","title":"Load vs Stress Testing","text":""},{"location":"tech-notes/test-automation-basics/#load-testing","title":"Load Testing:","text":"<ul> <li>Purpose: Load Testing is a type of performance testing that assesses how a system or application performs under normal or expected load conditions.</li> <li>Scope: It involves testing the system with a specific load level that simulates typical user activity and usage patterns.</li> <li>Objectives: The primary goal of load testing is to ensure that the system can handle its expected load without performance degradation.</li> <li>Test Conditions: Load tests may include concurrent user actions, data input, or transaction processing typical of regular system usage.</li> <li>Performance Metrics: Load testing measures performance indicators such as response times, throughput, and resource utilization.</li> <li>Benefits: Load testing helps identify performance bottlenecks and capacity limitations, allowing for optimization before deployment.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#stress-testing","title":"Stress Testing:","text":"<ul> <li>Purpose: Stress Testing is a type of performance testing that evaluates how a system behaves under extreme conditions, beyond its normal operational limits.</li> <li>Scope: It involves testing the system with higher-than-expected load levels or by deliberately overloading it.</li> <li>Objectives: The primary goal of stress testing is to identify the system's breaking point or to observe how it behaves under exceptional conditions.</li> <li>Test Conditions: Stress tests may include sudden spikes in user activity, excessive data loads, or resource exhaustion scenarios.</li> <li>Performance Metrics: Stress testing may focus on assessing the system's behavior during and after a stress event, looking for issues like crashes or data corruption.</li> <li>Benefits: Stress testing helps identify vulnerabilities and weaknesses in the system, enabling proactive mitigation and disaster recovery planning.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#key-differences_2","title":"Key Differences:","text":"<ul> <li>Load testing assesses how a system performs under expected or typical load conditions, while stress testing evaluates its behavior under extreme and abnormal conditions.</li> <li>Load testing is primarily concerned with ensuring performance under normal user activity, while stress testing seeks to find the system's limits and how it behaves when those limits are exceeded.</li> <li>Load testing helps optimize the system for expected traffic, while stress testing helps identify vulnerabilities and weaknesses in the face of unexpected events or extreme usage.</li> </ul> <p>In summary, load testing ensures that a system can handle typical loads, while stress testing explores how the system behaves under extreme conditions or unexpected events. Both types of testing are essential for assessing a system's robustness and performance under different scenarios.</p>"},{"location":"tech-notes/test-automation-basics/#priority-vs-severity","title":"Priority vs Severity","text":""},{"location":"tech-notes/test-automation-basics/#bug","title":"Bug","text":"<ul> <li>Priority (Bug): Priority for a bug determines the order in which the bug should be fixed, based on its importance and impact. For example, \"High\" priority bugs need to be addressed immediately, \"Medium\" priority bugs can be addressed after high-priority ones, and \"Low\" priority bugs can be deferred.</li> <li>Severity (Bug): Severity characterizes the seriousness of the bug, taking into account its potential impact on the system or users. For instance, \"Critical\" severity bugs are show-stoppers that render the system unusable, \"Major\" severity bugs significantly affect functionality, and \"Minor\" severity bugs have minimal impact.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-case","title":"Test Case","text":"<ul> <li>Priority (Test Case): Priority for a test case determines the order in which the test case should be executed during testing. \"High\" priority test cases are executed early to verify critical functionalities, \"Medium\" priority test cases are important but not critical, and \"Low\" priority test cases are executed later for less critical features.</li> <li>Severity (Test Case): Severity for a test case characterizes the criticality of the scenario it covers. \"Critical\" severity test cases are essential for the system to function properly, \"Major\" severity test cases are important but not show-stoppers, and \"Minor\" severity test cases cover non-critical or cosmetic aspects.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#user-story-agile-development","title":"User Story (Agile Development):","text":"<ul> <li>Priority (User Story): Priority for a user story in an Agile context determines its importance and order in the product backlog. It guides the development team on which stories to work on next. For example, \"High\" priority user stories are essential for the next sprint, \"Medium\" priority stories are important but not urgent, and \"Low\" priority stories can be addressed later.</li> <li>Severity (User Story): In the context of user stories, severity might not be a commonly used term. Instead, user stories often focus on the value they bring to the user or the business, which can be labeled as \"High Value,\" \"Medium Value,\" or \"Low Value.\"</li> </ul> <p>In Agile development, user stories are typically prioritized based on business value, customer needs, and other factors, and the concept of severity is not as relevant as in the context of testing. However, user stories can still be assigned a priority to determine their order of implementation in an Agile backlog.</p>"},{"location":"tech-notes/test-automation-basics/#retesting-vs-regression-testing","title":"Retesting vs Regression Testing","text":""},{"location":"tech-notes/test-automation-basics/#retesting","title":"Retesting","text":"<ul> <li>Purpose: Retesting is a type of testing that focuses on verifying that a specific defect, which was found and fixed in a previous testing phase, has been successfully rectified. The primary goal is to ensure that the reported issue no longer exists.</li> <li>Scope: Retesting is narrow in scope and typically involves executing the same test cases that initially revealed the defect. It doesn't explore new areas of the application, focusing solely on the fixed issue.</li> <li>Execution Time: Retesting is performed after the defect has been fixed, and it aims to validate the resolution quickly. It is a targeted and focused activity.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#regression-testing","title":"Regression Testing","text":"<ul> <li>Purpose: Regression testing is a testing approach that aims to ensure that recent changes or new features introduced into the software do not adversely affect existing, stable functionalities. It verifies that the application still works as expected after modifications.</li> <li>Scope: Regression testing is broader in scope and involves re-running a subset of existing test cases (both related to the changes and critical core functionalities) to detect unintended side effects or regressions.</li> <li>Execution Time: Regression testing is performed whenever there are code changes, new feature additions, or updates to the application. It's an ongoing process throughout the software development lifecycle.</li> </ul> <p>In summary, retesting and regression testing serve different purposes and have distinct scopes. Retesting is specific to validating the resolution of a known defect, while regression testing is a broader, ongoing effort to ensure that new changes do not introduce unintended issues in the existing, stable areas of the application.</p>"},{"location":"tech-notes/test-automation-basics/#sdlc-vs-stlc","title":"SDLC vs STLC","text":"<p>Software Development Life Cycle (SDLC) and Software Testing Life Cycle (STLC) are two distinct but interconnected processes in the software development and testing industry. Here are notes about both SDLC and STLC:</p>"},{"location":"tech-notes/test-automation-basics/#software-development-life-cycle-sdlc","title":"Software Development Life Cycle (SDLC)","text":"<ul> <li>Purpose: SDLC is a systematic process for planning, designing, developing, testing, and delivering software applications. It provides a structured approach to building software products, ensuring quality and meeting project objectives.</li> <li>Scope: SDLC encompasses the entire software development process, from initial requirements gathering and design to coding, testing, deployment, and maintenance.</li> <li>Phases: Common SDLC phases include Requirements Gathering, Planning, Design, Implementation (Coding), Testing, Deployment, and Maintenance.</li> <li>Methodologies: Various methodologies, such as Waterfall, Agile (e.g., Scrum), and DevOps, define the approach and order of these phases, emphasizing different aspects like sequential planning (Waterfall) or iterative development (Agile).</li> <li>Key Documents: SDLC produces various documents, including requirement specifications, design documents, codebase, and deployment plans.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#software-testing-life-cycle-stlc","title":"Software Testing Life Cycle (STLC)","text":"<ul> <li>Purpose: STLC is the process of planning, designing, executing, and evaluating testing activities throughout the software development life cycle. It ensures that software is thoroughly tested to meet quality and performance requirements.</li> <li>Scope: STLC specifically focuses on the testing phase of SDLC, covering various levels (unit, integration, system, acceptance) and types of testing (functional, non-functional).</li> <li>Phases: STLC typically consists of phases such as Test Planning, Test Design, Test Execution, Defect Reporting, and Test Closure.</li> <li>Methodologies: STLC operates within the framework of SDLC methodologies. For instance, in Agile SDLC, testing activities are incorporated into each sprint or iteration.</li> <li>Key Documents: STLC generates test documentation, including test plans, test cases, test data, defect reports, and test summary reports.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#key-differences_3","title":"Key Differences","text":"<ul> <li>SDLC encompasses the entire software development process, while STLC is specifically concerned with testing activities within SDLC.</li> <li>SDLC focuses on planning, design, coding, and overall software development, whereas STLC emphasizes testing strategy, test case creation, and test execution.</li> <li>SDLC can use various development methodologies (Waterfall, Agile), while STLC adapts to the chosen development methodology, ensuring testing aligns with the development process.</li> <li>In SDLC, the end goal is to deliver a working software product, while in STLC, the goal is to verify and validate the quality of the software through comprehensive testing.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#integration","title":"Integration","text":"<ul> <li>STLC is an integral part of SDLC. Testing activities are carried out in parallel with development activities, ensuring that testing is a continuous and concurrent process.</li> <li>STLC helps verify that software meets the quality standards set during the development phases of SDLC.</li> </ul> <p>In summary, SDLC represents the entire software development process, while STLC specifically focuses on the testing phase within SDLC. Both are crucial for delivering high-quality software products that meet user requirements and perform reliably.</p>"},{"location":"tech-notes/test-automation-basics/#smoke-vs-sanity","title":"Smoke vs Sanity","text":""},{"location":"tech-notes/test-automation-basics/#smoke-testing","title":"Smoke Testing","text":"<ul> <li>Purpose: Smoke testing, also known as build verification testing, is a preliminary test that checks whether the software build is stable enough for more comprehensive testing. It helps ensure that the critical functionalities of the application work without major issues.</li> <li>Scope: Smoke tests cover a basic set of test cases that exercise core features and critical paths of the software. These tests do not aim to explore all functionalities but focus on essential functionality.</li> <li>Execution Time: Smoke tests are quick to execute and are typically run after a new build is deployed. If a build fails the smoke test, it indicates that there are severe defects that need immediate attention.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#sanity-testing","title":"Sanity Testing","text":"<ul> <li>Purpose: Sanity testing is a subset of regression testing that focuses on verifying that specific code changes or new features have not adversely affected the existing, stable functionalities of the application. It ensures that the recent modifications have not introduced unexpected issues.</li> <li>Scope: Sanity tests are narrower in scope than comprehensive regression tests. They concentrate on the areas of the application affected by recent changes or enhancements.</li> <li>Execution Time: Sanity tests are relatively quick and are typically performed during the later stages of the testing cycle, after more extensive testing has taken place.</li> </ul> <p>In summary, both smoke testing and sanity testing are important types of software testing, but they serve different purposes and are conducted at different stages of the testing process. Smoke testing determines whether a newly built application is fit for further testing, while sanity testing verifies that specific changes or new features have not broken the existing, stable parts of the application. Both testing types are designed to catch critical issues early in the development cycle.</p>"},{"location":"tech-notes/test-automation-basics/#test-case-vs-scenario-vs-step","title":"Test Case vs Scenario vs Step","text":""},{"location":"tech-notes/test-automation-basics/#test-scenario","title":"Test Scenario","text":"<ul> <li>Definition: A test scenario is a high-level description of a specific function or feature to be tested.</li> <li>Purpose: Test scenarios provide a broad overview of what needs to be tested without going into detailed steps. They help in understanding the scope of testing for a particular feature.</li> <li>Example: A test scenario for a login feature might be \"Verify that users can successfully log in using valid credentials.\"</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-case_1","title":"Test Case","text":"<ul> <li>Definition: A test case is a detailed set of conditions, inputs, and expected results that specify how to test a particular aspect of a software application.</li> <li>Purpose: Test cases are specific and actionable instructions for executing tests. They provide step-by-step guidance to testers to verify whether the software functions correctly.</li> <li>Example: A test case for the login feature mentioned earlier might include steps like \"Enter valid username and password\" and the expected result of \"Successfully logged in.\"</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-step","title":"Test Step","text":"<ul> <li>Definition: A test step is a single action or instruction within a test case, defining what the tester needs to do and what is expected to happen.</li> <li>Purpose: Test steps break down a test case into individual, discrete actions. They provide a clear, sequential path for the tester to follow.</li> <li>Example: In the test case for the login feature, each step is a test step. For example, \"Enter username\" and \"Enter password\" would be individual test steps within the test case.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#differences","title":"Differences","text":"<ul> <li>Test Scenario is high-level and provides an overview, whereas Test Case is detailed and provides specific steps.</li> <li>Test Scenario doesn't include specific instructions or expected outcomes, while Test Case provides precise instructions and expected results.</li> <li>Test Case consists of multiple Test Steps, which are individual actions to be performed during testing.</li> <li>Test Scenarios are typically used for test planning and requirement analysis, while Test Cases are used for actual testing execution.</li> <li>Test Scenarios help in creating an initial test plan, while Test Cases ensure systematic and comprehensive testing of specific functionalities.</li> </ul> <p>In summary, test scenarios help you understand what needs to be tested at a high level, test cases provide the detailed steps and expected results for testing, and test steps break down those test cases into individual actions. All three are essential for effective and structured software testing.</p>"},{"location":"tech-notes/test-automation-basics/#test-pyramid","title":"Test Pyramid","text":"<p>The Test Pyramid strategy is designed to guide software development teams on how to structure their automated testing efforts efficiently by categorizing tests into three layers, forming a pyramid-like shape. The goal is to achieve a balanced approach to testing while ensuring thorough coverage and faster feedback.</p> <p>The three layers of the Test Pyramid are:</p> <ol> <li>Unit Tests (Base of the Pyramid):</li> <li>Unit tests are the foundation of the pyramid and should form the majority of your automated tests.</li> <li>These tests focus on verifying the smallest units of code, such as individual functions or methods.</li> <li>Unit tests are fast to execute, easy to maintain, and provide immediate feedback to developers.</li> <li> <p>They help catch and fix bugs early in the development process, ensuring code correctness at the lowest level.</p> </li> <li> <p>Integration Tests (Middle of the Pyramid):</p> </li> <li>Integration tests validate the interactions and integration between various components or modules of the software.</li> <li>These tests check how different units work together and whether they communicate correctly.</li> <li>Integration tests are broader in scope than unit tests but more focused than end-to-end tests.</li> <li> <p>They help uncover issues related to data flow, communication, and system integration.</p> </li> <li> <p>End-to-End Tests (Top of the Pyramid):</p> </li> <li>End-to-end tests, also known as UI tests or acceptance tests, validate the functionality of the entire application from the user's perspective.</li> <li>These tests simulate real user interactions with the application, including user interface interactions and workflows.</li> <li>End-to-end tests are the slowest and most brittle of the three layers, making them the most expensive to maintain and execute.</li> <li>They are essential for ensuring that the entire application functions correctly and that all components work together seamlessly.</li> </ol> <p>The key principles of the Test Pyramid strategy are as follows: - Prioritize writing a large number of fast and reliable unit tests to cover the majority of your codebase. - Use integration tests to validate that components and modules interact correctly. - Limit the number of end-to-end tests to focus on critical user scenarios and workflows.</p> <p>The Test Pyramid strategy helps strike a balance between test coverage, execution speed, and maintenance efforts. By emphasizing unit tests at the base of the pyramid, teams can catch and fix defects early in the development process, resulting in more robust and maintainable software. Integration and end-to-end tests serve as safety nets to ensure that the application functions correctly as a whole, without sacrificing the efficiency of the testing process.</p> <p></p>"},{"location":"tech-notes/test-automation-basics/#testcase-example","title":"TestCase Example","text":"<p>TestCase Example</p>"},{"location":"tech-notes/test-automation-basics/#test-case-identifier","title":"Test Case Identifier","text":"<ul> <li>A unique identifier or name for the test case, often using a numbering or naming convention for easy reference.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-case-title","title":"Test Case Title","text":"<ul> <li>A brief and descriptive title that summarizes the purpose of the test case.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#objective","title":"Objective","text":"<ul> <li>A clear statement of the specific objective or goal of the test case.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#prerequisites","title":"Prerequisites","text":"<ul> <li>Any preconditions or setup requirements that must be met before the test case can be executed.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-data","title":"Test Data","text":"<ul> <li>Details about the data, inputs, or conditions to be used in the test case.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-steps","title":"Test Steps","text":"<ul> <li>A step-by-step list of actions to be performed during the test, including specific instructions, input data, and expected outcomes for each step.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#expected-results","title":"Expected Results","text":"<ul> <li>The expected outcomes or behavior at the end of each test step. This helps in determining whether the test case passed or failed.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-environment","title":"Test Environment","text":"<ul> <li>Information about the test environment, including hardware, software, configurations, and tools required to execute the test case.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-execution","title":"Test Execution","text":"<ul> <li>Guidance on how the test case should be executed, including the order of test steps and any specific conditions for execution.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-passfail-criteria","title":"Test Pass/Fail Criteria","text":"<ul> <li>Clear criteria that define when the test case is considered a pass or a fail, based on the actual results compared to the expected results.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-data-setupcleanup","title":"Test Data Setup/Cleanup","text":"<ul> <li>Details on how test data should be prepared before the test and how any cleanup activities should be performed after the test.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-dependencies","title":"Test Dependencies","text":"<ul> <li>Any dependencies on other test cases, test scenarios, or external systems that the test case relies on.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#defect-references","title":"Defect References","text":"<ul> <li>Links or references to any related defects or issues in the defect tracking system, if applicable.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-case-author","title":"Test Case Author","text":"<ul> <li>The name or identification of the person responsible for creating and maintaining the test case.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-case-reviewer","title":"Test Case Reviewer","text":"<ul> <li>The name of the person who reviewed and verified the accuracy of the test case.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-case-status","title":"Test Case Status","text":"<ul> <li>The current status of the test case, which can indicate whether it is in draft, approved, executed, or completed.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-case-priority","title":"Test Case Priority","text":"<ul> <li>The priority of the test case, which can help in test execution scheduling.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#attachments","title":"Attachments","text":"<ul> <li>Any additional documentation, screenshots, diagrams, or files that are relevant to the test case.</li> </ul> <p>A well-structured test case document provides a clear and detailed description of how a particular functionality or aspect of the software should be tested. It helps testers understand what to test, how to test it, and what to expect as results, ensuring consistent and thorough testing throughout the project.</p>"},{"location":"tech-notes/test-automation-basics/#testplan-example","title":"TestPlan Example","text":"<p>TestPlan Example</p>"},{"location":"tech-notes/test-automation-basics/#introduction","title":"Introduction","text":"<ul> <li>Overview of the document.</li> <li>Purpose and scope of the test plan.</li> <li>Identification of the project or system being tested.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-objectives","title":"Test Objectives","text":"<ul> <li>Clear and concise statement of what the testing aims to achieve.</li> <li>Specific goals and desired outcomes.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-strategy","title":"Test Strategy","text":"<ul> <li>Description of the overall approach to testing, including the testing methods and techniques that will be used.</li> <li>Information on testing levels (e.g., unit testing, integration testing, system testing) and the order in which they will be conducted.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-scope","title":"Test Scope","text":"<ul> <li>Detailed information on what aspects of the system will be tested and what will not be tested.</li> <li>Inclusion and exclusion criteria for the scope of testing.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-deliverables","title":"Test Deliverables","text":"<ul> <li>List of documents and artifacts that will be produced during the testing process, such as test cases, test scripts, test data, and test reports.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-schedule","title":"Test Schedule","text":"<ul> <li>Timelines and milestones for the testing activities.</li> <li>Sequence and dependencies of testing phases.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#resource-requirements","title":"Resource Requirements","text":"<ul> <li>Identification of the people, tools, hardware, and software needed for testing.</li> <li>Allocation of roles and responsibilities for the testing team.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#risks-and-assumptions","title":"Risks and Assumptions","text":"<ul> <li>Identification of potential risks and challenges that could impact the testing process.</li> <li>Assumptions made during the test planning.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-environment_1","title":"Test Environment","text":"<ul> <li>Description of the test environment, including hardware, software, network configurations, and any other specific setups required for testing.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-data_1","title":"Test Data","text":"<ul> <li>Details on the test data needed for the test cases.</li> <li>How the test data will be created, obtained, or generated.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-execution_1","title":"Test Execution","text":"<ul> <li>Procedures for executing test cases, including the order and frequency of test runs.</li> <li>Entry and exit criteria for each test phase.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-reporting","title":"Test Reporting","text":"<ul> <li>Explanation of how test results will be recorded, tracked, and reported.</li> <li>Templates for test summary reports or defect reports.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#defect-management","title":"Defect Management","text":"<ul> <li>Procedures for logging, tracking, and managing defects.</li> <li>Severity and priority definitions for defects.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#change-control","title":"Change Control","text":"<ul> <li>How changes to the test plan or the scope of testing will be managed and documented.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#approval-and-sign-off","title":"Approval and Sign-Off","text":"<ul> <li>Identification of stakeholders who need to review and approve the test plan.</li> <li>Sign-off process to ensure that all parties are in agreement.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#appendices","title":"Appendices","text":"<ul> <li>Any supplementary information, such as glossaries, references, or additional details.</li> </ul> <p>A well-structured and thorough test plan provides a clear roadmap for the testing process, ensuring that all stakeholders understand the objectives, scope, and logistics of the testing effort. It helps maintain consistency and quality in testing activities and serves as a reference throughout the testing project.</p>"},{"location":"tech-notes/test-automation-basics/#levels-of-testing","title":"Levels of Testing","text":"<p>Unit Testing, Integration Testing, System Testing, and Acceptance Testing are different levels of software testing that serve distinct purposes in the software development and quality assurance process. Here are similar notes on each type of testing:</p>"},{"location":"tech-notes/test-automation-basics/#unit-testing","title":"Unit Testing","text":"<ul> <li>Purpose: Focuses on testing individual components or functions of the software in isolation.</li> <li>Scope: Tests the smallest units of code, such as functions, methods, or classes.</li> <li>Isolation: Tests are independent and isolated from the rest of the system.</li> <li>Test Data: Typically uses mock objects or stubs to simulate dependencies.</li> <li>Speed: Fast execution, suitable for continuous integration.</li> <li>Developers are primarily responsible for writing unit tests.</li> <li>Aims to catch and fix bugs early in the development process.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#integration-testing","title":"Integration Testing","text":"<ul> <li>Purpose: Validates the interactions and interfaces between different software components or modules.</li> <li>Scope: Tests the connections and integration points between units.</li> <li>**May involve testing API endpoints, data exchanges, or communication between modules.</li> <li>Focuses on ensuring that integrated components work together correctly.</li> <li>Helps detect issues related to data flow, interface compatibility, and component communication.</li> <li>Performed by developers and testing teams.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#system-testing","title":"System Testing","text":"<ul> <li>Purpose: Evaluates the entire software system as a whole, including all integrated components.</li> <li>Scope: Tests the software in its complete and functional state.</li> <li>**Ensures that the system meets its specified requirements and functions correctly.</li> <li>Covers functional and non-functional testing aspects, such as performance, security, and usability.</li> <li>Typically conducted by dedicated testing teams.</li> <li>Helps identify system-level issues, such as incorrect behavior or performance bottlenecks.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#acceptance-testing","title":"Acceptance Testing","text":"<ul> <li>Purpose: Validates that the software meets the specified business requirements and user expectations.</li> <li>Scope: Focuses on user scenarios, workflows, and user acceptance criteria.</li> <li>Typically involves end-to-end testing and often includes user interface (UI) testing.</li> <li>Performed by stakeholders, including product owners, business analysts, or end-users.</li> <li>Ensures that the software is ready for production release and fulfills its intended purpose.</li> <li>Helps to gain confidence in the software's readiness for deployment.</li> </ul> <p>In summary, these testing levels gradually progress from testing individual code units to validating the entire software system against specified requirements. Each level serves a unique purpose in ensuring the quality and reliability of the software. Unit testing focuses on small code units, integration testing ensures component interactions, system testing assesses the complete system, and acceptance testing verifies that the software aligns with user expectations and business needs.</p>"},{"location":"tech-notes/test-automation-basics/#traceability-matrix-example","title":"Traceability Matrix Example","text":"<p>Traceability Matrix Example</p> <p>A Requirement Traceability Matrix (RTM) is a critical document used in software development and testing to ensure that all requirements are covered and that testing efforts are aligned with those requirements. Here are notes about the Requirement Traceability Matrix:</p>"},{"location":"tech-notes/test-automation-basics/#requirement-traceability-matrix-rtm","title":"Requirement Traceability Matrix (RTM)","text":"<ul> <li>Purpose: An RTM is a tool used to track and manage the relationship between requirements, test cases, and other project artifacts. It ensures that each requirement is associated with corresponding test cases, helping to maintain transparency and coverage in the testing process.</li> <li>Scope: RTM focuses on the mapping of requirements to various test levels and types, including unit testing, integration testing, system testing, and user acceptance testing.</li> <li>Elements: An RTM typically contains rows representing requirements and columns representing test cases. The cells of the matrix indicate the mapping or coverage of specific requirements by the corresponding test cases.</li> <li>Usage: RTMs are used to verify that all requirements are tested and to trace test cases back to their corresponding requirements. They also assist in identifying gaps, redundancies, or inconsistencies in requirements and testing efforts.</li> <li>Key Documents: In addition to requirements and test cases, RTMs may include other documents such as change requests, defects, and design documents to track relationships.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#key-aspects","title":"Key Aspects","text":"<ul> <li>Bidi\u00adrectional Tracing: RTMs enable both forward tracing (from requirements to test cases) and backward tracing (from test cases to requirements).</li> <li>Coverage Analysis: RTMs help in assessing the extent of requirement coverage by test cases, highlighting untested or partially tested requirements.</li> <li>Change Impact Analysis: When requirements change, RTMs aid in identifying the impact on test cases, facilitating efficient updates to test scripts.</li> <li>Verification: RTMs help ensure that the project complies with defined requirements and standards.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#benefits","title":"Benefits","text":"<ul> <li>Improved Requirement Management: RTMs enhance requirement visibility and help in managing changes and updates.</li> <li>Enhanced Testing Efficiency: Testers can easily verify that all requirements are tested without omissions.</li> <li>Change Management: When requirements change, RTMs facilitate tracking and managing changes and their effects on testing.</li> <li>Gap Identification: RTMs can expose gaps or inconsistencies in requirements or test coverage.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#challenges","title":"Challenges","text":"<ul> <li>Maintaining Consistency: Keeping the RTM up-to-date with changing requirements or test cases can be challenging.</li> <li>Time-Consuming: Creating and maintaining a detailed RTM can be time-intensive, especially for large projects.</li> </ul> <p>In summary, an RTM is a valuable document that ensures requirements are adequately covered by test cases, enhancing the quality and effectiveness of testing efforts. It serves as a bridge between requirements and testing, making it easier to manage changes, verify compliance, and maintain consistency throughout the software development and testing process.</p>"},{"location":"tech-notes/test-automation-basics/#priority-vs-severity_1","title":"Priority vs Severity","text":""},{"location":"tech-notes/test-automation-basics/#bug_1","title":"Bug","text":"<ul> <li>Priority (Bug): Priority for a bug determines the order in which the bug should be fixed, based on its importance and impact. For example, \"High\" priority bugs need to be addressed immediately, \"Medium\" priority bugs can be addressed after high-priority ones, and \"Low\" priority bugs can be deferred.</li> <li>Severity (Bug): Severity characterizes the seriousness of the bug, taking into account its potential impact on the system or users. For instance, \"Critical\" severity bugs are show-stoppers that render the system unusable, \"Major\" severity bugs significantly affect functionality, and \"Minor\" severity bugs have minimal impact.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#test-case_2","title":"Test Case","text":"<ul> <li>Priority (Test Case): Priority for a test case determines the order in which the test case should be executed during testing. \"High\" priority test cases are executed early to verify critical functionalities, \"Medium\" priority test cases are important but not critical, and \"Low\" priority test cases are executed later for less critical features.</li> <li>Severity (Test Case): Severity for a test case characterizes the criticality of the scenario it covers. \"Critical\" severity test cases are essential for the system to function properly, \"Major\" severity test cases are important but not show-stoppers, and \"Minor\" severity test cases cover non-critical or cosmetic aspects.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#user-story-agile-development_1","title":"User Story (Agile Development):","text":"<ul> <li>Priority (User Story): Priority for a user story in an Agile context determines its importance and order in the product backlog. It guides the development team on which stories to work on next. For example, \"High\" priority user stories are essential for the next sprint, \"Medium\" priority stories are important but not urgent, and \"Low\" priority stories can be addressed later.</li> <li>Severity (User Story): In the context of user stories, severity might not be a commonly used term. Instead, user stories often focus on the value they bring to the user or the business, which can be labeled as \"High Value,\" \"Medium Value,\" or \"Low Value.\"</li> </ul> <p>In Agile development, user stories are typically prioritized based on business value, customer needs, and other factors, and the concept of severity is not as relevant as in the context of testing. However, user stories can still be assigned a priority to determine their order of implementation in an Agile backlog.</p>"},{"location":"tech-notes/test-automation-basics/#security-testing","title":"Security Testing","text":""},{"location":"tech-notes/test-automation-basics/#browser-cookies","title":"Browser Cookies","text":"<p>Cookies are the small encripted text files in the browser directory.</p>"},{"location":"tech-notes/test-automation-basics/#cookies-vs-session-cookies","title":"Cookies vs Session Cookies","text":"<ol> <li>Session cookies tracks the information about the logged in session, hence the appliaction dont have to authenticate over and over again.</li> <li>Cookies stores customers web applications settings and preferences for further use.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#cookies-security","title":"Cookies Security","text":"<ol> <li>Secure Atrribute should be enabled to make sure the authentication cookies are not passed to HTTP connection calls.</li> <li>HTTP Only flag makes sure that the cookies are retried only when HTTP call is made, if there is any cross site scripting code  trying to access the cookie (like document.getCookies) then those calls will not contain the Cookies linked to them.</li> <li>Make sure that the accessed domian name in commplete so that attacker cant acess subdomains, example .accenture.com can access all the subdomans like employee.accenture.com, info.accenture.com  hence the naming for full domain will make sure that the only that domain cookies are accessed and not anything else.</li> <li>Also make sure that the path attribute is also restricted as domain/ is less secure that domain/path/path , in second case cookies are only accessed via the path specified.</li> <li>Confidential cookies should be expired frequently. And others expiry time should be set as per the requirements.(online banking cookies expiry should be set to session)</li> </ol>"},{"location":"tech-notes/test-automation-basics/#sql-basics","title":"SQL Basics","text":""},{"location":"tech-notes/test-automation-basics/#dbms-database-management-system","title":"DBMS (Database Management system)","text":""},{"location":"tech-notes/test-automation-basics/#my-sql-docker-server","title":"MY SQL Docker server","text":"<pre><code>docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#sql-login","title":"SQL login","text":"<pre><code>mysql -u&lt;username&gt; -hlocalhost/ServerIp -p\nmysql -u&lt;username&gt; -hlocalhost/ServerIp -pPassword \n</code></pre>"},{"location":"tech-notes/test-automation-basics/#importexport-table","title":"Import/Export Table","text":"<pre><code># This exports data from a table to a .sql file\nmysqldump -uroot -hlocalhost/serverIP -pPassword tableName &gt; ~/export.sql\n\n# This Imports data from .sql file to a table\n# Note that the table name you specifi should have been already created in the SQL databse\nmysql -uroot -hlocalhost/serverIP -pPassword tableName &lt; ~/export.sql\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#create-db-and-tables","title":"Create Db and Tables","text":"<pre><code># Create Database\ncreate databse DatabaseName;\n\n# Create Tables with primarykey, foreign key and constraints\ncreate table tableName (\nPrimaryKeyID int primary key auto_increment  not null,\ncolumn1 varcar(20), \ncolumn2 text unique, \ncolumn3 int default 0,\n);\nforeign key (column3) references ReferenceTableName (columnName to reference) ON DELETE CASCADE\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#list-database-and-tables","title":"List Database and Tables","text":"<pre><code># List Database\nshow database;\n\n# List Tables\nshow Tables;\n\n# List Tables with views\nshow full Tables;\n\n# Select Database\nuse Database;\n\n# List Tables\ndescribe tableName;\ndisc tableName;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#delete-database-and-tables","title":"Delete Database and Tables","text":"<pre><code># Delete Entire Database\ndrop database databaseName\n\n# This removed the entire table from the database\ndrop table tablename \n\n# This deletes a spechific row from a table with id =3\ndelete from tableName where id = 3;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#sql-data-manupulation","title":"SQL Data Manupulation","text":""},{"location":"tech-notes/test-automation-basics/#add-data-into-table","title":"Add data into table","text":"<pre><code>insert into tablename (columnName1,columnName2) values(\"Test Value\",\"Test Value2\")\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#accessing-database","title":"Accessing Database","text":"<pre><code># Show all values from the table\nselect * from tableName;\n\n# Show a specific row\nselect * from tableName where id =1;\n\n# Show count of rows\nselect count(*) from tableName;\n\n# showing non NUll values\nselect * from tableName where name is NOT NULL\n\n# Show data where age not equal to 40;\nselect * from tableName where age != 40;\n\n# Show unique rows\nselect distinct * from tableName \n\n# In operator\nselect * from tableName where  id in(1,2,3);\n\n# Between operator\nselect * from tableName where id between 1 and 10;\n\n# Get todays date year time day and week\nselect time(now()), day(now()), year(now()), week(now());\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#reguler-expression-usage","title":"Reguler expression usage","text":"<pre><code># Show rows with name starting with s + any letter + u\nselect * from tableName where (name like \"%s_u\" &amp;&amp; age &gt; 40) || (name like \"%su\" &amp;&amp; age &lt; 40) ;\n\n# Show rows with name containing letter  o\nselect * from tableName where name like \"%o%\";\n\n# Show rows with name not starting with su\nselect * from tableName where name not like \"su%\";\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#updating-database","title":"Updating Database","text":"<pre><code># Adding new column to an existing table \nalter table tableName add columnName varchar(20); \n\n# Removing a column from an existing table\nalter table tableName drop columnName\n\n# Added Foreign key to existing table (this act like Enums in db world)\nalter table tableName add constrain fk_addForeignkey foreign key (columnName) reference tablename (columnName)\n\n# Update values in existing table\nupdate tableName set columnName1 = \"Value\" where id = 1;\n\n# Add index to and existing table(this adds index to the columns rows which helps in fetching the data quickly)\nalter table tableName add index idx_index(columnName);\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#group-by-order-by-limits-union-unionall-sub-queries-views-intersect-exists-case","title":"Group By, Order by, Limits, Union, UnionAll, Sub Queries, Views, Intersect, Exists, Case","text":"<pre><code># Accending Order\nselect * from tableName order by columnName1 asc, columnName2 desc;\n\n# Decending Order\nselect * from tableName order by columnName1 desc, columnName2 desc;\n\n# Group By\nselect columnName2 from tableName where condition group by columnName2 having condition order by columnName2 asc/desc;\n\n#Limits\nselect * from TableName Limit 1, 10;\n\n# note - Both the tables needs to be similer for this to work\n# Union Rmoves duplicates while unionall doesnt \nselect * from TableName condition\nunion/union all\nselect * from TableName condition\n\n# Intersect\n# Returns values which are in both the tables \n# both the columns should be same in both the tables\n# Functionality only available in Oracle DB\nselect * from TableName condition\nintersect\nselect * from TableName condition\n# in mysql find solutions for intersect is as per below\nselect * from table1 where id in (select id from table2);\n\n# Exists\n# this runs the second query first and if that is true only then the first query is run \nselect * from table1 exists(select * from table1 where id =1);\n\n# case\nselect columns, case id \nwhen 1 then columns * 2 \nwhen 2 then columns * 4 \nelse columns\nend\n'new_column_name', column3\nfrom table\n\n\n# Sub Queries\nselect * from TableName where column in (select * from table);\n\n# View\ncreate view viewName as (your SQL query);\n# View is a virtual table whose access can be provided to restricted users(developer decides which columns to be visible in the views)\n# View creates something which looks like table but in the background it just runs the query and creates a table/view.\n# Hene views can be slow to access.\n# note - data can be inserted into the view but it will endup inserting in the main table (might not be visible in view)\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#joins","title":"Joins","text":"<pre><code># Inner Join \nselect a.columnName1 , b.columnName2 from table1 as a join table2 as b on a.columnName1 = b.columnName2;\n\n# Left Join \nselect a.columnName1 , b.columnName2 from table1 as a left join table2 as b on a.columnName1 = b.columnName2;\n\n# Right Join \nselect a.columnName1 , b.columnName2 from table1 as a right join table2 as b on a.columnName1 = b.columnName2;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#variables-and-functions","title":"Variables and Functions","text":"<pre><code># Varibale\nset @varName = \"Value\";\n\n# Function\n\n# Join Strings\nselect concat(columnName,string2,string3,and so on ...) from tableName;\n\n# Uppercase String\nselect ucase(string);\n\n# Lower case String\nselect lcase(string)\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#stored-proc","title":"Stored Proc","text":"<pre><code># running multiple qureies at ones from another application\n# Create Procedure\ncreate procedure ProcedureName(in id1 int, id2 int, title text )\nbegin\nselect id, title into @id, @title from tableName where columnName1 &lt; id1 and columnName2 &gt; id2 and columnName3 = title;\nend;\n# note - you should be using a databse for prcedures to work\n\n# Drop Procedure\ndrop prcedure ProcedureName;\n\n# invoking a procedure\ncall ProcedureName(1,2);\n\n# Create Function \n# just returns one single value\ncreate function functionName(id int, name text) returns numberic(10,2) \nbegin\n  declare results numberic(10,2);\n  select id into @results from tablename where id= 1;\n\n  return results\nend; \n\n# calling Function \nselect functionName(1,2,\"text\"); \n# functions will return one value \n\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#sql-datatypes","title":"SQL DataTypes","text":""},{"location":"tech-notes/test-automation-basics/#numeric-types","title":"Numeric Types","text":"<pre><code>INT or INTEGER: A whole number.\n\nTINYINT: A very small integer.\n\nSMALLINT: A small integer.\n\nMEDIUMINT: A medium-sized integer.\n\nBIGINT: A large integer.\n\nFLOAT: A single-precision floating-point number.\n\nDOUBLE or REAL: A double-precision floating-point number.\n\nDECIMAL or NUMERIC: A fixed-point decimal number.\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#date-and-time-types","title":"Date and Time Types","text":"<pre><code>DATE: Date in 'YYYY-MM-DD' format.\n\nTIME: Time in 'HH:MM:SS' format.\n\nDATETIME: Date and time in 'YYYY-MM-DD HH:MM:SS' format.\n\nTIMESTAMP: A timestamp representing a datetime value.\n\nYEAR: A year in 2-digit or 4-digit format.\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#string-types","title":"String Types","text":"<p>```bash CHAR: Fixed-length character string.</p> <p>VARCHAR: Variable-length character string.</p> <p>BINARY: Fixed-length binary string.</p> <p>VARBINARY: Variable-length binary string.</p> <p>TINYBLOB, TINYTEXT: Tiny binary or text data.</p> <p>BLOB, TEXT: Binary or text data of various sizes.</p> <p>MEDIUMBLOB, MEDIUMTEXT: Medium-sized binary or text data.</p> <p>LONGBLOB, LONGTEXT: Large binary or text data.</p> <p>ENUM: Enumeration of possible values.</p> <p>SET: Set of values, where each value can be selected.</p> <pre><code>\n### JSON Types\n```bash\nJSON: JSON data type for storing JSON-encoded data.\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#spatial-types","title":"Spatial Types","text":"<pre><code>GEOMETRY: For geometric shapes.\n\nPOINT: For a point in space.\n\nLINESTRING: For a series of points.\n\nPOLYGON: For a closed shape.\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#other-types","title":"Other types","text":"<pre><code>BIT: A bit field type.\n\nBOOLEAN or BOOL: A synonym for TINYINT(1).\n\nSERIAL: An alias for BIGINT UNSIGNED AUTO_INCREMENT.\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#custom-user-defined-types","title":"Custom User-Defined Types","text":"<pre><code>MySQL allows you to create your own custom data types using the CREATE TYPE statement.\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#temporal-types-introduced-in-mysql-80","title":"Temporal Types (Introduced in MySQL 8.0)","text":"<pre><code>YEAR,\nYEAR_MONTH,\nYEAR_DAY,\nMONTH_DAY,\nDAY_TIME,\nHOUR_MINUTE,\nMINUTE_SECOND,\nSECOND_MICROSECOND,\nTIME_ZONE,\nand more. These types are used for working with temporal values.\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#sql-injection","title":"SQL Injection","text":"<p>SQL injection is a type of cyberattack that occurs when an attacker inserts malicious SQL (Structured Query Language) code into a vulnerable SQL query. SQL is a language used for managing and manipulating relational databases, and SQL injection attacks take advantage of poorly sanitized or unprotected inputs in web applications or software that interact with databases.</p> <p>Here's how SQL injection works:</p> <ol> <li> <p>Vulnerable Input: In a web application, user inputs such as text fields, search boxes, or URL parameters are often used in SQL queries without proper validation or sanitization.</p> </li> <li> <p>Malicious Input: An attacker submits carefully crafted input that includes SQL code in these vulnerable input fields. For example, they might input something like <code>' OR 1=1; --</code>.</p> </li> <li> <p>Manipulating Queries: The attacker's input is then concatenated with the original SQL query executed by the application. If the application doesn't properly validate or sanitize the input, the resulting query becomes a combination of the original query and the malicious SQL code.</p> </li> <li> <p>Execution: The modified query is sent to the database server, which executes it as if it were a legitimate query. In the example above, <code>' OR 1=1; --</code>, the attacker's goal is typically to make the query always return true (1=1), allowing them to bypass authentication or access unauthorized data.</p> </li> <li> <p>Data Theft or Manipulation: Depending on the attacker's intentions, they can use SQL injection to steal, manipulate, or delete data from the database, gain unauthorized access, or even take control of the entire application.</p> </li> </ol> <p>SQL injection attacks are a significant security concern and can have severe consequences if not properly mitigated. To prevent SQL injection, developers should use techniques such as parameterized queries or prepared statements, input validation, and output encoding to ensure that user inputs are not treated as executable SQL code. Additionally, regular security testing and code reviews can help identify and address potential vulnerabilities.</p> <ol> <li>Check from the list if website can be exploited using SQL injection.</li> <li>try enterting the orderby's with column 8 randomy to know the size of table.</li> <li>try entering incorrect query to understand which sql tool is being used.</li> <li>getting all the userid's</li> </ol> <pre><code>select * from user where username = tom or 1+1;\nhttps://?tom or 1+1;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#sql-operators","title":"SQL Operators","text":""},{"location":"tech-notes/test-automation-basics/#comparision","title":"Comparision","text":"<pre><code>&gt;   Greater than operator\n\n&gt;=  Greater than or equal operator\n\n&lt;   Less than operator\n\n&lt;&gt;, !=  Not equal operator\n\n&lt;=  Less than or equal operator\n\n&lt;=&gt;     NULL-safe equal to operator\n\n=   Equal operator\n\nBETWEEN ... AND ...     Whether a value is within a range of values\n\nCOALESCE()  Return the first non-NULL argument\n\nGREATEST()  Return the largest argument\n\nIN()    Whether a value is within a set of values\n\nINTERVAL()  Return the index of the argument that is less than the first argument\n\nIS  Test a value against a boolean\n\nIS NOT  Test a value against a boolean\n\nIS NOT NULL     NOT NULL value test\n\nIS NULL     NULL value test\n\nISNULL()    Test whether the argument is NULL\n\nLEAST()     Return the smallest argument\n\nLIKE    Simple pattern matching\n\nNOT BETWEEN ... AND ...     Whether a value is not within a range of values\n\nNOT IN()    Whether a value is not within a set of values\n\nNOT LIKE    Negation of simple pattern matching\n\nSTRCMP()    Compare two strings \n</code></pre>"},{"location":"tech-notes/test-automation-basics/#logical","title":"Logical","text":"<pre><code>\nAND, &amp;&amp;     Logical AND\n\nNOT, !  Negates value\n\nOR, ||  Logical OR\n\nXOR     Logical XOR \n</code></pre>"},{"location":"tech-notes/test-automation-basics/#xss-attack","title":"XSS Attack","text":"<p>Xross site scripting also know as XSS , as one of the most common we application vulneribility that  allows attackers to run his own client side script(specially javascript) in the web page viewed by the user.</p>"},{"location":"tech-notes/test-automation-basics/#vulnerable-cases","title":"Vulnerable cases","text":"<ul> <li>Url post string </li> <li>Input Elements eg - sending html tags in the input elements.</li> <li>From submission</li> <li>Any html tags passed in the input should convert to encoded format for the website to be secure.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#reflective-xss","title":"Reflective XSS","text":"<ol> <li>This is when the passed input is only valied for the active browser session.</li> <li>Also when malessios code is entered in the input, Website should not give any indication on what are allowed  characters and patterns hence the attacker is not fully aware of the exploits.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#persistence-xss","title":"Persistence XSS","text":"<ol> <li>In Persistence XSS attack the injected script gets altered or injected on the server.</li> <li>Hence anyone can then exploit the application from any device after this attack.</li> <li>Who ever visits the website the mellisous script will get downloaded to the clients machine.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#session-hijacking-and-csrfcross-site-request-forgrery","title":"Session Hijacking and CSRF(Cross site request forgrery)","text":"<ol> <li>malicious links can be used to access saved auth cookies to access sensitive applications from your own system , so never click on a suspicious linkes.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#cryptography-tokens","title":"Cryptography tokens","text":"<ol> <li>On login two tokens gets generated</li> <li>Lets say for submitting a form attacker might be able to replicate with endpoints with params but if the form submission is using cryptographi token which was generate at the time of login will be needed to move forward. hence the attacker will not be able to attack the website.</li> <li>Confidential data should not go as a part of get request, it should alwasys go in post request.</li> <li>Request should not be successfull on manually changing the token value.</li> <li>Try hitting the token ID from another system and with other user, this should not work.</li> <li>Check if the both the Cryptography token are required not just one.</li> <li>Make sure Cryptography tokens are used for sensitive data on the website.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#bruteforce-attach-handler-mechanisim","title":"Bruteforce attach handler mechanisim","text":"<ol> <li>make sure that automation scripts to do not try cmbinations and understand the password, lock account after 3 or 5 attempts.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#references","title":"References","text":"<p>https://www.1keydata.com/sql/sql.html</p>"},{"location":"tech-notes/test-automation-basics/#xray","title":"Xray","text":""},{"location":"tech-notes/test-automation-basics/#xray-types","title":"Xray Types","text":""},{"location":"tech-notes/test-automation-basics/#xray-functionality","title":"Xray Functionality","text":""},{"location":"tech-notes/test-automation-basics/#issue-types","title":"Issue Types","text":""},{"location":"tech-notes/test-automation-basics/#issue-types-added","title":"Issue Types added","text":""},{"location":"tech-notes/test-automation-basics/#supported-frameworks","title":"Supported Frameworks","text":""},{"location":"tech-notes/test-automation-basics/#ci-support","title":"CI Support","text":""},{"location":"tech-notes/test-automation-basics/#testing-board","title":"Testing Board","text":""},{"location":"tech-notes/test-automation-basics/#testcase","title":"TestCase","text":""},{"location":"tech-notes/test-automation-basics/#sprint-board","title":"Sprint Board","text":""},{"location":"tech-notes/test-automation-basics/#reference","title":"Reference","text":"<pre><code>https://docs.getxray.app/site/xray\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#terminology","title":"Terminology","text":"Xray ISTQB Description Test Test A test case. It may either be manual or automated, composed of multiple steps, actions and expected results. test case, test scenario, test template Precondition Pre-Condition Initial conditions that must be assured before the execution of the Test's own steps. A Pre-Condition may be used by multiple Tests. Test Set Test Set A group of tests, organized in some logical way. A test may belong to multiple Test Sets. test group, test suite Test Plan Test Plan A \"formal\" plan of the tests intended to be executed for a given version. Test Execution Test Execution An assignable, \"schedulable\" task to execute one or more tests for a given version/revision along with its results. test cycle Sub-Test Execution Sub-Test Execution A Sub-Test Execution has the same functionalities as the\u00a0Test Execution\u00a0issue type. The difference between them is that the Sub-Test Execution is a\u00a0sub-task\u00a0and can be created in a\u00a0requirement's context. Creating a Test Execution as a sub-task from within the requirement issue screen will provide the user the ability to track executions on the Agile board. Test Run - A specific run of a test. An instance of the test containing the execution status and a snapshot of the test specification. Whenever a user adds a Test to a Test Execution, a test run is created internally within the Test Execution context. A test may have multiple test runs. Coverable Issue Story, requirement, Bug, .... All issues whose Issue Type is configured as being a Coverable Issue Type in Project Settings: Test Coverage. Test Status - The calculated test coverage status of a Test, for some scope (e.g., version/test plan). In the context of a Test Execution, the recorded status of a Test Run. .. Requirement Story, Requirement, .... Something that you expect from the system; a feature. A good requirement explains how the system should behave and its purpose. Test Repository - The full list of tests within a project. In Xray, the test repository is simply composed of all Test issues. Test Strategy - The requirements you want to validate, how to validate them,\u00a0use of either manual or automated tests,\u00a0the resource allocation, etc. Testing Lifecycle - After requirement specification and revision, the testing lifecyce involves test\u00a0planning, test\u00a0designing, test\u00a0execution\u00a0and test\u00a0reporting."},{"location":"tech-notes/test-automation-basics/#testcase_1","title":"TestCase","text":""},{"location":"tech-notes/test-automation-basics/#test-types","title":"Test Types","text":"<ul> <li>Cucumber: of the Gherkin Kind;</li> <li>Generic: of the Unstructured Kind;</li> <li>Manual: of the Steps Kind.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#preconditions","title":"Preconditions","text":"<ul> <li>A Precondition is like defining the step \"0\" for your tests.</li> </ul>"},{"location":"tech-notes/test-automation-basics/#precondition-types","title":"Precondition Types","text":"<pre><code>- Manual Type\n- Generic Type\n- Cucumber Type\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#cucumber","title":"Cucumber","text":""},{"location":"tech-notes/test-automation-basics/#manual-and-generic","title":"Manual and Generic","text":""},{"location":"tech-notes/test-automation-basics/#import-steps","title":"Import Steps","text":"<ul> <li>Test</li> <li>CSV</li> <li>JSON</li> <li>Clipboard</li> </ul>"},{"location":"tech-notes/test-automation-basics/#export-steps","title":"Export Steps","text":"<ul> <li>To CSV</li> </ul>"},{"location":"tech-notes/test-automation-basics/#cucumber-tests","title":"Cucumber Tests","text":""},{"location":"tech-notes/test-automation-basics/#export-to-cucumber","title":"Export to Cucumber","text":"<ol> <li>Feature file can be exported from xray itself. </li> </ol> <p> Export to Cucumber</p>"},{"location":"tech-notes/test-automation-basics/#parameterized-test","title":"Parameterized Test","text":""},{"location":"tech-notes/test-automation-basics/#datasets","title":"Datasets","text":"<p>The parameters, along with their values, are defined within a dataset. A dataset is a collection of data represented with a tabular view where every column of the table represents a particular variable (or parameter), and each row corresponds to a given record (or iteration) of the dataset.</p> <p>The number of rows in the dataset determines the number of iterations to execute. If the dataset contains a single row, there will be a single execution parameterized with the values defined on the dataset row.</p> <p>Datasets can be defined in different entities and scopes. A dataset can be defined, edited, or simply viewed using the \"Dataset\" button located in each Xray entity or scope.</p> <p></p>"},{"location":"tech-notes/test-automation-basics/#test-case-versioning","title":"Test Case Versioning","text":""},{"location":"tech-notes/test-automation-basics/#test-coverage-add-coverage","title":"Test Coverage add Coverage","text":""},{"location":"tech-notes/test-automation-basics/#test-coverage-add-defect","title":"Test Coverage add Defect","text":""},{"location":"tech-notes/test-automation-basics/#test-coverage-story","title":"Test Coverage Story","text":""},{"location":"tech-notes/test-automation-basics/#execute-tests","title":"Execute Tests","text":"<p>The easiest way to execute your tests is directly from the Test Plan, but you can also perform ad-hoc Test Executions directly from a Test, or even create a new Test Execution issue.\u00a0</p> <ol> <li>Inside the Test Plan, click on Create Test Execution.  </li> </ol> <p></p> <ol> <li>Go to Test Execution, and click on Execute (play button).  </li> </ol> <p></p> <ol> <li>You are now at the Test Execution Screen, and from here you can follow the test steps and set the execution status:\u00a0TODO,\u00a0EXECUTING,\u00a0FAIL\u00a0and\u00a0**PASS.  </li> </ol> <p></p> <ol> <li>Did you find a defect and want to report it? Create Defects from the Test Execution Screen, click on + button in the\u00a0Findings\u00a0section and select Create Defect (or expand the\u00a0Findings section and in the Defects\u00a0panel select\u00a0**Create Defect)  </li> </ol> <p> </p>"},{"location":"tech-notes/test-automation-basics/#sub-test-execution","title":"Sub Test Execution","text":"<p>A Sub-Test Execution is similar to a Test Execution, but created as a sub-task of a requirement. Normally, you will create Test Executions from Test Plans, or create ad hoc Test Executions (directly from a Test).</p>"},{"location":"tech-notes/test-automation-basics/#test-repository","title":"Test Repository","text":"<p>A project page which enables the hierarchical organisation of Tests at the project level by allowing you to organise Tests in folders and sub-folders. You can also perform several actions from this page including, creating new Tests, creating new Test Plans, Test Sets, Test Executions for a group of Tests, etc.\u00a0This is the recommended approach whenever you have a large number of Tests and want to manage them more effectively.</p>"},{"location":"tech-notes/test-automation-basics/#test-set","title":"Test Set","text":"<p>An issue type for organising tests, and it is a flat list of Tests and is a simple way to create different groups of Tests. You can easily use them to add several Tests at once into Tests Plans or Test Executions.</p>"},{"location":"tech-notes/test-automation-basics/#test-plan","title":"Test Plan","text":"<ol> <li>With Test Plans you will decide which Tests you want to perform, who will execute them and when they will be executed.  </li> <li>Also, you may want to prioritise some of the Tests and focus on specific requirements.  </li> <li>Test Plans are used to define the scope of your testing, track and consolidate the related results, no matter how many times you've run the tests.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#planning","title":"Planning","text":"<p>Planning is the activity where you decide your\u00a0testing strategy, e.g.,\u00a0 which covered issues you want to validate, how would you validate them, will it be manual or automated, how will the resources be allocated, when and who will execute the tests. Depending on several factors, you may want to prioritize some of the tests, or focus on specific requirements.\u00a0</p> <p>Although you may plan tests in different ways, we recommend that you use the\u00a0Test Plan issue specifically for this purpose.</p> <p>In your Test Plan, you can put the Tests you want to track for a given version and the Test Plan will show you the consolidated results for those Tests. In other words, it will present the latest status of each Test, independent of the number of testing iterations (i.e., Test Execution) you make with them</p>"},{"location":"tech-notes/test-automation-basics/#test-plan-steps","title":"Test Plan Steps","text":"<ol> <li>Click Create button and select Test Plan issue.</li> <li>Besides Summary, you may want to fill out the\u00a0Fix Version\u00a0to indicate that you're tracking the results of the Tests for a specific version. This only makes sense if you have multiple versions.  </li> </ol> <ol> <li>After creating the Test Plan, you can add Tests.  </li> </ol> <ol> <li>Choose the Tests you want, by using the\u00a0Select\u00a0or\u00a0Search\u00a0tabs and then selecting some or all of them.\u00a0Click\u00a0Add Selected\u00a0or\u00a0Add All.  </li> </ol>"},{"location":"tech-notes/test-automation-basics/#reports","title":"Reports","text":"<p>Xray provides several ways to make it easier for the entire team to have a clear view of the overall readiness of the project.</p> <p>As part of your daily tasks, use the dedicated reports and gadgets available in your customized dashboard to evaluate your testing progress.</p> <p>The most popular reports are:\u00a0</p> <p></p>"},{"location":"tech-notes/test-automation-basics/#zephyr","title":"Zephyr","text":""},{"location":"tech-notes/test-automation-basics/#test-case_3","title":"Test Case","text":"<p>A test artefact developed for a particular test condition, such as to exercise a particular program path or to verify compliance with a specific requirement.</p>"},{"location":"tech-notes/test-automation-basics/#test-library","title":"Test Library","text":"<p>The location where test cases are created and stored. This is also known as a test repository. Any Jira project can be a test library. Test cases are created and managed under a test library; however, you can share and reuse test cases across Jira projects when necessary to prevent duplication and increase reusability. Within a test Library, you can organize test cases by using a folder structure and categorize by using labels or custom fields.</p>"},{"location":"tech-notes/test-automation-basics/#test-script","title":"Test Script","text":"<p>A specified sequence of steps and expected results for the execution of a test case. This is also known as manual test script or test procedure specification. Zephyr Scale allows the use of traditional step-by-step as well as BDD (Gherkin syntax) and plain text scripts.</p>"},{"location":"tech-notes/test-automation-basics/#test-cycle","title":"Test Cycle","text":"<p>An ordered list of test cases assigned to testers and test environments created to achieve specific testing goals (usually a longer test run, such as regression tests, build verification tests, end-to-end tests, etc.).</p>"},{"location":"tech-notes/test-automation-basics/#test-plan_1","title":"Test Plan","text":"<p>An artefact used to track testing progress throughout an entire release or version. You can associate several test cycles to a test plan to can get real-time progress reports. Test plan fields are customizable, which allows you to track scope, risks, strategy, entry and exit criteria, test environment, test bed, and more.</p>"},{"location":"tech-notes/test-automation-basics/#test-execution-result","title":"Test Execution Result","text":"<p>A set of information that generates and is stored when a test case is executed. Data includes the tester responsible for the execution, the execution date, the defects raised, the environment and the status of the execution (e.g., passed or failed), and more.</p>"},{"location":"tech-notes/test-automation-basics/#test-environment_2","title":"Test Environment","text":"<p>A test environment is an attribute of a test execution result used to determine the environments to be tested for each test case. Planning your test environment includes defining your platform coverage, such as operational systems, browsers, databases, etc.</p> <p></p>"},{"location":"tech-notes/test-automation-basics/#settings","title":"Settings","text":""},{"location":"tech-notes/test-automation-basics/#navigation","title":"Navigation","text":"<p>https://support.smartbear.com/zephyr-scale-cloud/docs/get-started/navigation-basics.html</p>"},{"location":"tech-notes/test-automation-basics/#working-with-folders","title":"Working With Folders","text":"<p>https://support.smartbear.com/zephy-scale-cloud/docs/get-started/working-with-folders.html</p>"},{"location":"tech-notes/test-automation-basics/#workflow-strategies","title":"Workflow Strategies","text":""},{"location":"tech-notes/test-automation-basics/#testplan","title":"TestPlan","text":"<p>Test plans (groups of test cycles) are used to track testing progress throughout an entire release or version. You can link several test cycles to a test plan and get real-time progress reports when you need them. Test plan fields are customizable, which allows you to track scope, risk, strategy, entry and exit criteria, test environment, test bed, and more.</p>"},{"location":"tech-notes/test-automation-basics/#testcycle","title":"TestCycle","text":"<p>The test case stores useful information, like the tester responsible for the execution, the execution date, the defects raised, the environment used, and the status of the execution (e.g., passed, failed, etc).</p> <p></p> <p></p>"},{"location":"tech-notes/test-automation-basics/#executing-tests-from-cycle","title":"Executing Tests from Cycle","text":""},{"location":"tech-notes/test-automation-basics/#jira-zephyr-integration","title":"Jira Zephyr Integration","text":""},{"location":"tech-notes/test-automation-basics/#link-to-defect","title":"Link to Defect","text":""},{"location":"tech-notes/test-automation-basics/#testcase_2","title":"TestCase","text":""},{"location":"tech-notes/test-automation-basics/#test-data_2","title":"Test Data","text":""},{"location":"tech-notes/test-automation-basics/#parameters","title":"Parameters","text":""},{"location":"tech-notes/test-automation-basics/#modular-test-case","title":"Modular Test Case","text":""},{"location":"tech-notes/test-automation-basics/#test-case-versions","title":"Test Case Versions","text":""},{"location":"tech-notes/test-automation-basics/#bdd-tests","title":"BDD Tests","text":"<p> Select Export Feature Files (BDD - Gherkin) from More to download the feature file for your new test case (or the selected test cases).</p>"},{"location":"tech-notes/test-automation-basics/#data-driven-test","title":"Data Driven Test","text":"<p>Testdata: </p> <p>DataSet: </p>"},{"location":"tech-notes/test-automation-basics/#test-cycle_1","title":"Test Cycle","text":"<p>A test cycle is a set of test cases that are grouped to achieve specific testing goals. Test cycles can be assigned to specific testers and test environments, and they offer a comprehensive overview of coordinated testing efforts.</p>"},{"location":"tech-notes/test-automation-basics/#creating-test-cases-in-bulk","title":"Creating Test Cases in Bulk","text":""},{"location":"tech-notes/test-automation-basics/#jira-integration","title":"Jira Integration","text":""},{"location":"tech-notes/test-automation-basics/#test-execution_2","title":"Test Execution","text":""},{"location":"tech-notes/test-automation-basics/#test-execution-reports","title":"Test-Execution Reports","text":"<p>Test-execution reports provide information about the status of the testing effort, including overall software quality and test execution progress.</p> Report Title Description Test execution results (summary) Provides the summary of the test execution results (such as the overall status and progress) Test execution results (list) Provides a list of test execution results Test execution results (detailed) Provides a list of test execution results with details Test execution burn up Provides a test execution burn-up chart. Test execution burn down Provides a test execution burn-down chart. Test execution completion over time by status Provides a test execution results line and bar chart. Test execution completion over time Provides a test execution results line and bar chart (completed). Test execution completion over time by status (accumulated) Provides a test execution results line and bar chart (accumulated). Test execution effort over time Provides a test execution effort line and bar chart Test execution effort (overall) Provides a test execution effort bar chart (estimated x actual). Test execution effort by tester Provides a test execution effort by tester (estimated x actual). Test execution results (overall) Provides a test execution results gauge chart (overall). Test execution results (progress) Provides a test execution results donut chart. Test execution results by project Provides a test execution results stacked bar chart grouped by project. Test execution results by coverage Provides a test execution results stacked bar chart grouped by coverage Test execution results by test plan Provides a test execution results stacked bar chart grouped by test plan Test execution results by test cycle Provides a test execution results stacked bar chart grouped by test cycle Test execution results by tester Provides a test execution results stacked bar chart grouped by tester. Test execution results by component Provides a test execution results stacked bar chart grouped by component. Test execution results by environment Provides a test execution results stacked bar chart grouped by environment Test execution results by label Provides a test execution results stacked bar chart grouped by label Test execution results by iteration Provides a test execution results stacked bar chart grouped by iteration. Test execution results by version Provides a test execution results stacked bar chart grouped by version. Test execution results by priority Provides a test execution results stacked bar chart grouped by priority. Test execution results by type Provides a test execution results stacked bar chart grouped by test execution type (manual x automated) Test execution scorecard by test cycle Provides a test execution results scorecard broken down by test cycle Test execution scorecard by tester Provides a test execution results scorecard broken down by tester"},{"location":"tech-notes/test-automation-basics/#traceability-reports","title":"Traceability Reports","text":"<p>Traceability reports give you the ability to see coverage details from a range of helpful perspectives.</p> Report Title Description Coverage Report Displays the coverage relationship between issues (coverage) and test cases Traceability Report Provides a table of the traceability between issues (coverage), test cases, and test executions Traceability Matrix Displays the traceability matrix between test cases and issues (coverage) Traceability Tree Offers you dynamic, broad-ranging traceability and coverage statistics for all Jira issue types <p></p>"},{"location":"tech-notes/test-automation-basics/#automationframework","title":"AutomationFramework","text":"<p>![MicroFrontend.png]](/static/MicroFrontend.png)</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"tech-notes/test-automation-basics/#unit-testing_1","title":"Unit Testing","text":""},{"location":"tech-notes/test-automation-basics/#integration-testing_1","title":"Integration Testing","text":"<p>```Create MicroFrontend npx create-mf-app</p> <pre><code>\n## Cucumber\n### Basics\n\nCucumber is the BDD Framework for running automated tests. Cucumber does not Automate your testcases.\n\n![Cucumber.png](/static/Cucumber.png)\n\n### Create Cucumber Project\n```shell\nmvn archetype:generate                      \\\n   \"-DarchetypeGroupId=io.cucumber\"           \\\n   \"-DarchetypeArtifactId=cucumber-archetype\" \\\n   \"-DarchetypeVersion=7.15.0\"               \\\n   \"-DgroupId=hellocucumber\"                  \\\n   \"-DartifactId=hellocucumber\"               \\\n   \"-Dpackage=hellocucumber\"                  \\\n   \"-Dversion=1.0.0-SNAPSHOT\"                 \\\n   \"-DinteractiveMode=false\"\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#gherkin","title":"Gherkin","text":"<p>a\u00a0Business Readable, Domain Specific Language  that lets you describe software's behavior.</p>"},{"location":"tech-notes/test-automation-basics/#cucumber-terminology","title":"Cucumber Terminology","text":"<ul> <li>Scenario</li> <li>Feature</li> <li>Feature file</li> <li>Scenario outline</li> <li>Step Definition</li> </ul>"},{"location":"tech-notes/test-automation-basics/#feature","title":"Feature","text":"<pre><code>\nBackground:\n  Start Browser\n\nFeature: Test Suite \n  Scenario: test case\n    Given step with int 1\n    When step with string \"two\"\n    Then step three\n    And step four\n    Then step five\n    But step six\n\n### Step Defination\n```Cucumber\n    @Given(\"step with int {int}\")\n    public void step_with_int(Integer int1) {\n        System.out.println(\"Step 1\");\n    }\n\n    @When(\"step with string {string}\")\n    public void step_with_string(String string) {\n        System.out.println(\"Step 2\");\n    }\n\n    @Then(\"step three\")\n    public void step_three() {\n        System.out.println(\"Step 3\");\n    }\n\n    @Then(\"step four\")\n    public void step_four() {\n        System.out.println(\"Step 4\");\n    }\n\n    @Then(\"step five\")\n    public void step_five() {\n        System.out.println(\"Step 5\");\n    }\n\n    @Then(\"step six\")\n    public void step_six() {\n        System.out.println(\"Step 6\");\n    }\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#runner-file","title":"Runner File","text":"<pre><code>import io.cucumber.testng.AbstractTestNGCucumberTests;\nimport io.cucumber.testng.CucumberOptions;\n\n@CucumberOptions(\nfeatures = \"src/test/java/features\",\nglue = \"stepDefination\",\nmonochrome = true,\ntags = \"@Smoke\",\ndryrun = true,\nplugin = {\"pretty\", \"html:target/cucumber.html\",\"json:target/cucumber.json\", \"com.aventstack.extentreports.cucumber.adapter.ExtentCucumberAdapter:\" }\n)\n\npublic class smokeRunner extends AbstractTestNGCucumberTests {}\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#tags","title":"Tags","text":"<p>```Cucumber@   @Smoke   Scenario: test case     Given step with int 1</p> <p>@Regression   Scenario: test case     Given step with int 1</p> <p>@Smoke @Regression   Scenario: test case     Given step with int 1</p>"},{"location":"tech-notes/test-automation-basics/#runner-params","title":"Runner Params","text":"<p>tags = \"@Smoke\" tags = \"@Smoke and @Regression\" tags = \"@Smoke or @Regression\" tags = \"not @Smoke\"</p> <pre><code>\n### Hooks\n\n```java\npublic class hooks {\n\n    @Before\n    public void beforeAll() {\n        System.out.println(\"------------------\");\n        System.out.println(\"Before all\");\n        System.out.println(\"------------------\");\n    }\n\n    @After\n    public void afterAll() {\n        System.out.println(\"------------------\");\n        System.out.println(\"After all\");\n        System.out.println(\"------------------\");\n    }\n\n    @Before(\"@Smoke\")\n    public void beforeAllSmoke() {\n        System.out.println(\"------------------\");\n        System.out.println(\"Before all smoke\");\n        System.out.println(\"------------------\");\n    }\n\n    @After(\"@Smoke\")\n    public void afterAllSmoke() {\n        System.out.println(\"------------------\");\n        System.out.println(\"After all smoke\");\n        System.out.println(\"------------------\");\n    }\n\n}\n</code></pre> <p>cucumber dependency injection (picocontainer)</p> <p>step definition should be written using SRP (Single Responsibility Principle)</p>"},{"location":"tech-notes/test-automation-basics/#extentreports-cucumber7-adapter","title":"ExtentReports Cucumber7 Adapter","text":"<pre><code>https://ghchirp.site/3196/\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#extentproperties","title":"extent.properties","text":"<pre><code>extent.reporter.spark.start=true\nextent.reporter.spark.out=target/extentReport/report.html\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#spark-configxml","title":"Spark-config.xml","text":"<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;extentreports&gt;\n    &lt;configuration&gt;\n        &lt;!-- report theme --&gt;\n        &lt;!-- standard, dark --&gt;\n        &lt;theme&gt;dark&lt;/theme&gt;\n\n        &lt;!-- document encoding --&gt;\n        &lt;!-- defaults to UTF-8 --&gt;\n        &lt;encoding&gt;UTF-8&lt;/encoding&gt;\n\n        &lt;!-- protocol for script and stylesheets --&gt;\n        &lt;!-- defaults to https --&gt;\n        &lt;protocol&gt;https&lt;/protocol&gt;\n\n        &lt;!-- title of the document --&gt;\n        &lt;documentTitle&gt;Basic Test&lt;/documentTitle&gt;\n\n        &lt;!-- report name - displayed at top-nav --&gt;\n        &lt;reportName&gt;Report Name&lt;/reportName&gt;\n\n        &lt;!-- view report without internet --&gt;\n        &lt;offlineMode&gt;false&lt;/offlineMode&gt;\n\n        &lt;thumbnailForBase64&gt;true&lt;/thumbnailForBase64&gt;\n\n        &lt;!-- custom javascript --&gt;\n        &lt;js&gt;&lt;/js&gt;\n\n        &lt;!-- custom styles --&gt;\n        &lt;css&gt;&lt;/css&gt;\n    &lt;/configuration&gt;\n&lt;/extentreports&gt;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#take-screenshots-on-failure","title":"Take ScreenShots on failure","text":"<pre><code>    @AfterStep\n    public void takeScreenShots(Scenario scenario) throws IOException {\n        if(scenario.isFailed()) {\n            //Take Screenshot\n            byte[] screenshotFile = ((TakesScreenshot)contextManager.driverManager.getDriver()).getScreenshotAs(OutputType.BYTES);\n            //Attach to Extent report\n            scenario.attach(screenshotFile, \"image/png\", \"image\");\n        }\n    }\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#dependency-injection","title":"Dependency Injection","text":"<ol> <li>Add Cucumber picocontainer for the POM file from mvn repository.</li> <li>Create a BrowserContext class for injection.</li> </ol> <pre><code>public class BrowserContext {\n\n    public WebDriver driver;\n\n    public BrowserContext() {\n        driver = new ChromeDriver();\n    }\n\n}\n</code></pre> <ol> <li>Call the BrowserContext in stepdefinition file</li> </ol> <pre><code>public class login {\n     WebDriver driver;\n\n     public login(BrowserContext browserContext){\n         this.driver = browserContext.driver;\n     }\n}\n</code></pre> <ol> <li>You don't need to create an object of of the Browser Context class to when using picocontainer for dependency injection</li> <li>Always write step definition with SRP(Single Responsibility principal)</li> <li>Class's needs to be loosely coupled when righting step-definition.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#factory-desgin-pattern","title":"Factory Desgin Pattern","text":"<ol> <li>Create a class files with getters of all the pages in page Object class.</li> </ol> <pre><code>package pagesObject;\n\npublic class PageObjectManager {\n\n    public LoginPage getLoginPage() {\n        return new LoginPage();\n    }\n\n}\n</code></pre> <ol> <li>Add getter for PageObjectManger in BrowserContext class</li> </ol> <pre><code>    public PageObjectManager getPageObjectManager() {\n        return new PageObjectManager();\n    }\n</code></pre> <ol> <li>Call the PageObjectManager from stepdefinition</li> </ol> <pre><code>    LoginPage loginPage = browserContext.getPageObjectManager().getLoginPage(); \n</code></pre>"},{"location":"tech-notes/test-automation-basics/#dependency-injection_1","title":"Dependency Injection","text":"<ol> <li>Add Cucumber picocontainer for the POM file from mvn repository.</li> <li>Create a BrowserContext class for injection.</li> </ol> <pre><code>public class BrowserContext {\n\n    public WebDriver driver;\n\n    public BrowserContext() {\n        driver = new ChromeDriver();\n    }\n\n}\n</code></pre> <ol> <li>Call the BrowserContext in stepdefinition file</li> </ol> <pre><code>public class login {\n     WebDriver driver;\n\n     public login(BrowserContext browserContext){\n         this.driver = browserContext.driver;\n     }\n}\n</code></pre> <ol> <li>You don't need to create an object of of the Browser Context class to when using picocontainer for dependency injection</li> <li>Always write step definition with SRP(Single Responsibility principal)</li> <li>Class's needs to be loosely coupled when righting step-definition.</li> </ol>"},{"location":"tech-notes/test-automation-basics/#factory-desgin-pattern_1","title":"Factory Desgin Pattern","text":"<ol> <li>Create a class files with getters of all the pages in page Object class.</li> </ol> <pre><code>package pagesObject;\n\npublic class PageObjectManager {\n\n    public LoginPage getLoginPage() {\n        return new LoginPage();\n    }\n\n}\n</code></pre> <ol> <li>Add getter for PageObjectManger in BrowserContext class</li> </ol> <pre><code>    public PageObjectManager getPageObjectManager() {\n        return new PageObjectManager();\n    }\n</code></pre> <ol> <li>Call the PageObjectManager from stepdefinition</li> </ol> <pre><code>    LoginPage loginPage = browserContext.getPageObjectManager().getLoginPage(); \n</code></pre>"},{"location":"tech-notes/test-automation-basics/#parallel-test-using-surefire","title":"Parallel Test using Surefire","text":"<ul> <li>Parallel Tests</li> </ul> <pre><code>&lt;!-- https://mvnrepository.com/artifact/org.apache.maven.plugins/maven-surefire-plugin --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n    &lt;version&gt;3.2.3&lt;/version&gt;\n&lt;/dependency&gt;\n\n</code></pre> <pre><code>public class Regression extends AbstractTestNGCucumberTests {\n\n@Override\n\n@DataProvider(parallel = true)\n\npublic Object[][] scenarios() {\n\nreturn super.scenarios();\n\n}\n\n}\n</code></pre> <p>To add the Surefire plugin to your <code>pom.xml</code> file, you can include the following configuration:</p> <pre><code>&lt;build&gt;\n    &lt;plugins&gt;\n        &lt;!-- Surefire Plugin for running tests --&gt;\n        &lt;plugin&gt;\n            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n            &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n            &lt;version&gt;3.0.0-M5&lt;/version&gt; &lt;!-- Use the latest version available --&gt;\n\n            &lt;configuration&gt;\n                &lt;!-- Set the test classes directory --&gt;\n                &lt;testClassesDirectory&gt;${project.build.directory}&lt;/testClassesDirectory&gt;\n                &lt;includes&gt;\n                    &lt;include&gt;**/*Test*.java&lt;/include&gt;\n                    &lt;include&gt;**/*Test.java&lt;/include&gt;\n                    &lt;include&gt;**/*Tests.java&lt;/include&gt;\n                &lt;/includes&gt;\n            &lt;/configuration&gt;\n        &lt;/plugin&gt;\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <p>This configuration will include the Surefire Plugin with the specified version (3.0.0-M5 in this example). It also configures the plugin to include test classes based on the standard naming conventions (<code>*Test*.java</code>, <code>*Test.java</code>, <code>*Tests.java</code>).</p> <p>Make sure to replace the version with the latest version available at the time you're adding it. You can check the Maven Repository for the latest version.</p>"},{"location":"tech-notes/test-automation-basics/#parallel-tests-using-firesure","title":"Parallel Tests using FireSure","text":"<pre><code>&lt;plugin&gt;\n\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n\n&lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt;\n\n&lt;version&gt;2.22.0&lt;/version&gt;\n\n&lt;executions&gt;\n\n&lt;execution&gt;\n\n&lt;goals&gt;\n\n&lt;goal&gt;integration-test&lt;/goal&gt;\n\n&lt;goal&gt;verify&lt;/goal&gt;\n\n&lt;/goals&gt;\n\n&lt;configuration&gt;\n\n&lt;parallel&gt;methods&lt;/parallel&gt;\n\n&lt;useUnlimitedThreads&gt;true&lt;/useUnlimitedThreads&gt;\n\n&lt;/configuration&gt;\n\n&lt;/execution&gt;\n\n&lt;/executions&gt;\n\n&lt;/plugin&gt;\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#grid","title":"Grid","text":"<p><code>Parallel Tests on Multiple Machines with Differen versions of Browser on different Platform</code></p>"},{"location":"tech-notes/test-automation-basics/#development-server-on-4444","title":"Development Server on 4444","text":"<pre><code>java -jar selenium-server-&lt;version&gt;.jar standalone\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#architecture","title":"Architecture","text":"<p>Not applicable in case of Safari -- It can only spin up one instance</p>"},{"location":"tech-notes/test-automation-basics/#hub-registration","title":"Hub Registration","text":"<pre><code>java -jar selenium-server-&lt;version&gt;.jar hub\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#hub-on-a-specific-port","title":"Hub on a specific port","text":"<pre><code>java -jar selenium-server-&lt;version&gt;.jar hub --publish-events tcp://&lt;hub-ip&gt;:8886 --subscribe-events tcp://&lt;hub-ip&gt;:8887 --port 8888\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#node-registration","title":"Node registration","text":"<pre><code>java -jar selenium-server-&lt;version&gt;.jar node \n</code></pre>"},{"location":"tech-notes/test-automation-basics/#node-registration-on-a-specific-port","title":"Node registration on a specific port","text":"<pre><code>java -jar selenium-server-&lt;version&gt;.jar node --port 5555\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#connect-to-a-hub","title":"Connect to a hub","text":"<pre><code>java -jar selenium-server-&lt;version&gt;.jar node --hub http://&lt;hub-ip&gt;:4444\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#connect-to-a-hub-with-specific-port","title":"connect to a hub with specific port","text":"<pre><code>java -jar selenium-server-&lt;version&gt;.jar node --publish-events tcp://&lt;hub-ip&gt;:8886 --subscribe-events tcp://&lt;hub-ip&gt;:8887\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#reference_1","title":"Reference","text":""},{"location":"tech-notes/test-automation-basics/#cli-options","title":"CLI Options","text":""},{"location":"tech-notes/test-automation-basics/#driver-configurations","title":"Driver Configurations","text":""},{"location":"tech-notes/test-automation-basics/#grid-components","title":"Grid Components","text":""},{"location":"tech-notes/test-automation-basics/#starting-grid","title":"Starting Grid","text":""},{"location":"tech-notes/test-automation-basics/#grid-docker-image","title":"Grid Docker Image","text":"<p>Install docker</p> <pre><code>sudo yum update -y\nsudo yum install -y docker\nsudo service docker start\n\nsudo usermod -aG docker ec2-user\ndocker network create Grid\n\ndocker run -d -p 4442-4444:4442-4444 --net Grid --name selenium-hub selenium/hub:latest\n\ndocker run -d --net Grid -e SE_EVENT_BUS_HOST=selenium-hub \\\n    --shm-size=\"2g\" \\\n    -e SE_EVENT_BUS_PUBLISH_PORT=4442 \\\n    -e SE_EVENT_BUS_SUBSCRIBE_PORT=4443 \\\n    selenium/node-firefox:latest\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#log4j","title":"Log4J","text":"<p>Log4J</p>"},{"location":"tech-notes/test-automation-basics/#maven","title":"Maven","text":""},{"location":"tech-notes/test-automation-basics/#pomproject-object-model","title":"POM(Project Object Model)","text":"<ul> <li>Maven builds a project using its project object model (POM) </li> </ul>"},{"location":"tech-notes/test-automation-basics/#advantages","title":"Advantages","text":"<ul> <li>Simple project setup that follows best practices.</li> <li>Keeping test source code in a separate and parallel to the main code.</li> <li>Using test case naming conventions to locate and execute tests.</li> <li>Having test cases setup their environment instead of customizing the build for test preparation.</li> <li>Assists in project workflow such as release and issue management.</li> <li>Able to easily work with multiple projects at the same time.</li> <li>Coherent site of project information</li> <li>Dependency management</li> </ul>"},{"location":"tech-notes/test-automation-basics/#installation_1","title":"Installation","text":"<pre><code>brew install maven\n````\n\n### Commands\n```Maven\nmvn verify\nmvn clean install\nmvn compile\nmvn test\nmvn test-compile\nmvn package\nmvn install\nmvn clean\n</code></pre>"},{"location":"tech-notes/test-automation-basics/#reference_2","title":"Reference","text":""},{"location":"tech-notes/test-automation-basics/#java-project","title":"Java Project","text":"<pre><code>mvn archetype:generate -DarchetypeGroupId=com.mail.automation -DarchetypeArtifactId=com-botcat-automation -DgroupId=mail.automation -DartifactId=EMailAutomation -Dversion=1.0-SNAPSHOT\n</code></pre>"},{"location":"tech-notes/typescript/","title":"TypeScript","text":"<p>Tutorial web site</p> <p></p>"},{"location":"tech-notes/typescript/#important-commands","title":"Important commands","text":"<pre><code>yarn install\u00a0-g\u00a0typescript # install\ntsc --v # version\nnpm\u00a0install\u00a0-g\u00a0ts-node # ts to js converter \n</code></pre> <p><code>tsc app.ts</code> compiles to code to js file  <code>node app.js</code> runs the js file  <code>ts-node app.ts</code> run ts file directly</p>"},{"location":"tech-notes/typescript/#types","title":"Types","text":"<ul> <li>Primitive types     String      number     boolean      null     undefined     symbol - constant</li> <li>Object Type</li> </ul> <pre><code>\nlet newString: string = 'Hello world';\n\nconst newNumber: number = 1;\n\nlet newBool: boolean = true;\n\nlet newArray: number[] = [1, 2, 3, 4];\n\nlet newFuctionVariable: (name: string) =&gt; string;\nnewFuctionVariable = function(name: string) {\n  return `Hi ${name}`;\n}; // this is valid\n// this is invalid cause we are assigning wrong data function to the variable\n// newFuctionVariable = function() {\n//   console.log('Hello');\n// }; \nconsole.log('This is a String : ' + newString);\nconsole.log('This is a Number : ' + newNumber);\nconsole.log('This is a Boolean: ' + newBool);\nconsole.log('This is a Array: ' + newArray);\n\n//Object\nlet employee: { \nfirstName: string;\nlastName: string;\nage: number;\njobTitle: string;\n};\n\nlet big: bigint = 9007199254740991n; //bigint\n//In typescript numbers are floting point and bigint are long in java\n\n//String literals\n``let profile: string = `I'm ${firstName}.  I'm a ${title}`;``\n``let description = `This TypeScript string can  span multiple  lines `;``\n</code></pre>"},{"location":"tech-notes/typescript/#contextual-typing","title":"Contextual typing","text":"<p><code>document.addEventListener('click', function (event) {     console.log(event.button); //  });</code></p>"},{"location":"tech-notes/typescript/#tuple","title":"Tuple","text":"<ul> <li>Tuple is Final list.</li> </ul> <pre><code>let skill: [string, number]; \nskill = ['Programming', 5];\n\n// Optional parameters\nlet bgColor, headerColor: [number, number, number, number?];\n</code></pre>"},{"location":"tech-notes/typescript/#enum","title":"Enum","text":"<pre><code>enum name {constant1, constant2, ...};\n</code></pre>"},{"location":"tech-notes/Azure/AKS/","title":"AKS","text":""},{"location":"tech-notes/Azure/AKS/#azure-kubernates-service","title":"Azure Kubernates Service","text":""},{"location":"tech-notes/Azure/AKS/#features","title":"Features","text":"<ul> <li>Container orchestrator </li> <li>Auto scaling </li> <li>Service discovery</li> <li>Load balancer</li> <li>self healing </li> <li>Zero downtime</li> </ul>"},{"location":"tech-notes/Azure/AKS/#important-points","title":"Important points","text":"<ul> <li>Cluster</li> <li>Deploy microservices to the Cluster</li> </ul> <p>The above can be done by two orchestration tools in azure  1. AKS  2. Service fabric </p>"},{"location":"tech-notes/Azure/App%20Service/","title":"App Service","text":""},{"location":"tech-notes/Azure/App%20Service/#app-service-paas-service","title":"App service (PAAS service)","text":"<ul> <li>Web apps</li> <li>Mobile apps</li> <li>API apps (RESTful API)</li> <li>Function apps (Serverless) </li> </ul>"},{"location":"tech-notes/Azure/App%20Service/#app-service-plan","title":"App service plan","text":"<ul> <li>App service plan defines what kind of capacity you have for your workloads.</li> <li>CICD can be specified in the app service plan.</li> <li>Monitoring insights can be defined in the app service plan</li> <li>Scale up and Scale out can be done while increasing the app service plan</li> </ul>"},{"location":"tech-notes/Azure/App%20Service/#web-app","title":"Web app","text":"<p>1.Deployment option - code - container - static website 2. Web app runs in an app service plan  3. Scaling up and out - manual - automatic      - (based on metrics), add rules for scaling up and down     - (based on schedule), add rules for scaling up and down - rule-based 4.Deployment slots - staging slot - production slot - swap slots - Slots can be used for AB testing where some percentage of traffic can be traversed to the slot to check if everything is ok in production  5. Handler mappings - mapping file extensions to handlers like storage 6. Application settings - App config (Baiscally json file) 7. TLS certificate - Custom domain 8. Logs - Metrics - App service Logs(Logs stored in local storage accesseble via ftp) - Application logging - Web server logging - Diagnostic logs (Get logs in LAW, storage account, stream to event hub, or send to partners) - Application logging - Web server logging - Detailed error messages - Failed request tracing 9. Log stream - Real time logs - Application logging - Web server logging 10. Interact with the deployed app  - Development tools - Kudu - Console</p>"},{"location":"tech-notes/Azure/Basics/","title":"Basics","text":""},{"location":"tech-notes/Azure/Basics/#shared-responsibility-model","title":"Shared responsibility model","text":"<pre><code>- On premise: Customer is responsible for everything.\n- Iaas: MS responsible for physical infrastructure, customer responsible for OS, apps, data.(Azure VM)\n- PaaS: MS responsible for physical infrastructure, OS, apps, customer responsible for data.(Azure SQL, Azure App Service)\n- SaaS: MS responsible for everything.(Office 365, Dynamics 365)\n</code></pre>"},{"location":"tech-notes/Azure/Basics/#cloud-types","title":"cloud types","text":"<pre><code>- Public cloud - Azure\n- Private cloud - Government cloud\n- Hybrid Cloud - Public + Private cloud\n</code></pre>"},{"location":"tech-notes/Azure/Basics/#regions-and-zones","title":"Regions and Zones","text":"<pre><code>- Soveregin Region ---&gt;&gt; Used by Governments\n- Region A ------------------------------Region Pair-----------------------------Region B\n|\n- ( Availability zones A |  Availability zones B )\n|\n- Data center A | Data center B\n</code></pre>"},{"location":"tech-notes/Azure/Basics/#priceing-calculator","title":"Priceing calculator","text":"<pre><code>- This gives you a basic rought estimate for using the service on the cloud.\n- Capex - Buying the servers\n- Opex - Renting the servers\n</code></pre>"},{"location":"tech-notes/Azure/Basics/#cloud-concepts","title":"Cloud concepts","text":"<pre><code>1. High availability -&gt; Up time , no downtime is 100% availability(Not possible)\n2. Scalability -&gt; Design to add/ remove extra servers (Vertical scaling, horizontal scaling)\n3. Elasticity -&gt; Automating scalaility\n4. Reliability -&gt; Ability to system to recover from failures \n    - Autoscaling \n    - Avoid single point of failure \n    - Backups\n    - Multi Region deployments\n    - Health probes and self healing\n5. Predictibility -&gt; Predict and forcast and control performance and behavior of the system (Autoscaling)\n    - Microsoft security Respons center\n    - Always on DDos\n    - Azure policies and blueprints\n    - Azure Entra ID\n    - RBAC\n    - update management\n    - Encryption by default\n    - Firewalls\n6. Governance -&gt; Monitoring and policies \n    - policies\n    - auditing and reporting\n    - Industry standards\n    - management groups \n    - custom roles\n    - soft deletes\n    - cloud adoption framework\n7. Managability -&gt; \n    - Portal\n    - CLI\n    - Api's\n8. Serverless\n    - Functions\n    - Container Apps\n    - Kubernetes\n    - SQL database\n9. Cosmos DB\n</code></pre>"},{"location":"tech-notes/Azure/Basics/#types-of-service","title":"Types of service","text":"<pre><code>- Zonal services --&gt; Will be deployed in one az and not redundant\n- Zone redundant services --&gt; These services are zone redundant and can tolearate outages\n- Always available services --&gt; By defaul zone redundant (Azure Entra ID, Azure portal, Azure front door)\n</code></pre>"},{"location":"tech-notes/Azure/Basics/#imp-point","title":"IMP point","text":"<pre><code>- NSG can be attached to subnet\n- NSG can be attached to Vertual machines network interface\n- NSG cant be attached to the Vnet\n</code></pre>"},{"location":"tech-notes/Azure/Container%20Apps/","title":"Container Apps","text":""},{"location":"tech-notes/Azure/Container%20Apps/#azure-container-app","title":"Azure Container App","text":"<pre><code>- Used for production grade applications\n- Container environment needed , similar to app service plan\n    - Consumption plan (Serverless)\n    - Dedicated host\n- Acr or docker registry can be used\n- Scaling can be set up\n</code></pre>"},{"location":"tech-notes/Azure/Container%20Instance/","title":"Container Instance","text":""},{"location":"tech-notes/Azure/Container%20Instance/#container-instance","title":"Container Instance","text":"<pre><code>- Used for testing \n- Low priority jobs\n- Simple jobs \n- Non production sku \n- No scaling\n- No orchestration\n- Can be deployed on multiple zones\n- Acr or docked hub can be used\n- On failure restart\n</code></pre>"},{"location":"tech-notes/Azure/Database/","title":"Database","text":""},{"location":"tech-notes/Azure/Database/#database","title":"Database","text":""},{"location":"tech-notes/Azure/Database/#important-points","title":"Important points","text":"<ol> <li>Availability per mounth     99.95% - 22min     99.99% - 4.5 mins     5'9s - 26 sec</li> <li>Durability     11'9s - 1 million files for 10 million years you lose one file</li> <li>Consistency<ul> <li>Strong consistency --&gt; Syncronous replication(slow)</li> <li>Eventual consistancy --&gt; Asunchronous replication(slow, might return different values)</li> <li>Read after write consistency --&gt; Inserts are immediately available, Updates are with eventual consistency</li> </ul> </li> <li>RTO (Recovery time objective)<ul> <li>Maximum acceptable downtime</li> </ul> </li> <li>RPO (Recovery point objective)<ul> <li>Maximum acceptable data loss</li> </ul> </li> </ol>"},{"location":"tech-notes/Azure/Database/#relational-database","title":"Relational database","text":"<pre><code>- predefine schema and table relationships \n- Relational Database\n    - OLTP (Online transaction processing)\n        - Large number of users make large number of small transactions\n            - Managed DB (99.99% availability)\n                - Microsoft SQL server\n                - mySQL server\n                - PostgreSQL\n    - OLAP (Online analytics processing)\n            - Analyze huge data\n                - Azure Synaps Analytics\n- No SQL database\n    - Azure cosmosdb (99.999% availability)\n        - Documents\n        - Shards\n- In memory database (Caching data)\n    - Redis\n</code></pre>"},{"location":"tech-notes/Azure/Docker/","title":"Docker","text":""},{"location":"tech-notes/Azure/Docker/#docker-basics","title":"Docker Basics","text":"<ol> <li>Docker image is build of layers built from docker image.</li> <li>Docker file run from top to bottom.</li> <li>Docker registry is used for storing the docker images.</li> </ol>"},{"location":"tech-notes/Azure/Docker/#basic-commands","title":"Basic Commands","text":"<pre><code>docker version\ndocker info # Gives move info about installed docker version\ndocker login\ndocker container run -p 80:80 -d -n nameofcontainer nginx # Start basic nginx container in detached mode\ndocker container run -n mongodbname -d mongo # Start mongo db\ndocker container ls # list all the running containers \ndocker ps # running docker container\ndocker container ls -a # list all the container including stoped\ndocker ps -a # list docker container running and non running\ndocker container stop containerID # stop the container\ndocker container start containerID # start the container \ndocker container logs containername # show running container logs\ndocker container top # show process running on the container \ndocker container rm -f containerID # stop and remove the container in one command\n\ndocker container run -it container-image-name # run docker container with interative terminal\nexport DOCKER_HOST=ssh://root@143.222.2222.121 # this connects to the remote docker container\n</code></pre>"},{"location":"tech-notes/Azure/Linux/","title":"Linux","text":""},{"location":"tech-notes/Azure/Linux/#os","title":"OS","text":"<ol> <li>Desktop os -&gt; windows , mac , ubuntu</li> <li>Server os -&gt; windows server, centos , red hat linux</li> <li>Mobile 0s -&gt; android, windows, iso</li> <li>My used linux distros are ubuntu and centos(Red hat)</li> <li>Linux file systems ext4,XFC and Btrfs</li> <li>Linux <ul> <li>Kernal, started at boot, memory and cpu management, file system access, Network management</li> <li>Shell , programs to interact with kernal </li> </ul> </li> <li>Centos stream is a copy of red had</li> </ol>"},{"location":"tech-notes/Azure/Linux/#connect-remotely","title":"Connect remotely","text":"<pre><code>ssh -l username ip.address.1.0\nifconfig  # get the ip address\ncd / # Takes you to the root dir\n</code></pre>"},{"location":"tech-notes/Azure/Linux/#list","title":"List","text":"<pre><code>ls # list contents of dir\nls foldername # lists the content of folder without moving to the folder\nls -l # detailed list in alphabatical order\nls -ltr # detailed list with oldest on the top , reverse's the order, t sort by time\nls -a # list with hidden files\n</code></pre>"},{"location":"tech-notes/Azure/Linux/#movement","title":"Movement","text":"<pre><code>open foldername # Open the specified folder\npwd # Print working directory\ncd foldername # Moves to the sepcified folder\n</code></pre>"},{"location":"tech-notes/Azure/Linux/#combining-commands","title":"Combining commands","text":"<pre><code>; can be used for separating the commands\n</code></pre>"},{"location":"tech-notes/Azure/Linux/#file-system","title":"File system","text":"<pre><code>/boot # folder for bootleader (grab.cfg)\n/root # home dir for root\n/dev  # system devices\n/etc  # configuration\n/usr/bin # Commands\n/usr/sbin # system commands\n/opt # optional applications\n/proc # proccess\n/lib # programming libraries\n/tmp # dir for temp files\n/home # user dir\n/var # system logs\n/run # Storing temp runtime files like PID\n/mnt # mount external file system\n/media # mounting cd rom\n</code></pre>"},{"location":"tech-notes/Azure/Linux/#file-types","title":"File types","text":"<ul> <li>Regular files (text files , files with extentions) d Directory l Links c Special character device files(Hard drive, etc) s socket files p named pipe  b block device</li> </ul>"},{"location":"tech-notes/Azure/Linux/#change-password","title":"Change password","text":"<p>passwd userid</p>"},{"location":"tech-notes/Azure/Linux/#imp-commands","title":"Imp commands","text":"<pre><code>mkdir dirname # Make directory\ntouch filename # creata a file\ncp initialfilename finalfilename # copy file\nmv initialfilename finalfilename # move file\ncp -R initialdir finaldir # copy directories\nrm filename # remove the file\nrm -r # remove the folder content recursively\nrm -rf # remove the directory\nrmdir #removes empty directory\nfind . -name filename # find files \nfind . -type file # find files with type\nwhoami # print current user\nsu - # change to root user\n</code></pre>"},{"location":"tech-notes/Azure/Linux/#wild-cards","title":"Wild cards","text":"<pre><code>concept of Globbing\nrm abc*  # remove all the files starting with abc\nrm *xyz  # remove all the files ending with xyz\nls -l abc* # list all the files starting with abc\ntouch abcd[1-2].txt # create files with the sequence numbers\nrm ?bc* # remove files with bc starting from second charecter\n** # This searchs for all the files also in the sub folders\n</code></pre>"},{"location":"tech-notes/Azure/Linux/#user-accounts","title":"user accounts","text":"<ol> <li>Superuser Sudo</li> <li>Normal user sudo # change user with sudo</li> </ol>"},{"location":"tech-notes/Azure/Linux/#ubuntu-and-mac-package-management","title":"ubuntu and mac package management","text":"<pre><code>sudo apt update # Refresh the list of all packages\nsudo apt upgrade # Runs small upgrade of system\nsudo apt full-upgrade # Runs entire upgrade of the system\nsudo apt install\nsudo apt remove\nsudo apt autoremove # removes not used packages\nbrew install\nbrew update\nbrew upgrade\nbrew ls # list all the packages\n</code></pre>"},{"location":"tech-notes/Azure/Networking/","title":"Networking","text":""},{"location":"tech-notes/Azure/Networking/#basics","title":"Basics","text":"<ol> <li>Network -&gt; computer to computer connection</li> <li>protocal -&gt; Its like a language of communication</li> <li>ports -&gt; ports are like doors on which the communication is happening</li> <li>server -&gt; computer providing files and information</li> <li>clinet -&gt; computer gathering files and information from server</li> <li>mac address -&gt; This is the address on the network card         Mac address are unique for a device , it burnt on the device, usually its unique.         There were instances when the mac address were same for two devices , but mac address can also be changedj</li> <li>Ip address -&gt; DHCP allocates ip address to your device network         ifconfig --&gt; IPv4 </li> <li>ping ip.addresss.0.1.2 --&gt; used for communication between computers</li> </ol>"},{"location":"tech-notes/Azure/Networking/#service","title":"Service","text":"<ol> <li>http</li> <li>https</li> <li>email</li> <li>ftp</li> </ol>"},{"location":"tech-notes/Azure/Networking/#terminologies","title":"Terminologies","text":"<p>Repeater --&gt; takes the signal and repeats its (Dumb device) hub --&gt; takes to signal and repeats it to multiple outputs (Dumb device) bridge --&gt; a device between hub and switches switches -&gt;      1. take the signal and repeats it to multiple outputs but with filter and inteligence depending upon the mac address table (inteligence device)     2. are used for forwarding traffic in local area network (LAN) rounter --&gt; are used for forward traffic from lan to wan(wide area network) firewall --&gt; filters the traffic      1. Allows or deny who can enter your network     2. IDS -&gt; Intrusion detections system (This only detects the attack)     3. IPS -&gt; Intrusion protection system (This detacts and stops the attack) Lan controller --&gt; defines access points</p>"},{"location":"tech-notes/Azure/Networking/#different-types-of-layers-model","title":"Different types of layers model","text":"<ol> <li>OSI model (7 layer)</li> <li>TCP/IP model</li> </ol>"},{"location":"tech-notes/Azure/Networking/#layers","title":"Layers","text":"<p>layer1 (Physical layer) --&gt; hub, repeaters. (bits , if light -&gt; 1 , no light -&gt; 0)  layer2 --&gt; (Frame) --&gt; switches , bridge. (signals moving from one frame to onather) layer3 --&gt; (routers) --&gt; (packets, packets of information transporting Network) layer4 protocol --&gt; Tcp / Udp (segments) layer 5 ,6, 7 --&gt; applications (layer7) --&gt; HTTP/ HTTPS/ Telnet /FTP /TFTP  </p>"},{"location":"tech-notes/Azure/Networking/#ports","title":"Ports","text":"<p>Http - 80 Https - 443 FTP -21 ssh -23 Email(SMTP,pop3) - 25</p>"},{"location":"tech-notes/Azure/Networking/#binary","title":"Binary","text":"<p>IP address 192.168.1.72  --&gt; 32 bit  IPv4 192 --&gt;&gt; 0000 1010 168 --&gt;&gt; 1000 1010 1   --&gt;&gt; 0100 1010 72  --&gt;&gt; 0010 1010 subnet mask 225.225.225.0 --&gt; 32 bits router --&gt; 10.0.0.1 --&gt; 32 bits</p>"},{"location":"tech-notes/Azure/Networking/#ipv4","title":"IPv4","text":"<p>IP address's resides in the layer three in the router to identify the devices in the network Private ip (Similar Ip can be used in a different network) public IP (This is unique in the world) Dns is used to convert DNS name to ipaddress</p>"},{"location":"tech-notes/Azure/Networking/#classes-in-ip-address-network-address-and-host-address","title":"Classes in Ip address  (Network address and host address)","text":"<p>Class A Class B Class C 192.168.1.1 Class A Class E </p>"},{"location":"tech-notes/Azure/Networking/#special-address","title":"Special address","text":"<p>Direct broadacast address (Brodcast on different networks) local broadcast address (Broadcast on locak network) DHCP server then defines the ip address for the devices on the network</p>"},{"location":"tech-notes/Azure/Notes/","title":"Notes","text":""},{"location":"tech-notes/Azure/Notes/#az-900","title":"AZ-900","text":""},{"location":"tech-notes/Azure/Notes/#azure-virtual-desktop","title":"Azure Virtual Desktop","text":"<pre><code>- Virtual desktop for use\n- Vnet peering for connection two vnets \n- Azure DNS -&gt; resolves internal Vnet ips, does not work outside azure(http://somesite.local)\n- Azure VPN connects workstation to a network or network to a network , traffic in encripted. can be used intenally, \n- If Azure VPN needs to be used out side azure then it needs a physical device which needs to be connected to the network.\n- Point to side VPN (connect your workstation to the office network)\n- Site to site VPN (connect one network to another network ), also called as VPN peering \n- Express route -&gt; This is faster VPN , usually this is private internet connection to the network, does not uses the public internet.\n- public endpoints\n</code></pre>"},{"location":"tech-notes/Azure/Notes/#serverless","title":"Serverless","text":""},{"location":"tech-notes/Azure/Notes/#azure-functions","title":"Azure functions","text":"<pre><code>- Lambda functions\n- Trigger\n- bindings \n- durable functions \n- long running functions \n- premium or dedicated host option\n- Host pools \n- Create vm inside host pool (the user need to have Licence in entra id \n- Create a workspace \n- Assign the user to the host pool\n</code></pre>"},{"location":"tech-notes/Azure/Notes/#features","title":"Features","text":"<pre><code>1. Options\n    - Code \n    - Container\n2. Plans\n    - Consumption plan\n    - Premium plan\n    - App service plan\n3. Functions needs storage account\n4. Functaion app can contain multiple functions\n5. Triggers\n    - HTTP\n    - Timer\n    - Blob\n    - Queue\n    - Event grid\n    - Service bus\n6. Bindings\n    - Input\n    - Output\n7. Authorization level\n    - Function\n    - Anonymous(Do not require any security)\n    - Admin\n8. Code + Test (Section) , here you can develop the function and test it.\n9. Function.json(Contains the bindings and triggers)\n</code></pre>"},{"location":"tech-notes/Azure/Notes/#deployment-types","title":"Deployment types:","text":"<pre><code>- code ( some famous languages , choose custom handler for not listed ones )\n- Containers  \nHosting plan:\n- How many resources can be scaled and how much can it scale\n1. Consumption plan - server less\n3. Function premium \n5. App service plan - use the existing app service plan\n\n- Function needs a storage account to store the files\n- Public access can be turned off and can be attached to a virtual network( premium or app service plan needed ) \n- CICD can be done as needed \n- Monitoring can be turned on as per need. \n- Functions can be created in the portal itself\n- Functions have trigger. \n- Functions also have  bindings\n</code></pre>"},{"location":"tech-notes/Azure/Notes/#networking-services","title":"Networking services","text":"<pre><code>- Vnet\n- Subnets\n</code></pre>"},{"location":"tech-notes/Azure/Notes/#storage-services","title":"Storage services","text":""},{"location":"tech-notes/Azure/Notes/#database-services","title":"Database services","text":""},{"location":"tech-notes/Azure/Notes/#powershell","title":"Powershell","text":"<pre><code># list all modules\nGet-Module -ListAvailable\nGet-Module -ListAvailable -Name Az\n\n# Install Azure Powershell\nInstall-Module -Name Az -AllowClobber -Scope CurrentUser\n\n# Update Azure Powershell\nUpdate-Module -Name Az\n\n# Connect to Azure\nConnect-AzAccount\n</code></pre>"},{"location":"tech-notes/Azure/Notes/#containers","title":"Containers","text":"<pre><code>- Web app for Containers\n- container instances\n    - Used for bursts for k8's\n    - Non production workloads , testing \n- Container registry (Needed to enable admin account to use the image in web app and container instances)\n</code></pre>"},{"location":"tech-notes/Azure/Notes/#resource-groups","title":"Resource groups","text":"<ul> <li>Resource group should have a region </li> <li></li> <li>On delete all the resources inside the resource group are deleted</li> <li></li> </ul> <p>Bandwidth cost : * Data moving outside azure cost money *  * Data moving inside azure is free. * </p> <p>Networking Virtual Network: * Isolated network  *  * Ip range needs to be specified  *  * At least one subnet must be created *  * Resources in the same subnet can communicate via private IP address *  * Connect two vnets using vent peering  * </p> <p>Network security groups:  * Nsg filters the traffic depending on the inbound and outbound rule. *  * High priority rules takes the lead , any overlapping rule after that is ignored.  *  * Multiple inbound and outbound rule can be specified. *  * Nsg\u2019s are connected to subnet or network interfaces nic\u2019s. *  * Nsg can\u2019t be linked to the vent , instead azure file wall service is used to filter traffic to the virtual network. * </p> <p>Application security group: * is extension of nsg\u2019s *  * Servers can be grouped under multiple applications security groups and then those application security groups can then be defined in the nsgs , hence you don\u2019t have to create rules for all the servers in the group. *  Azure VPN: * Point to site :Traffic travels through vpn to virtual network gateway and then towards the vent *  * Site to site : Traffic travels through on premises network or any other network to virtual network gateway and then the the vent  *  Express route: * Dedicated private connection from on prem network or any network to the azure network.  * </p> <p>Azure load balancer:  * Balance traffic between multiple servers. *  * Public lb gets the traffic from Internet  *  * Private lb gets the traffics from within the network  *  * Add servers in back end pool setting in load balancer. *  * Health probe can be added to Lb to check if backend machines are healthy . Define the probe and then define the rule  *  * You don\u2019t need to have public ip linked to the servers and the lb has the public ip attached to it  * </p> <p>Azure DNS( Domain name service ) :</p> <ul> <li>DNS can be purchased from external domain provider</li> <li></li> <li>DNS records needs to be configured in the azure DNS </li> <li></li> <li>Create DNS zone , give the name as the domain you purchased from some external service. </li> <li></li> <li>The DNS zone then needs to be connected to the domain service </li> </ul>"},{"location":"tech-notes/Azure/Vim/","title":"Vim","text":""},{"location":"tech-notes/Azure/Vim/#basic-motions","title":"Basic Motions","text":"<pre><code>crlt + f # page down\ncrlt + b # page up\nz + enter # moves the current line at the very top\nw , W move a word forward\nb, B move a word backward\n  0 move to the start of the row\n_ move to the first word of the line\n$ move to the end of the line\ngg move to the top of the document\nG move to the very bottom of the document\nx delete the character under the cursor\nX delete the character before the cursor\ndd delete the line under the cursor\ndw delete the word under the cursor\nd$ delete from the cursor to the end of the line\nD delete from the cursor to the end of the line\nd0 delete from the cursor to the start of the line\nidgg delete from the cursor to the top of the document\ndG delete from the cursor to the bottom of the document\n. repeat the last command\np paste the last deleted text below the cursor (Put)\nP paste the last deleted text before the cursor (Put)\nyy copy the line under the cursor (Yank)\nu undo the last command\nctrl + r redo the last command\nr replace the character under the cursor\nJ join the current line with the next line\nf + character find the next character in the line\nF + character find the previous character in the line\n; to cycle through the last search\n, to cycle through the last search in the opposite direction\n/ + text search for the text in the document and \nn to cycle through the results and \nN to cycle through the results in the opposite direction\n:/s/old/new/g search for old and replace with new globally and confirm each replacement\n</code></pre>"},{"location":"tech-notes/Azure/Vim/#insert-commands","title":"Insert Commands","text":"<pre><code>i insert mode before the cursor\na insert mode after the cursor\no insert mode on the next line\nO insert mode on the previous line\nA insert mode at the end of the line\nI insert mode at the start of the line\n</code></pre>"},{"location":"tech-notes/Azure/Vim/#register-types","title":"Register Types","text":"<pre><code>unnamed register or default register: \"\"\nnumbered registers: \"0, \"1, \"2, \"3, \"4, \"5, \"6, \"7, \"8, \"9\nnames registers: \"a, \"b, \"c, \"d, \"e, \"f, \"g, \"h, \"i, \"j, \"k, \"l, \"m, \"n, \"o, \"p, \"q, \"r, \"s, \"t, \"u, \"v, \"w, \"x, \"y, \"z\nBlack hole register: \"_\n</code></pre>"},{"location":"tech-notes/Azure/Vim/#macros","title":"Macros","text":"<pre><code>q + register\nafter macros is recorded hit q in normal mode\nTo use the macro use @ + macro register\nv for visual mode\nctrl + v for visual block mode\n</code></pre>"},{"location":"tech-notes/Azure/readme/","title":"Azure documentation","text":"<p>Docks</p>"},{"location":"tech-notes/Azure/readme/#shared-responsibility-model","title":"Shared responsibility model","text":"<pre><code>- On premise: Customer is responsible for everything.\n- Iaas: MS responsible for physical infrastructure, customer responsible for OS, apps, data.(Azure VM)\n- PaaS: MS responsible for physical infrastructure, OS, apps, customer responsible for data.(Azure SQL, Azure App Service)\n- SaaS: MS responsible for everything.(Office 365, Dynamics 365)\n</code></pre>"},{"location":"tech-notes/Azure/readme/#cloud-types","title":"cloud types","text":"<pre><code>- Public cloud - Azure\n- Private cloud - Government cloud\n- Hybrid Cloud - Public + Private cloud\n</code></pre>"},{"location":"tech-notes/Azure/readme/#regions-and-zones","title":"Regions and Zones","text":"<pre><code>- Soveregin Region ---&gt;&gt; Used by Governments\n- Region A ------------------------------Region Pair-----------------------------Region B\n|\n- ( Availability zones A |  Availability zones B )\n|\n- Data center A | Data center B\n</code></pre>"},{"location":"tech-notes/Azure/readme/#pricing-calculator","title":"Pricing calculator","text":"<pre><code>- This gives you a basic rought estimate for using the service on the cloud.\n- Capex - Buying the servers\n- Opex - Renting the servers\n</code></pre>"},{"location":"tech-notes/Azure/readme/#cloud-concepts","title":"Cloud concepts","text":"<pre><code>1. High availability -&gt; Up time , no downtime is 100% availability(Not possible)\n2. Scalability -&gt; Design to add/ remove extra servers (Vertical scaling, horizontal scaling)\n3. Elasticity -&gt; Automating scalaility\n4. Reliability(fault tolarent) -&gt; Ability to system to recover from failures \n    - Autoscaling \n    - Avoid single point of failure \n    - Backups\n    - Multi Region deployments\n    - Health probes and self healing\n5 Disaster recovery can be done using site recovery tool\n6. Predictibility -&gt; Predict and forcast and control performance and behavior of the system (Autoscaling)\n    - Microsoft security Respons center\n    - Always on DDos\n    - Azure policies and blueprints\n    - Azure Entra ID\n    - RBAC\n    - update management\n    - Encryption by default\n    - Firewalls\n7. Governance -&gt; Monitoring and policies \n    - policies\n    - auditing and reporting\n    - Industry standards\n    - management groups \n    - custom roles\n    - soft deletes\n    - cloud adoption framework\n8. Managability -&gt; \n    - Portal\n    - CLI\n    - Api's\n9. Serverless\n    - Functions\n    - Container Apps\n    - Kubernetes\n    - SQL database\n10. Cosmos DB\n</code></pre>"},{"location":"tech-notes/Azure/readme/#types-of-service","title":"Types of service","text":"<pre><code>- Zonal services --&gt; Will be deployed in one az and not redundant\n- Zone redundant services --&gt; These services are zone redundant and can tolearate outages\n- Always available services --&gt; By defaul zone redundant (Azure Entra ID, Azure portal, Azure front door)\n</code></pre>"},{"location":"tech-notes/Azure/readme/#imp-point","title":"IMP point","text":"<pre><code>- NSG can be attached to subnet\n- NSG can be attached to Vertual machines network interface\n- NSG cant be attached to the Vnet\n</code></pre>"},{"location":"tech-notes/Azure/Advisor/readme/","title":"Azure advisor","text":"<pre><code>- Gives advise on\n    - Cost\n    - Security\n    - Reliability\n    - Operational excellence\n    - Performance\n</code></pre>"},{"location":"tech-notes/Azure/Advisor/readme/#recomendation-alers","title":"Recomendation alers","text":"<pre><code>- Recomendation alerts can be set too\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Azure-Pipeline/","title":"Azure pipelines","text":""},{"location":"tech-notes/Azure/Devops/Azure-Pipeline/#pipeline-basics","title":"Pipeline basics","text":"<ul> <li>Pipeline = collection of stages.</li> <li>Stages = collection of jobs.</li> <li>Jobs = collection of steps.</li> <li>Each Job runs on one agent.</li> <li>Manual approvals are possible between stages.</li> <li>Deployment = Jobs and steps running sequentially.</li> <li>Deployment groups = collection of machines for deployment. [run once, rolling, canary].</li> <li>Environments are collection of resources where the application is deployed.</li> <li>Jobs are collection of steps that run sequentially on the same agent, there can be agentless jobs too.</li> <li>Release is versioned set of artifacts specified in a pipeline for a deployment to an environment.</li> <li>Run is a single execution of a pipeline.</li> <li>Step is a single task that is executed by the agent.</li> <li>Script is a sequence of commands that are executed by the agent.</li> <li>Task is a pre-packaged script that performs an action in a pipelines.</li> <li>Library includes secure files and variable groups. Secure files are a way to store files and share them across pipelines.</li> </ul>"},{"location":"tech-notes/Azure/Devops/Azure-Pipeline/#trigger-basics","title":"Trigger basics","text":"<ul> <li>Triggers can't use variables in triggers.</li> <li>Cannot specify triggers in the template files.</li> <li>There are two types of triggers , Build Triggers or CI Triggers and Release Triggers or CD Triggers.</li> </ul> <pre><code>name: my-first-azure-pipeline # name of the pipe run not the pipeline\n# Pipeline name is picked from the yaml file name\ntrigger: none\ntrigger: \nbatch: true # Run pipeline in sequence with multiple commits.Address caution.\n    branches:\n        include:\n          - main\n          - feature/* # Wildcard (* , ** and ?)\n        exclude:\n          - wip/*\n    paths:\n        include:\n          - pipelines/my-first-azure-pipeline*\n        exclude:\n          - README.md\n    tags: # This will run when you push a tag. \n        include:\n            - v1.*\n        exclude:\n          - v1.0\npr:\n branches:\n   include:\n      - main\n   exclude:\n      - wip/*\n paths:\n    include:\n      - pipelines/my-first-azure-pipeline*\n    exclude:\n      - README.md\n tags:\n   include:\n     - v1.*\n   exclude:\n     - v1.0\nresources: # This is redundant here as this is the default behaviour\n    - repo: self\n</code></pre> <ul> <li>To skip a pipeline run, you can include the following in the commit message:</li> <li>[skip ci] or [ci skip]</li> <li>skip-checks: true or skip-checks:true</li> <li>[skip azurepipelines] or [azurepipelines skip]</li> <li>[skip azpipelines] or [azpipelines skip]</li> <li>[skip azp] or [azp skip]</li> <li>NO_CI</li> <li>Adding conditions to the pipelines</li> <li>condition: and(succeeded(), ne(variables['Build.Reason'], 'PullRequest'))</li> </ul> Agent pool <pre><code>pool: # Define selfhosted pool for the pipeline\n   name: 'selfhosted'\n\npool: # Define Microsoft hosted pool for the pipeline\n    vmImage: 'ubuntu-latest' # you can use 'windows-latest' for Windows and 'macOS-latest' for macOS \n\nstrategy: # Parallel jobs on different OS\n    matrix:\n      linux:\n        imageName: \"ubuntu-latest\"\n     mac:\n        imageName: \"macOS-latest\"\n      windows:\n        imageName: \"windows-latest\"\n    maxParallel: 3\n\npool:\n    vmImage: $(imageName)\nstrategy: # Parallel jobs on different JDK versions\n    matrix:\n      jdk10:\n        jdkVersion: \"1.10\"\n      jdk11:\n        jdkVersion: \"1.11\"\n    maxParallel: 2\n\nstrategy: # Parallel jobs on different OS and JDK versions\n    matrix:\n      jdk10_linux:\n        imageName: \"ubuntu-latest\"\n        jdkVersion: \"1.10\"\n      jdk11_windows:\n        imageName: \"windows-latest\"\n        jdkVersion: \"1.11\"\n    maxParallel: 2\n\n  pool:\n    vmImage: $(imageName)\n  pool:\n   name: 'selfhosted'\n</code></pre> Variables <pre><code>variables:\n  - name: someVariableName\n    value: valueOfTheVariable\n  - name: pathVersion # dont know what is this for\n    value: $[counter(0, 0)]   \n  - template: variables/variables-test.yaml # reference variables from seperate variable file\n</code></pre> Pipeline structure <pre><code>stage level\njob level\n\njobs:\n- job: job1\n   pool:\n     vmImage: 'ubuntu-latest'\n   variables:\n     job_variable1: value1    # Job level variable\n   steps:\n   - bash: echo $(global_variable)\n   - bash: echo $(job_variable1)\n   - bash: echo $JOB_VARIABLE1 \n\n- job: job2\n   pool:\n     vmImage: 'ubuntu-latest'\n   variables:\n     job_variable2: value2    # this is only available in job2\n   steps:\n   - bash: echo $(global_variable)\n   - bash: echo $(job_variable2)\n   - bash: echo $GLOBAL_VARIABLE\n</code></pre> Git checkout  Multi Checkouts in a pipeline ------------------------------ - Use either checkout or uses options to checkout a different repository. If not specified it checks out the current repository.   <pre><code>steps:\n - checkout: git://FabrikamFiber/FabrikamTools # Azure Repos Git repository in the same organization\n - script: # Do something with that repo # Or you can reference it with a uses statement in the job\n uses:\n   repositories: # List of referenced repositories\n   - FabrikamTools # Repository reference to FabrikamTools\n</code></pre> <pre><code>jobs:\n  - job: bicep_build\n    steps:\n      - checkout: self # This step is redundant (pipelines default beheviour in first step)\n        persistCredentials: true\n        clean: true\n        fetchDepth: 0\n</code></pre> Tasks <pre><code>  - task: AzurePowerShell@5\n    name: bicepBuildTrigger\n    env:\n        SYSTEM_ACCESSTOKEN: $(System.AccessToken)\n    inputs:\n        displayName: 'Triggering bicep build for changed files'\n        ScriptType: filePath\n        ScriptPath: $(Build.SourceDirectory)/pipelines/scripts/trigger_pipeline.ps1\n        failOnStderr: true\n        azurePowerShellVersion: \"LatestVersion\"\n        azureSubscription: ${{ variables.azureSubscriptionName}}\n        pwsh: true\n        ScriptArgument: &gt; # Use this to avoid newline characters in multilines string\n            -patchVersion $(patchVersion)\n            -pipelineName \"build-and-publish-module\"\n            -bicepVersionFile \"metadata.json\"\n            -bicepFile \"main.bicep\"\n\n# inline script type\n- task: AzurePowerShell@5\n  inputs:\n    ScriptType: filePath\n    ScriptPath: $(Build.SourcesDirectory)/scripts/myscript.ps1\n    azureSubscription: $(azureSubscriptionName)\n    pwsh: true\n    failOnStderr: true\n\n\n# file type script type\n- task: AzurePowerShell@5\n  inputs:\n    ScriptType: inlineScript\n    ScriptInline: |\n      Write-Host \"Hello, World!\"\n      Get-AzResourceGroup\n    azureSubscription: $(azureSubscriptionName)\n    pwsh: true\n    failOnStderr: true\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/","title":"Docker","text":""},{"location":"tech-notes/Azure/Devops/Docker/#architecture","title":"Architecture","text":""},{"location":"tech-notes/Azure/Devops/Docker/#docker-run","title":"Docker run","text":"<pre><code>$ docker run -i -t ubuntu /bin/bash\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#docker-pull","title":"Docker pull","text":"<pre><code>docker pull ubuntu/latest\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#docker-file","title":"Docker file","text":"<pre><code>FROM node:18-alpine\nWORKDIR /app\nCOPY . .\nRUN yarn install --production\nCMD [\"node\", \"src/index.js\"]\nEXPOSE 3000\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#build-image","title":"Build Image","text":"<pre><code>$ cd /path/to/getting-started-app\n$ docker build -t getting-started \n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#list-containers","title":"List containers","text":"<pre><code>docker ps\ndocker ps -a //list container with all those were stopped\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#stop-containers","title":"Stop containers","text":"<pre><code>$ docker stop &lt;the-container-id&gt;\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#remove-stoped-containers","title":"Remove stoped containers","text":"<pre><code>$ docker rm &lt;the-container-id&gt;\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#push-image-to-dockerhub","title":"Push image to dockerhub","text":"<pre><code>docker tag getting-started YOUR-USER-NAME/getting-started\ndocker push YOUR-USER-NAME/getting-started\n</code></pre> <p>Continue from here  https://docs.docker.com/get-started/05_persisting_data/</p>"},{"location":"tech-notes/Azure/Devops/Docker/#create-volume","title":"Create Volume.","text":"<pre><code>docker volume create mynewvolume\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#mount-the-created-volume","title":"Mount the created volume.","text":"<pre><code>docker run -dp 3000:3000 --mount type=volume,src=mynewvolume,target=/etc/todos ubuntu \n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#bind-mount","title":"Bind Mount","text":"<pre><code>docker run -it --rm -v ~/code/app:/app image:latest\n</code></pre> <pre><code> docker run -it --mount type=bind,src=\"$(pwd)\",target=/src ubuntu bash\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#create-network","title":"Create network","text":"<p>``` docker network create todo-app</p> <pre><code>\n\n```d\nservices:\n  app:\n    image: node:18-alpine\n    command: sh -c \"yarn install &amp;&amp; yarn run dev\"\n    ports:\n      - 127.0.0.1:3000:3000\n    working_dir: /app\n    volumes:\n      - ./:/app\n    environment:\n      MYSQL_HOST: mysql\n      MYSQL_USER: root\n      MYSQL_PASSWORD: secret\n      MYSQL_DB: todos\n\n  mysql:\n    image: mysql:8.0\n    volumes:\n      - todo-mysql-data:/var/lib/mysql\n    environment:\n      MYSQL_ROOT_PASSWORD: secret\n      MYSQL_DATABASE: todos\n\nvolumes:\n  todo-mysql-data:\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#references","title":"References","text":"<ul> <li> <p>Docker Overview</p> </li> <li> <p>Docker Quick Start Guide</p> </li> <li> <p>kernel namespaces and cgroups</p> </li> </ul>"},{"location":"tech-notes/Azure/Devops/Docker/#docker-file-reference","title":"Docker File Reference","text":""},{"location":"tech-notes/Azure/Devops/Docker/#docker-commands","title":"Docker Commands","text":"<ul> <li>Login </li> </ul> <pre><code>docker login\n</code></pre> <ul> <li>Build Image</li> </ul> <pre><code>docker build -t username/imagename:tag .\n</code></pre> <ul> <li>List Image</li> </ul> <pre><code>docker image ls\ndocker image ls -a\n</code></pre> <ul> <li>List of running containers.</li> </ul> <pre><code>docker ps\nor \ndocker container ls\n</code></pre> <ul> <li>List of running as well as stopped containers.</li> </ul> <pre><code>docker ps -a\nor\ndocker container ls -a\n</code></pre> <ul> <li>Container .</li> </ul> <pre><code>docker stop &lt;the-container-id&gt;\n</code></pre> <ul> <li>Remove Stopped Container.</li> </ul> <pre><code>docker rm &lt;the-container-id&gt;\n</code></pre> <ul> <li>Stop and remove container with one command.</li> </ul> <pre><code>docker rm -f &lt;the-container-id&gt;\n</code></pre> <ul> <li>To push locally built image to dockerhub you first need to tag the image appropriately </li> </ul> <pre><code>docker image -t imagename dockeruserID/imagename:version\n</code></pre> <ul> <li>Push image to dockerHub</li> </ul> <pre><code>docker push dockeruserID/imagename:version\n</code></pre> <ul> <li>Run commands in a running container </li> </ul> <pre><code>docker exec &lt;container-id&gt; cat /data.txt\n</code></pre> <ul> <li>You can watch the logs using</li> </ul> <pre><code>docker logs &lt;container-id&gt;\n</code></pre> <ul> <li>Use the docker image history command to see the layers in the getting-started image you created earlier in the tutorial.</li> </ul> <pre><code>docker image history --no-trunc getting-started \n\n</code></pre>"},{"location":"tech-notes/Azure/Devops/Docker/#interacting-with-container","title":"Interacting with container","text":"<p>To execute commands inside a Docker container, you can use the <code>docker exec</code> command. Here's how you can do it:</p> <ol> <li>Start the Docker container: Ensure that your Docker container is running. You can start a container using the <code>docker run</code> command. For example:</li> </ol> <pre><code>docker run -it container-name\n</code></pre> <p>Replace <code>container-name</code> with the name or ID of your Docker container.</p> <ol> <li>Execute a command inside the container: Open a new terminal or command prompt window and use the following command to execute a command inside the running container:</li> </ol> <pre><code>docker exec -it container-name command\n</code></pre> <p>Replace <code>container-name</code> with the name or ID of your Docker container, and replace <code>command</code> with the command you want to execute inside the container. The <code>-it</code> option allows you to interact with the container's terminal.</p> <p>For example, if you want to execute a bash shell inside the container, you can run:</p> <pre><code>docker exec -it container-name bash\n</code></pre> <p>This will start a new shell session inside the running container.</p> <ol> <li>Run a command and exit: If you want to run a command inside the container and exit immediately without entering an interactive shell, you can use the following command:</li> </ol> <pre><code>docker exec container-name command\n</code></pre> <p>Replace <code>container-name</code> with the name or ID of your Docker container, and replace <code>command</code> with the command you want to execute inside the container.</p> <p>For example, to list the files in the container's <code>/app</code> directory, you can run:</p> <pre><code>docker exec container-name ls /app\n</code></pre> <p>That's it! You can now execute commands inside your Docker container using the <code>docker exec</code> command.</p>"},{"location":"tech-notes/Azure/Devops/Docker/#docker-compose","title":"Docker Compose","text":"<ul> <li>Install Docker Compose</li> </ul> <pre><code>sudo pacman -S docker-compose\n</code></pre> <ul> <li>Check Docker Compose Version</li> </ul> <pre><code>docker compose version\n</code></pre> <ul> <li>Start from compose file</li> </ul> <pre><code>compose up\n</code></pre> <ul> <li>Start from compose file</li> </ul> <pre><code>compose down \n</code></pre> <ul> <li>By default, named volumes in your compose file are NOT removed when running docker compose down. If you want to remove the volumes, you will need to add the --volumes flag.</li> </ul>"},{"location":"tech-notes/Azure/Devops/Docker/#reference","title":"Reference","text":"<ul> <li>Github Project</li> </ul>"},{"location":"tech-notes/Azure/Devops/Docker/#step-by-step-guide-to-creating-a-dockerignore-file","title":"Step-by-step guide to creating a <code>.dockerignore</code> file:","text":"<ol> <li>Create a New File:</li> <li>Open a text editor or terminal and navigate to the root directory of your Docker project.</li> <li> <p>Create a new file named <code>.dockerignore</code>. Note the leading dot (<code>.</code>) in the filename, as it signifies that it is a hidden file.</p> </li> <li> <p>Specify Ignored Files and Directories:</p> </li> <li>In the <code>.dockerignore</code> file, list the files and directories you want Docker to ignore when building the image.</li> <li>Each entry should be on a separate line.</li> <li> <p>You can use wildcards and patterns to match multiple files or directories. For example, <code>*.log</code> matches all files with the <code>.log</code> extension, and <code>logs/</code> matches the <code>logs</code> directory and its contents.</p> </li> <li> <p>Save the File:</p> </li> <li> <p>Save the <code>.dockerignore</code> file in the root directory of your Docker project.</p> </li> <li> <p>Build or Run Docker Image:</p> </li> <li>With the <code>.dockerignore</code> file in place, when you build or run a Docker image, Docker will exclude the specified files and directories from the context used during the build process.</li> <li>This can help speed up the build process and reduce the size of the resulting image.</li> </ol> <p>Here's an example <code>.dockerignore</code> file to get you started:</p> <pre><code># Ignore specific file\nfile.txt\n\n# Ignore all files with .log extension\n*.log\n\n# Ignore the logs directory\nlogs/\n\n# Ignore the temp directory and its contents\ntemp/\n</code></pre> <p>Customize the <code>.dockerignore</code> file based on your project's needs, including any files or directories you want to exclude from the Docker image.</p> <ul> <li>[[Nextjs Docker File]]</li> </ul> <p>A Dockerfile is a text file used to define the configuration and instructions for building a Docker container image. It consists of a set of commands and parameters that specify how to assemble an image. When the Dockerfile is used to build the image, each instruction is executed step-by-step, creating layers that form the final image.</p> <p>Here is a breakdown of the structure of a Dockerfile and how it is written:</p> <ol> <li>Base Image Selection:    The first line of a Dockerfile usually specifies the base image upon which the new image will be built. It defines the starting point for your container. You can use an existing base image from the Docker Hub or a private repository.</li> </ol> <p><code>Dockerfile    FROM ubuntu:latest</code></p> <ol> <li>Environment Setup:    You can set environment variables to configure the container's behavior or to provide configuration details.</li> </ol> <p><code>Dockerfile    ENV MY_VAR=my_value</code></p> <ol> <li>Working Directory:    You can set the working directory inside the container where commands will be executed.</li> </ol> <p><code>Dockerfile    WORKDIR /app</code></p> <ol> <li>Copying Files:    You can copy files from the host machine into the container's filesystem.</li> </ol> <p><code>Dockerfile    COPY ./src /app/src</code></p> <ol> <li>Installing Dependencies:    You can use package managers (like <code>apt-get</code>, <code>yum</code>, or <code>pip</code>) to install required software and dependencies inside the container.</li> </ol> <p><code>Dockerfile    RUN apt-get update &amp;&amp; apt-get install -y python3</code></p> <ol> <li>Exposing Ports:    If your application listens on specific ports, you can expose them to the host machine.</li> </ol> <p><code>Dockerfile    EXPOSE 80</code></p> <ol> <li>Running Commands:    You can execute commands within the container during image build time.</li> </ol> <p><code>Dockerfile    RUN python3 -m pip install flask</code></p> <ol> <li>Entrypoint or CMD:    Specifies the command that will be executed when the container is run. It's either the <code>CMD</code> or <code>ENTRYPOINT</code> instruction.</li> </ol> <p><code>Dockerfile    CMD [\"python3\", \"app.py\"]</code></p> <p>The <code>CMD</code> instruction allows you to specify a default command and arguments that can be overridden when starting the container. The <code>ENTRYPOINT</code> instruction is similar but makes it harder to override the specified command.</p> <ol> <li> <p>Additional Configuration and Cleanup:    You can add any additional configurations or cleanup operations in the Dockerfile as needed.</p> </li> <li> <p>Building the Image:     Once you've written the Dockerfile, you can build the Docker image using the <code>docker build</code> command. The Docker CLI will read the Dockerfile and execute each instruction to create the final image.</p> </li> </ol> <p><code>bash    docker build -t my_image_name:tag .</code></p> <ol> <li>Running the Container:     After building the image, you can run a container based on that image using the <code>docker run</code> command.</li> </ol> <p><code>bash    docker run -p 8080:80 my_image_name:tag</code></p> <p>This is a basic overview of a Dockerfile and how it is written. Dockerfiles can be more complex depending on the application requirements, and you can use various instructions and techniques to optimize the image size and build process.</p>"},{"location":"tech-notes/Azure/Devops/Docker/#dockerfile","title":"DockerFile","text":"<pre><code># Use an official Node.js image as the base\nFROM node:14-alpine\n\n# Set the working directory inside the container\nWORKDIR /app\n\n# Copy package.json and package-lock.json to the working directory\nCOPY package*.json ./\n\n# Install project dependencies\nRUN npm install\n\n# Copy the entire project to the working directory\nCOPY . .\n\n# Build the Next.js application\nRUN npm run build\n\n# Expose the desired port (change it to match your Next.js application's port)\nEXPOSE 3000\n\n# Set the command to start the Next.js application\nCMD [\"npm\", \"start\"]\n</code></pre> <p>Make sure to replace <code>3000</code> with the actual port number your Next.js application listens on. This Dockerfile assumes that your project structure includes <code>package.json</code>, <code>package-lock.json</code>, and a build script defined in <code>scripts</code> section of <code>package.json</code>.</p> <p>To build a Docker image using this Dockerfile, navigate to the directory containing the Dockerfile and run the following command:</p> <pre><code>docker build -t your-image-name .\n</code></pre> <p>Replace <code>your-image-name</code> with the desired name for your Docker image.</p> <p>Once the image is built, you can run a container based on this image using the following command:</p> <pre><code>docker run -p 3000:3000 your-image-name\n</code></pre> <p>This will map port 3000 of the container to port 3000 of your host machine. You can then access your Next.js application by visiting <code>http://localhost:3000</code> in your browser.</p> <p>Remember to customize the Dockerfile as per your project's specific requirements, such as additional dependencies or environment variables.</p>"},{"location":"tech-notes/Azure/Devops-test/readme/","title":"Azure devops","text":""},{"location":"tech-notes/Azure/Devops-test/readme/#organization","title":"Organization","text":"<pre><code>- Project 1\n- Project 2\n</code></pre>"},{"location":"tech-notes/Azure/Devops-test/readme/#projects-1","title":"Projects 1","text":"<pre><code>- Overview\n    - Summary (Project summary , readme can be used)\n    - Bashboards (add wedgits here)\n    - Wiki (Confluence)\n- Boards\n    - Work Items(All the tickets created)\n    - Boards (Sprint dashboard)\n    - Backlogs (Sprint Boards)\n    - Sprint (Sprint board)\n    - Queries (Filters with charts)\n        - Shared Queries\n        - My Queries\n    - Delivery Plans(Jira plans)\n    - Analytics views\n- Repos\n- Pipelines\n    - Build pipeline\n    - Release pipeline\n- Test Plans\n- Arrifacts\n</code></pre>"},{"location":"tech-notes/Azure/Devops-test/readme/#workflows","title":"Workflows","text":"<ol> <li>Basic <ul> <li>Epic | Issues | Tasks</li> </ul> </li> <li>Agile<ul> <li>Epic | Feature | User Stories/Bugs/Issues | Tasks | </li> </ul> </li> <li>Scrum<ul> <li>Epic | Feature | Backlog Item/Bug | Task </li> </ul> </li> <li>CMMI<ul> <li>Epic | Feature | Requirement/Bugs/Change request | Task</li> </ul> </li> </ol>"},{"location":"tech-notes/Azure/Devops-test/readme/#ticket-state","title":"Ticket state","text":"<ol> <li>New -&gt; Active -&gt; Resolved -&gt; Closed     -&gt; Removed</li> </ol>"},{"location":"tech-notes/Azure/Devops-test/readme/#dashboard","title":"Dashboard","text":"<pre><code>- Burndown charts (Give the info on how much work was completed by the end of the sprint)\n- Cyle time chart (Time taken to close a work item)\n- Lead time (Time taken to close a work item after it was created)\n- Velocity chart (Teams capacity to deliver work sprint after sprint)\n</code></pre>"},{"location":"tech-notes/Azure/Devops-test/readme/#permissions","title":"Permissions","text":"<pre><code>- Project level \n    - Not set = deny\n- Organization lelve\n- Query permission(This can be only added to the shared queries and not to the my queries)\n- Dashboard permission\n</code></pre>"},{"location":"tech-notes/Azure/Devops-test/readme/#ms-teams","title":"MS teams","text":"<pre><code>- MS teams can be linked to azure devops\n- You have to give the permission to use oauth from thired party\n- Azure boards app can be installed in the teams after that (@azure boards link)\n- We can subscribe to the events from the azure boards in teams\n</code></pre>"},{"location":"tech-notes/Azure/Devops-test/readme/#azure-pipelines","title":"Azure pipelines","text":"Pipeline basics  - Pipeline is collection of stages, stages are collection of jobs, jobs are collection of steps. - Each Job runs on one agent. - Approvals can be added to stages for manual intervention. - Deployment in yaml referes to deployment jobs and its action of running a sequencial task for one stage . - Deployment groups are collection of target machines where the application is deployed [Strategies like run once, rolling, and canary can be used for deployment jobs]. - Environments are collection of resources where the application is deployed. - Jobs are collection of steps that run sequentially on the same agent, there can be agentless jobs too. - Release is versioned set of artifacts specified in a pipeline for a deployment to an environment. - Run is a single execution of a pipeline. - Step is a single task that is executed by the agent. - Script is a sequence of commands that are executed by the agent. - Task is a pre-packaged script that performs an action in a pipelines. - Library includes secure files and variable groups. Secure files are a way to store files and share them across pipelines.  Trigger basics  - Triggers can't use variables in triggers. - Cannot specify triggers in the template files. - There are two types of triggers , Build Triggers or CI Triggers and Release Triggers or CD Triggers.   <pre><code>name: my-first-azure-pipeline # Name of the pipeline\n\ntrigger: none # This will not run the pipeline automatically, you have to run it manually.\ntrigger: # This is a CI or Build trigger, This will run when there is a commit to the branch or if you push specified tags.\nbatch: true # This will run the pipeline in sequence if multiple commits are pushed. Address caution when using this, as you wont be able to run t\n    branches:\n        include:\n      - main\n      - feature/* # Wildcard can include * , ** and ? characters * meaning any number of characters and ? meaning any single character, If you start your pattern with * in a YAML pipeline, you must wrap the pattern in quotes, like \"*-releases\" can be used on branches and paths.\n    exclude:\n      - wip/*\n  paths:\n    include:\n      - pipelines/my-first-azure-pipeline*\n    exclude:\n      - README.md\ntags: # This is a tag trigger, This will run when you push a tag that matches the pattern. If you don't specify any tag triggers, then by default, tags will not trigger pipelines.\n    include:\n      - v1.*\n    exclude:\n      - v1.0\n#Pr Triggers\npr:\n branches:\n   include:\n#      - main\n#    exclude:\n#      - wip/*\n#  paths:\n#    include:\n#      - pipelines/my-first-azure-pipeline*\n  #   exclude:\n  #     - README.md\n  # tags:\n  #   include:\n  #     - v1.*\n  #   exclude:\n  #     - v1.0\n\nresources: # This is redundant here as this is the default behaviour\n    - repo: self\n\n</code></pre>   - To skip a pipeline run, you can include the following in the commit message: - [skip ci] or [ci skip] - skip-checks: true or skip-checks:true - [skip azurepipelines] or [azurepipelines skip] - [skip azpipelines] or [azpipelines skip] - [skip azp] or [azp skip] - NO_CI - Adding conditions to the pipelines - condition: and(succeeded(), ne(variables['Build.Reason'], 'PullRequest'))   Agent pool <pre><code>pool: # Define selfhosted pool for the pipeline\n   name: 'selfhosted'\n\npool: # Define Microsoft hosted pool for the pipeline\n    vmImage: 'ubuntu-latest' # you can use 'windows-latest' for Windows and 'macOS-latest' for macOS \n\nstrategy: # Parallel jobs on different OS\n    matrix:\n      linux:\n        imageName: \"ubuntu-latest\"\n     mac:\n        imageName: \"macOS-latest\"\n      windows:\n        imageName: \"windows-latest\"\n    maxParallel: 3\n\npool:\n    vmImage: $(imageName)\nstrategy: # Parallel jobs on different JDK versions\n    matrix:\n      jdk10:\n        jdkVersion: \"1.10\"\n      jdk11:\n        jdkVersion: \"1.11\"\n    maxParallel: 2\n\nstrategy: # Parallel jobs on different OS and JDK versions\n    matrix:\n      jdk10_linux:\n        imageName: \"ubuntu-latest\"\n        jdkVersion: \"1.10\"\n      jdk11_windows:\n        imageName: \"windows-latest\"\n        jdkVersion: \"1.11\"\n    maxParallel: 2\n\n  pool:\n    vmImage: $(imageName)\n  pool:\n   name: 'selfhosted'\n</code></pre> Variables <pre><code>variables:\n  - name: someVariableName\n    value: valueOfTheVariable\n  - name: pathVersion # dont know what is this for\n    value: $[counter(0, 0)]   \n  - template: variables/variables-test.yaml # reference variables from seperate variable file\n</code></pre> Pipeline structure <pre><code>stage level\njob level\n\njobs:\n- job: job1\n   pool:\n     vmImage: 'ubuntu-latest'\n   variables:\n     job_variable1: value1    # Job level variable\n   steps:\n   - bash: echo $(global_variable)\n   - bash: echo $(job_variable1)\n   - bash: echo $JOB_VARIABLE1 \n\n- job: job2\n   pool:\n     vmImage: 'ubuntu-latest'\n   variables:\n     job_variable2: value2    # this is only available in job2\n   steps:\n   - bash: echo $(global_variable)\n   - bash: echo $(job_variable2)\n   - bash: echo $GLOBAL_VARIABLE\n</code></pre> Git checkout  Multi Checkouts in a pipeline ------------------------------ - Use either checkout or uses options to checkout a different repository. If not specified it checks out the current repository.   <pre><code>steps:\n - checkout: git://FabrikamFiber/FabrikamTools # Azure Repos Git repository in the same organization\n - script: # Do something with that repo # Or you can reference it with a uses statement in the job\n uses:\n   repositories: # List of referenced repositories\n   - FabrikamTools # Repository reference to FabrikamTools\n</code></pre> <pre><code>jobs:\n  - job: bicep_build\n    steps:\n      - checkout: self # This step is redundant (pipelines default beheviour in first step)\n        persistCredentials: true\n        clean: true\n        fetchDepth: 0\n</code></pre> Tasks <pre><code>  - task: AzurePowerShell@5\n    name: bicepBuildTrigger\n    env:\n        SYSTEM_ACCESSTOKEN: $(System.AccessToken)\n    inputs:\n        displayName: 'Triggering bicep build for changed files'\n        ScriptType: filePath\n        ScriptPath: $(Build.SourceDirectory)/pipelines/scripts/trigger_pipeline.ps1\n        failOnStderr: true\n        azurePowerShellVersion: \"LatestVersion\"\n        azureSubscription: ${{ variables.azureSubscriptionName}}\n        pwsh: true\n        ScriptArgument: &gt; # Use this to avoid newline characters in multilines string\n            -patchVersion $(patchVersion)\n            -pipelineName \"build-and-publish-module\"\n            -bicepVersionFile \"metadata.json\"\n            -bicepFile \"main.bicep\"\n\n# inline script type\n- task: AzurePowerShell@5\n  inputs:\n    ScriptType: filePath\n    ScriptPath: $(Build.SourcesDirectory)/scripts/myscript.ps1\n    azureSubscription: $(azureSubscriptionName)\n    pwsh: true\n    failOnStderr: true\n\n\n# file type script type\n- task: AzurePowerShell@5\n  inputs:\n    ScriptType: inlineScript\n    ScriptInline: |\n      Write-Host \"Hello, World!\"\n      Get-AzResourceGroup\n    azureSubscription: $(azureSubscriptionName)\n    pwsh: true\n    failOnStderr: true\n</code></pre>"},{"location":"tech-notes/Azure/cdn/readme/","title":"CDN (Front end door)","text":"<ol> <li>This helps deliver content cashed on the location closer to the user(from point of presence location)</li> <li>After creating the CDN endpoint needs to be added and linked to the web app or any other service</li> </ol>"},{"location":"tech-notes/Azure/cli/readme/","title":"Cli","text":"<p>az login az vm list az vm create az vm delete az keyvault list az network vnet list az network vnet subnet list az network vnet subnet create az network vnet subnet delete</p>"},{"location":"tech-notes/Azure/cost-management/readme/","title":"Cost management","text":"<ol> <li>Pricing Calculator -&gt; gives you estimated mounthly cost</li> <li>Total Cost of ownership calculator -&gt; Cost of moving from onprem to cloud</li> <li>Azure const management -&gt; </li> </ol>"},{"location":"tech-notes/Azure/disk/create/","title":"Create Disk","text":""},{"location":"tech-notes/Azure/disk/create/#disk-details","title":"Disk details","text":"<ul> <li>Availability<ul> <li>No infrastructure redundancy required</li> <li>Zone 1, Zone 2, Zone 3</li> </ul> </li> <li>Source type<ul> <li>None</li> <li>Snapshot</li> <li>Storage blob</li> <li>Disk</li> <li>Disk restore point</li> <li>Public image</li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/disk/settings/","title":"Disk settings","text":""},{"location":"tech-notes/Azure/disk/settings/#overview","title":"Overview","text":"<ul> <li>Create snapshot <ul> <li>Disk can be created from the snapshot</li> </ul> </li> <li>Name, region</li> <li>Snaphot type<ul> <li>Incremental(Save on cost by making partial copy, based on difference between the last snapshot)</li> <li>Full (Make complete read only copy of the disk)</li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/disk/settings/#settings","title":"Settings","text":""},{"location":"tech-notes/Azure/disk/settings/#configuration","title":"Configuration","text":"<ul> <li>Enable shared disk<ul> <li>This can be enabled for 2 or 3 vm's</li> <li>when this is enabled , host caching is unavailable, </li> </ul> </li> <li>Enable demand bursting <ul> <li>Only available for more than 512 gb's,</li> <li>This helps burst iops beyond provisioned target up to 30000 iops and 1000 mb's</li> <li>Allow disk to be used for vm hibernation</li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/disk/settings/#size-performance","title":"Size + Performance","text":"<ul> <li>Storage type<ul> <li>Premium SSD</li> <li>Standard SSD</li> <li>Standard HHD</li> <li>Zone redundant storage<ul> <li>Premium SSD</li> <li>Standard SSD</li> </ul> </li> </ul> </li> <li>Disk size</li> <li>Performance tier<ul> <li>IOPS , MB/s</li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/disk/settings/#encryption","title":"Encryption","text":"<ul> <li>Plaform managed keys</li> <li>Customer managed keys</li> <li>Platform managed and customer managed keys</li> </ul>"},{"location":"tech-notes/Azure/disk/settings/#networking","title":"Networking","text":"<ul> <li>Public access from all networks</li> <li>Enable private access<ul> <li>Disk access<ul> <li>Private link</li> </ul> </li> </ul> </li> <li>Display public and private access</li> </ul>"},{"location":"tech-notes/Azure/disk/settings/#disk-export","title":"Disk Export","text":"<ul> <li>Allow data access with Azure AD authentication</li> <li>Generate a secure URL<ul> <li>URl expires in ___ seconds</li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/disk/settings/#properties","title":"Properties","text":"<ul> <li>Resource ID</li> <li>Other details</li> </ul>"},{"location":"tech-notes/Azure/disk/settings/#automation","title":"Automation","text":"<ul> <li>CLI/PS</li> <li>Task</li> <li>Export template</li> </ul>"},{"location":"tech-notes/Azure/entra/readme/","title":"EntraID","text":""},{"location":"tech-notes/Azure/entra/readme/#authentication","title":"Authentication","text":""},{"location":"tech-notes/Azure/entra/readme/#autherization","title":"Autherization","text":""},{"location":"tech-notes/Azure/entra/readme/#subscription-type","title":"Subscription type","text":"<pre><code>- Free\n    - Pim is not free\n    - Self service password is not free\n    - Custom roles creation is not free\n    - MFA through phone and sms is not free\n    - MFA throught authenticator app is free\n    - Conditional access is not free\n- PD1 (Some users are with more features and some are on free tier)\n- PD2 This is for enterprice customers\n- Entra ID governance (Advance)\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#concept-of-account-and-subscriptions","title":"Concept of account and subscriptions","text":"<pre><code>- Account\n    - Person (Email@email.com)\n    - Application (Managed Identity)\n- Tenant (Organization , www.google.com --&gt; Domain)\n    - Entra ID tenant\n    - Azure AD B2C (Uses Thired party logins like linkeding or google )\n        - Global administrator (Organization Owner)\n        - You can switch tenants from the Manage tenants option\n        - You can add custom domain to the the tenant too (In most cases you can just use the one that is provided by MS, I use it like that )\n        - After making the custom domain just make it as a primary domain\n- Subscription (Billing)\n    - Can be moved to a different tenent\n    - Sub Types\n        - Pay as you go\n        - Enterprice\n    - Cost management\n        - Cost analysis(Shows you your spendings)\n        - Cost alert\n            - Create a budget\n            - Create an anomaly(Its not a budget but just an email trigger with anomaly)\n                - This will detect if there are some wired changes to the resources or to the cost (Can get an email daily too)\n        - Budget\n            - Create budget\n        - Azvisor recommendations\n            - Gives advice on your resources\n- Resource Group\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#users","title":"Users","text":"<pre><code>- Users can be created \n- External users can be invited\n- Op prem active directory users can be synced to the Entra ID users too\n- To assign license to users, user location in the user properties tab should be defined(This is because there are location specific constraints for Azure)\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#groups","title":"Groups","text":"<pre><code>- Groups can be created to group users\n- You have to turn on if you want to add roles to the groups directly rather than giving roles to the users\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#dynamic-groups","title":"Dynamic Groups","text":"<pre><code>- This moved users to the specific groups depending upon the filter. \n    - You can created rules like display name contains certain things.(Depending on job titles , Depending on the location)\n- Membership option should be select to Dynamic user instead of assigned user\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#administratior-units","title":"Administratior units","text":"<pre><code>- Give roles to different units in the organization\n- Segrigate your organization in different units\n- You can add users directly to AU\n- You can add groups to the AU too\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#devices","title":"Devices","text":"<pre><code>- Devices can be registered to make sure certain softwares or updates to the devices can be enforced\n- Used for conditional access\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#bulk-operation","title":"Bulk operation","text":"<pre><code>- You can download a csv file and make changes to it and upload the changed file\n- This will make the changed csv data changes to the azure entraID\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#self-password-reset","title":"Self password reset","text":"<pre><code>- This is a premium feature\n- This is by defaut enabled for the administrator\n- If enabled the users can just use forgot password\n- AAD connect can be used to reset password on on prem AD(In this case password is resetted on the cloud and pushed back to the on prem AD)\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#rbac","title":"RBAC","text":"<pre><code>- Least privilege\n    - Example roles\n        - Developer\n        - Development manager\n        - IT operations\n        - Report Reader\n        - Global administrator\n- you can define conditions on assigned role assignments\n    - You can add an action\n    - You can Add expression\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#cbac-claims-based-access-control","title":"CBAC (Claims based access control)","text":"<pre><code>- Eg: createing SAS keys in storage account to gain access to the storage resource\n- You can disable the CBAC roles in the portal\n- You can also enable the RBAC using the active directory or entra ID to the storage accounts and many other resources\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#roles-and-administrator","title":"Roles and administrator","text":"<pre><code>- Here you can assigne administrator level roles to the users\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#entra-id-custom-roles","title":"Entra ID Custom roles","text":"<pre><code>- Entra ID free subscription does not allow custom roles\n- You can create the custom roles to be scope specific\n    - custom role created on a subscrition can be assigned to all the resources inside that subscritption\n    - custom role created on a subscription but towards a resource group socpe , then in that case the role can be assigned to all the resources that are available in that resource and not towards the resource outside the scoped resource groups.\n- You are only allowed to created 5000 custom roles\n- Deny assignments can not be added from the portal\n- DataActions can be used to define what types of action can the user perform\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#role-assignment-custom-role","title":"Role assignment custom role","text":"<pre><code>- You are free to create this custom role , This is different from the custom role in Entra ID\n- Tou are also free to create conditional access in role assignmnet section its different that the conditional access in entraID\n</code></pre> <pre><code>{\n  \"properties\": {\n    \"roleName\": \"Custom Role Example\",\n    \"description\": \"An example custom role for Azure\",\n    \"assignableScopes\": [\n      \"/subscriptions/{subscription-id}\"\n    ],\n    \"permissions\": [\n      {\n        \"actions\": [\n          \"Microsoft.Compute/virtualMachines/start/action\",\n          \"Microsoft.Compute/virtualMachines/deallocate/action\"\n        ],\n        \"notActions\": [],\n        \"dataActions\": [],\n        \"notDataActions\": []\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#interpret-access","title":"Interpret access","text":"<pre><code>- You can go to the resource and look for the role assignment tab to check who has access to that resources\n- Navigate to Entra ID --&gt;&gt; Azure role assignments --&gt;&gt; here you can select the user and check what access does that user have on which resources\n- Keep in mind that there are two roles section in Entra Id\n    - 1. Azure Role Assignments -&gt; This one is for checking who has access to which resources\n    - 2. Assigned Roles -&gt; This is to check who has access to Admin roles (Entra ID specific)\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#deny-assignments","title":"Deny assignments","text":"<pre><code>- There is no concept of Deny assignment in azure\n- The only way to denu assignment is not not give the access.\n</code></pre>"},{"location":"tech-notes/Azure/entra/readme/#windows-vm-role-assignments","title":"Windows VM role assignments","text":"<pre><code>- When create a VM select login with Entra ID.\n- Then user can login with the entra ID credentials.\n- To connect using RDP, RDP file needs to be modified\n    - Add credentials in the file and save it\n        - Allow remote desktop connection from entra from inside the windows VM\n            - User will be able to connect successfully\n</code></pre>"},{"location":"tech-notes/Azure/entraid/readme/","title":"EntraID","text":""},{"location":"tech-notes/Azure/entraid/readme/#iam-service","title":"IAM service","text":"<ol> <li>Detault Directry</li> <li>Primary domain</li> <li>License</li> <li>Users</li> <li>Groups</li> </ol> <p>Authentication  Authorisation</p>"},{"location":"tech-notes/Azure/firewall/readme/","title":"Azure Firewall","text":""},{"location":"tech-notes/Azure/key-vault/readme/","title":"Azure keyVault","text":""},{"location":"tech-notes/Azure/key-vault/readme/#store-secrets","title":"Store secrets","text":""},{"location":"tech-notes/Azure/key-vault/readme/#store-certificates","title":"Store certificates","text":""},{"location":"tech-notes/Azure/logic-app/readme/","title":"Logic app","text":""},{"location":"tech-notes/Azure/logic-app/readme/#create-workflows","title":"Create workflows","text":""},{"location":"tech-notes/Azure/policy/readme/","title":"Azure policies","text":"<pre><code>- Definations (Predefined policies already defined by azrue)\n- Policies in the defination can be assigned to a specific scope\n- You can also exclude certain resources from the policy assignments\n- Policy enforcement\n    - Enabled (This is prevent users from creating the resources)\n    - Disabled (This is not prevent but just inform)\n- We can define what happends when a policy is violated\n- By default the policy only affects the newly created resources\n- User will have to remediate the policies of you want those policies to be applied back again to older resources\n- You can choose to deploy a template depending upon a policy\n- Custom policies can also be defined\n- Policy effect can be deny or audit\n    - Deny  \n        - User will not be able to create the resource\n    - Audit\n        - User will be able to create the resource but it will be reported\n- No allowed resources policy can be used to stop team members to create certain resources\n</code></pre>"},{"location":"tech-notes/Azure/policy/readme/#custom-policies","title":"Custom policies","text":"<pre><code>- Policies are json documents\n</code></pre>"},{"location":"tech-notes/Azure/policy/readme/#tag-policies","title":"Tag policies","text":"<pre><code>- You can have policy for the resources to have certain tags\n</code></pre>"},{"location":"tech-notes/Azure/policy/readme/#resource-move","title":"Resource move","text":"<pre><code>- resources can be moved to other subscription or rg or a region\n- But this will change the resource parameters like resource ID's if you move it to other subscriptions\n</code></pre>"},{"location":"tech-notes/Azure/policy/readme/#policies-scope","title":"Policies scope","text":"<pre><code>- Subscription\n- MG\n- RG\n- Resource level(This is possible using CLI)\n</code></pre>"},{"location":"tech-notes/Azure/powershell/readme/","title":"Powershell","text":"<pre><code>    PSVersionTable.PSVersion #Gives the current version of powershell installed\n    Get-Modules -Name Az -ListAvailable # Get all installed Az modules\n    Get-InstalledModule -Name Az -AllVersions | Select-Object -Property Name,Version | ConvertTo-CSV\n    Install-Module -Name modulename -AllowClobber -Force -Repository PSGallery # Installs the module\n    Update-Module -Name Az -AllowClobber -Force -Repository PSGallery # updates the installed module\n    Connect-AzAccount # Login to azure from powershell terminal\n    Get-AzVM\n    New-AzVM\n    Remove-AzVM\n    Get-AzKeyVault\n    New-AzKeyVault\n    Remove-AzKeyVault\n    Get-AzVirtualNetwork\n    New-AzVirtualNetwork\n    Remove-AzVirtualNetwork\n    Get-AzVirtualNetworkSubnetConfig\n    New-AzVirtualNetworkSubnetConfig\n    Remove-AzVirtualNetworkSubnetConfig\n    Get-AzWebApp\n    Get-AzSubscription\n    Set-AzContext   -Subscription \"SubID\"\n</code></pre>"},{"location":"tech-notes/Azure/powershell1/powershell/","title":"PowerShell","text":"<ul> <li>PS = commandline shell + scripting language</li> <li>PS accepts and returns .Net objects</li> <li>Powershell desired state configuration (DSC) is a management framework in PowerShell that enables you to manage your enterprise infrastructure with configuration as code.</li> <li>cmdlet = powershell command</li> </ul> <pre><code>$PSVersionTable.PSVersion\n$PSVersionTable.PSVersion\nGet-Verb\nGet_Command\nGet-Member \nGet-Help\n</code></pre> <ul> <li>Search Commands</li> </ul> <pre><code>Get-Command -Verb Get -Noun alias* \nGet-Command -Name Get-Process\nGet-Command -Name *-Process\n</code></pre> <ul> <li>Get help</li> </ul> <pre><code>Get-Help -Name Get-Help # Get help\nGet-Help Get-FileHash -Examples\nGet-Help -Name Get-Help -Full\nGet-Process | Get-Member # gets the object types\nhelp -Name Get-Help -Full\nhelp Get-Help -\n</code></pre> <ul> <li>Get-Member</li> </ul> <pre><code>Get-Process tmux | Get-Member\nGet-Process -Name 'name-of-process' | Get-Member | Select-Object Name, MemberType\n</code></pre> <ul> <li>Formatting results</li> </ul> <pre><code>|Format-Table \n|Format-List\n|Format-Wide\n|Format-Custom\n</code></pre> <ul> <li>Operators</li> </ul> <pre><code># Add c for case sensitivity like -ceq for equals to with case sensitivity\n|`-eq`|Equal to|\n|`-ne`|Not equal to|\n|`-gt`|Greater than|\n|`-ge`|Greater than or equal to|\n|`-lt`|Less than|\n|`-le`|Less than or equal to|\n</code></pre> <ul> <li>Complex example</li> </ul> <pre><code>Get-Process | Where-Object CPU -gt 2 | Sort-Object CPU -Descending | Select-Object -First 3\nGet-Process | Select-Object Name | Where-Object Name -eq 'name-of-process'\n</code></pre>"},{"location":"tech-notes/Azure/powershell1/powershell/#powershell_1","title":"Powershell","text":""},{"location":"tech-notes/Azure/powershell1/powershell/#basic-info","title":"Basic info","text":"<ul> <li>Accepts and returns .Net object rather than plain text</li> <li>Commands in pwsh is called cmdlets</li> <li>Follows Verb-Noun naming convention</li> <li>In Get-Help command [Parameter] []<ul> <li>First [] in parameters specify that it can be specified by name and position</li> <li>[] in System.string specificed that it can take array of string</li> </ul>"},{"location":"tech-notes/Azure/powershell1/powershell/#basic-commands","title":"Basic commands","text":"<pre><code>$PSVersionTable.PSVersion ## Shows the version in table format\npwsh -v ## Give full list of verbs available\nGet-Verb ## Gets all the verbs there are \nGet-Command ## Get all the commands available on the system\nGet-Command -Name Get-Process\nGet-Command -Name *-Process\nGet-Command -Verb Get\nGet-Command -Noun U*\nGet-Command -Verb Get -Noun P*\nGet-Command | Select-Object -First 5 -Property Name , Source\nGet-Process | Get-Member -MemberType Method ## Gives the members of the object method . property, script property\nGet-Help ## Self explanatory\n</code></pre>"},{"location":"tech-notes/Azure/powershell1/powershell/#desired-state-configurationdsc","title":"Desired state configuration(DSC)","text":""},{"location":"tech-notes/Azure/powershell1/powershell/#modules","title":"Modules","text":"<ul> <li>Import-Module</li> <li>Remove-Module</li> </ul>"},{"location":"tech-notes/Azure/powershell1/powershell/#books","title":"Books","text":"<ul> <li>PowerShell 101</li> <li>The powershell conference book</li> <li>Powershell deep dives</li> </ul>"},{"location":"tech-notes/Azure/powershell1/powershell/#imp-folks","title":"IMP Folks","text":"<ul> <li>Jeffrey Snover</li> </ul>"},{"location":"tech-notes/Azure/powershell1/powershell/#continue","title":"Continue","text":"<p>https://learn.microsoft.com/en-us/powershell/scripting/learn/ps101/02-help-system?view=powershell-7.4#switch-parameters</p>"},{"location":"tech-notes/Azure/rbac/readme/","title":"Entra ID","text":""},{"location":"tech-notes/Azure/rbac/readme/#microsoft-active-directorythis-is-still-used-in-some-of-the-on-prem-servers","title":"Microsoft active directory(This is still used in some of the on prem servers)","text":""},{"location":"tech-notes/Azure/rbac/readme/#entra-domain-servce-used-to-connect-microsoft-active-directory-hosted-on-azure-to-entra-id","title":"Entra Domain servce - Used to connect Microsoft active directory hosted on azure to Entra ID","text":""},{"location":"tech-notes/Azure/rbac/readme/#entra-cloud-sync-used-to-sync-ms-active-directory-on-prem-to-azure-cloud","title":"Entra cloud Sync - Used to sync MS active directory on prem to azure cloud","text":""},{"location":"tech-notes/Azure/resource-group/readme/","title":"Resource Group","text":"<p>Resource Group Docs</p>"},{"location":"tech-notes/Azure/resource-group/readme/#resource-group-imp-information","title":"Resource group Imp information","text":"<ul> <li>Resource groups store metadata about the resources in the region where the resource group is created.</li> <li>Resource groups should club the resources that share the same lifecycle.</li> <li>Resource groups can contain resources from different regions.</li> </ul>"},{"location":"tech-notes/Azure/resource-group/readme/#resource-group-imp-sh-commands","title":"Resource group Imp sh commands","text":"<pre><code>az group create --name demoResourceGroup --location westus\naz group list\naz group show --name exampleGroup\naz group delete --name exampleGroup\n</code></pre>"},{"location":"tech-notes/Azure/resource-group/readme/#resource-group-imp-powershell-commands","title":"Resource group Imp powershell commands","text":"<pre><code>New-AzResourceGroup -Name demoResourceGroup -Location westus\nGet-AzResourceGroup\nGet-AzResourceGroup -Name exampleGroup\nRemove-AzResourceGroup -Name exampleGroup\n</code></pre>"},{"location":"tech-notes/Azure/resource-group/readme/#bicep","title":"Bicep","text":"<pre><code>az deployment create --name deploymentName --location swedencentral --template-file resourceGroup.bicep --parameters resourceGroupName=nameOftheRG resourceGroupLocation=swedencentral \n</code></pre>"},{"location":"tech-notes/Azure/resource-group/readme/#completed-pages","title":"Completed pages","text":"<ul> <li>[x] Portal</li> <li>[x] Cli</li> <li>[x] Powershell</li> <li>[x] Bicep</li> <li>[ ] Terraform</li> <li>[ ] Python</li> </ul>"},{"location":"tech-notes/Azure/sentinel/readme/","title":"Azure Sentinal","text":"<p>Fetch data from different services</p>"},{"location":"tech-notes/Azure/storage-account/readme/","title":"Storage account (s3)","text":""},{"location":"tech-notes/Azure/storage-account/readme/#storage-account-creation-option","title":"Storage account creation option","text":""},{"location":"tech-notes/Azure/storage-account/readme/#basic-information","title":"Basic Information","text":"<pre><code>- Globally unique storage account name.\n- Region specific\n- Storage account accessibility\n    - Storage explorer, downloadable software for viewing the storage services\n    - Storage browser is another way of viewing your storage services\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/readme/#performance","title":"Performance","text":"<pre><code>- Standard (GPV2) \n    - Storage Types\n        - (All types)\n    - Redundancy \n        - LSR,ZRS,GRS,GZRS\n- Premium (High performance)\n    - Storage Types\n        - Block Blobs (Consistent reads) , Datalake option available\n        - Page Blobs (Random reads), Datalake option not available\n        - File Shares\n    - Redundancy\n        - LZR, ZRS\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/readme/#storage-type","title":"Storage Type","text":"<pre><code>- Containers - ( Blob,unstructured data )\n- File Shares - SMB or NFS (Linux) , Azure file sync is hybrid approach to file share\n    - Types\n        - Transaction optimized, Hot and cold\n    - This does not work from home system as the SMB/445 port is blocked by ISP's\n    - Add directory\n    - Backups (Runs on a schedule, can be done manually too)\n    - Snapshot(point in time version of the file is saved, never expires)\n    ## Azure file sync\n        - Download application on the server \n        - This server syncs files to the file share\n        - Group sync (Which files needs to be synced)\n- Queues - messages can be queued or dequeued\n- Tables (No sql database)\n    - entities \n        - partitionKey = column and rowKey = row\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/readme/#advance-settings","title":"Advance settings","text":"<pre><code>- Require secure transfer for RestAPI\n- Enable anonymous access on individual containers\n- Enable storage account key access, SAS token (shared access signature) to access data, You can too login with this in portal \n- Default to microsoft entra authentication in auzre portal\n- Mininum TLS version\n- Datalake\n    - used for big data, can store more that 5 petabytes, hadoop of synaps\n- Enable large file share(Initial capacity = 100 TB, select this to get more storage)\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/readme/#azure-migrate","title":"Azure migrate","text":"<pre><code>- Discovery (Examins your achitecture and gives a suggestion on migration)\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/readme/#storage-account-level-settings","title":"Storage account level settings","text":""},{"location":"tech-notes/Azure/storage-account/readme/#data-management","title":"Data management","text":"<pre><code>- Lifecycle management\n    - Add rules with conditions\n        - Hot(default)\n        - Cool (Cheaper storage with more expensive read writes) , stored for minimum 30 days\n        - cold (much cheaper storage with more expensive reads and wirtes), stored for minimum of 90 days\n        - Archive (offline storage,Cheapest but most expensice reads and writes), stored for minimum of 120 day\n            - To access files from the archive tier , files needs to be rehydrated first.\n            - You have to set the access tier to archive on file to file basis\n        - Premium storage account\n            - no access tiers\n            - no lifecycle management\n- Data protection\n    - Enable azure backups for blobs\n    - Enable point in time restore\n    - Enable soft delete or blobs/containers\n    - Enable permanent delete for soft deleted items\n    - Enable versioning\n    - Enable blob change feed (Keep track of create, modification and delete change to blobs)\n        - Immutablitiy (In this file will not be deleted ever)\n- Object replication (Versioning needs to be enabled for this)\n    - Create replication rules to replicate objects to destination account\n    - Failover(Click this button to make secondary region primary)\n- Object replication\n    - Create replication\n        - Source account --&gt;&gt; destination account(Read only)\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/readme/#redundancy-data-does-not-leave-the-region","title":"Redundancy (data does not leave the region)","text":"<pre><code>- LSR - default, 3 Copies in same datacenter (11 9's))\n- ZRS - 3 copies in different AZ\n- GRS - Extra three copies are added to another region (3 + 3)\n- GZRS - Extra one LRS is added to another region\n- RA GRS - Read only GRS\n- RA GZRS - read only GZRS\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/readme/#security-and-networking","title":"Security and Networking","text":"<pre><code>- Networking\n    - Firewall and virtual networks\n        - Public, specific IP , Disable \n    - Private endpoint connections\n        - Private links \n    - Custom domains\n- Network routing\n    - Microsoft network routing (This tries to be on MS backnbone)\n    - Internet Routing (This doesnt)\n- Access Keys (This gives access to the entire storage account)\n    - You get two keys\n        - Key\n        - Connection string(This can be used to connect programatically)\n - SAS (Shared access signature) - Access with more conditions\n    - Can be created on different levels\n    - You can limit more things like the time , type of access etc\n    - Can access a single file via browser\n    - Can access entire container\n- Encription\n    - Data encrypted by default\n    - MMK (Micrososft managed keys)\n    - CMK (Customer managed keys)\n        when its created you have to decide if this needs to be appled on only blobs or all storage types(Cant be changed afterwords)\n        - Encription scope\n            - can encript a data over a scope\n    - Enable infrastructure encryption\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/readme/#settings","title":"Settings","text":"<pre><code>- Configuration\n    - Allow blog anonymous access(This give access to the files without SAS token)\n    - Access Tier\n        - Hot ,cool, Other options are available on specific files\n- Endpoints\n    - All the links to the storage types\n    - You get extra read endpoints in case if GZRS\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/readme/#monitoring","title":"Monitoring","text":"<pre><code>- insights\n- Alerts\n- Metrics(compute unit level metrics)\n- Workbooks (Queries)\n- Diagonastics settings\n    - this needs to be turned on\n    - Can send to log analythics workspace, storage account or stream to event hub\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/container/readme/","title":"Container settings","text":""},{"location":"tech-notes/Azure/storage-account/container/readme/#settings","title":"Settings","text":"<pre><code>- SAS token\n- Access policy (Can be created on the file level only)\n    - Create a a policy and attach it to the SAS token\n        - If the policy is deleted the access will be revoked(Dont need to remove the SAS token)\n    - Immutable blob storage\n        - Create policy to get read access to the data\n            - policy make sure that the specified data does not get deleted in that specified time frame\n        - Time based retention policy\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/container/readme/#change-access-tier","title":"Change access tier","text":"<pre><code>    - Hot,Cool,cold,Archive\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/container/readme/#blob-level-setting","title":"Blob level setting","text":"<pre><code>- Snapshots\n    - take snapshot of a single blob\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/file-share/readme/","title":"File Share","text":"<pre><code>- upload files\n- File shared can be connected to the VM (on 445 SMB)\n- Add directory\n- soft delete\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/file-share/readme/#operations","title":"Operations","text":"<pre><code>- Snapshot (Create snapshot)\n- Backups\n</code></pre>"},{"location":"tech-notes/Azure/storage-account/import-export-job/readme/","title":"Import export job","text":"<pre><code>- Dose not work for normal agreements\n- Azure databox (AWS snowball)*\n    - Databox (100 tB)\n    - Databox Disk (8 tb)\n    - Databox Heavy (1 PB)\n- Disk Drive \n    - Provide your own disk\n    - Creates a .jr file\n- Az copy (One container to another) , does not triverse over the internet\n    - Authentication\n        - SAS token\n        - Azure AD\n</code></pre>"},{"location":"tech-notes/Azure/traffic-manager/readme/","title":"Traffic manager (Loadbalancer)","text":"<pre><code>- DNS based loadbalancer accross azure endpoints\n- Rounting methods\n    - Priority routing method\n        - Routing done if the appliaction goes down on any of the nodes\n    - Weighter routing method\n        - Routing done on the basis of define weight/percentage\n- Endpoints needs to be created for loadbalancing\n</code></pre>"},{"location":"tech-notes/Azure/virtual-machines/create/","title":"Create virtual machine","text":""},{"location":"tech-notes/Azure/virtual-machines/create/#basic","title":"Basic","text":"<ul> <li>Availability options<ul> <li>No infrastructure redundancy</li> <li>Availability zones (self selected , azure selected)</li> <li>VM scale sets (Comes with a load balancer)<ul> <li>Create new scale sets<ul> <li>Select availability zones</li> <li>Orchestration<ul> <li>Scale set model (mode)<ul> <li>Flexible (Mix with linux and windows systems with spot with some spot instances)</li> <li>Uniform</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>Availability sets (does not come with load balancer)<ul> <li>more that two vm's</li> <li>Fault domains (Based on power source and network switch)<ul> <li>2 machines with 2 fault domains will create 1 each vm's in seperate power supplys)</li> <li>4 machines with 2 fault domains will create 2 vm's each in seperate power supplys)</li> </ul> </li> <li>Update domain (This for maintenance activity, up to 20 servers allowed)<ul> <li>4 vm's and 5 update domains then only one vm will be updated for planned maintenance at a time.</li> <li>20 machines a 5 update domains then 5 vm's will be updated for planned maintenance at a time. </li> </ul> </li> </ul> </li> </ul> </li> <li>Security type</li> <li>Image<ul> <li>Ubuntu</li> <li>Windows</li> </ul> </li> <li>VM architecture<ul> <li>Arm 64</li> <li>x64</li> </ul> </li> <li>Run with spot instances</li> <li>Size</li> <li>Enable hibernation</li> <li>Administrator account<ul> <li>Username</li> <li>password<ul> <li>SSH public key</li> <li>Password</li> </ul> </li> </ul> </li> <li>Public inbound port<ul> <li>None</li> <li>Allow selected ports<ul> <li>Http, Https, Ssh, Rdp</li> </ul> </li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#disk","title":"Disk","text":"<ul> <li>Encryption at host</li> <li>Os disk (Temporary storage)<ul> <li>Disk size</li> <li>Disk type<ul> <li>Premium SSD</li> <li>Standard SSD</li> <li>Standard HDD</li> <li>Zone redundant storage(data replicated in three zones)<ul> <li>Premium SSD</li> <li>Standard SSD</li> </ul> </li> </ul> </li> <li>Delete with VM</li> <li>Key management<ul> <li>Platform managed keys</li> <li>Customer managed keys</li> <li>Platform managed and customer managed keys</li> </ul> </li> <li>Enable Ultra Disk compatibility (More faster than premium ssd)</li> </ul> </li> <li>Temporary disk</li> <li>Data disks for vm's<ul> <li>Add extra data disk (This can be detached and reattached to another vm)</li> <li>This cant be attached to two different VM's at the same time (Use file shares to do that</li> </ul> </li> <li>Advanced<ul> <li>Use managed disks</li> <li>Ephemeral os disk<ul> <li>none</li> <li>os cache placement</li> <li>test disk placement</li> </ul> </li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#networking","title":"Networking","text":"<ul> <li>Vnet <ul> <li>every vm should be linked to a Vnet</li> <li>Vnet should be in the same region as the vm</li> </ul> </li> <li>Subnet</li> <li>Public ip (with this the vm can be accessed from the internet)</li> <li>Network security group(controls the access to the subnet)<ul> <li>Public inbound ports<ul> <li>None</li> <li>Allow selected ports</li> <li>Http, Https, Ssh, Rdp</li> </ul> </li> </ul> </li> <li>Delete NIC and public Ip when vm is deleted</li> <li>Enable accelerated netorking (high speed network between the vm's)</li> <li>Loadbalancing<ul> <li>None</li> <li>Azure loadbalancer</li> <li>Application gateway</li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#managemnent","title":"Managemnent","text":"<ul> <li>Defender for cloud</li> <li>Identity (managed identity)</li> <li>Azure AD login</li> <li>Auto shutdown</li> <li>Enable backups<ul> <li>Disaster recovery</li> </ul> </li> <li>Os updates</li> <li>Hot patching</li> <li>Rebooting</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#monitoring","title":"Monitoring","text":"<ul> <li>Alerts (Cost involved)</li> <li>Boot diagonastcs</li> <li>Health monitoring</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#advance","title":"Advance","text":"<ul> <li>Extention<ul> <li>Install custom extentions</li> </ul> </li> <li>Vm applications<ul> <li>Install custom applications</li> </ul> </li> <li>Custom data<ul> <li>Init script</li> <li>Custom data</li> </ul> </li> <li>User data<ul> <li>Pass a script or a configuration file</li> </ul> </li> <li>Performance nvme</li> <li>Dedicated host<ul> <li>Host group</li> <li>Capacity reservation group</li> <li>Proximity placemanent group (Shortest distance between the vm's)</li> </ul> </li> </ul> <p>------------------ Stuff below was from az 900</p>"},{"location":"tech-notes/Azure/virtual-machines/create/#ip-address","title":"IP address","text":"<ul> <li>public IP address is not free , every public IP address has a cost attached to it.</li> <li>Dynamic Public IP address </li> <li>Static Public IP address</li> <li>Private IP address</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#dedicated-host-virtual-machines","title":"Dedicated host virtual machines","text":"<ul> <li>Create dedicated host from marketplace</li> <li>Then create virtual machines inside that dedicated host</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#azure-spot-instances","title":"Azure Spot instances","text":"<ul> <li>The vm's can be stopped any time </li> <li>Should be used for workloads which can handle vm's stopping , reserved for 1 or 3 years</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#reserved-instance","title":"Reserved instance","text":"<ul> <li>You can reserve capacity in bulk for longer periods of time which can then cost you less </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#azure-monitoring","title":"Azure monitoring","text":"<ul> <li>This helps monitor the logs and other metrics of the virtual machine</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#vm-scale-setsvmss","title":"VM Scale sets(VMSS)","text":"<ul> <li>Scaling based on conditions</li> <li>up to 100 VMs in single scale sets can be increased that to 1000</li> <li>It creates a loadbalancer by default(Should be explicitly deleted)</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#availability-sets","title":"Availability sets","text":"<ul> <li>load balancing between two servers</li> <li>Fault domains (machines running on different rack)</li> <li>Update domains (used for updateing the applications)</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#proximity-group","title":"Proximity group","text":"<ul> <li>Having multiple machines close to each other</li> <li>Faster inter communication due to being very close to each other </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#imp-points","title":"Imp points","text":"<ul> <li>RDP - port 3389 windows machine </li> <li>SSH - port 22 Linux machine </li> <li>Vent ( free of cost, only traffic going out of the Avnet is charged)</li> <li>Cloud init will run the script at startup</li> <li>NSG ( behaves like a small firewall ), no charges</li> <li>Inbound and outbound rules can be added</li> <li>Disk , charged </li> <li>Public Ip , charged - traffic from public Internet </li> <li>Static assignment ( ip address does not change on restart )</li> <li>Dynamic assignment ( ip address changes on restart )</li> <li>Nic ( network interface )</li> <li>One vm should be connected to at least one subnet using NIC(ACL using nsg).</li> <li>Can be assigned to more that one private IP address if there are more than one subnet linked to the VM.</li> <li>Each VM can be assigned one public IP address so that It can be accessed from the internet.</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#vm-sizes","title":"VM sizes","text":"<ul> <li>Bs ( low cost )</li> <li>D general purpose </li> <li>F more compute power </li> <li>M more memory </li> <li>N more gpu power</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#availability-chart","title":"Availability chart","text":"<ul> <li>Single instance premium ssd or ultra disk 99.9 </li> <li>Single instance standard ssd 99.5</li> <li>Single instanceHdd 95</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#availability-sets-logical-grouping-to-increase-availability-9995","title":"Availability sets ( logical grouping to increase availability) 99.95","text":"<ul> <li>Fault domain ( grouping on different power source )</li> <li>Update domain ( grouping on the base of updates ) </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#availablity-zones-9999","title":"Availablity zones 99.99","text":"<ul> <li>Scale set ( create multiple vms ) </li> <li>Add optional lb</li> <li>Multiple availablity zones </li> <li>Scaling </li> <li>Manual scaling </li> <li>Rule based scaling </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/create/#pricing","title":"Pricing:","text":"<ul> <li>Dedicated host </li> <li>Azure spot instance ( unused capacity ,azure can decide to take it back ) </li> <li>Azure reservations ( pay for long term at discount ) </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/powershell/","title":"Powershell vm commands","text":"<pre><code>- Connect-AzAccount (Login to azure)\n- Get-AzContext (Get the az account context)\n- New-AzResourceGroup -Name myrg - Location yourlocation\n- New-AzVM -Name testVM -Location yourlocation\n- Invoke-AzVMRunCommand -ResourceGroupName 'name' -VMName 'vmname' -CommandId 'RunPowerShellScript' - ScriptionString 'Install-WindowsFeature'\n- Stop-AzVm -ResourceGroupName \"Rgname\" -Name \"VmName\"\n- Start-AzVm -ResourceGroupName \"Rgname\" -Name \"VmName\"\n- Remove-AzVm \"\"\n- Remove-AzResourceGroup -Name \"My-Rg\"\n</code></pre>"},{"location":"tech-notes/Azure/virtual-machines/settings/","title":"Virtual machine settings","text":""},{"location":"tech-notes/Azure/virtual-machines/settings/#connect","title":"Connect","text":"<ul> <li>Connect<ul> <li>rdp on windows machine(port 3389)</li> <li>ssh on linux based machine(port 443)</li> </ul> </li> <li>Bastion<ul> <li>Deploy baston</li> <li>Bastion needs to be in the same region</li> <li>Bastion needs to be attached to the same vnet</li> <li>Tier<ul> <li>Basic</li> <li>Standard(Sharable link)</li> </ul> </li> <li>Need a new subnet for the bastion, needs /26 </li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/settings/#networking","title":"Networking","text":"<ul> <li>Network settings<ul> <li>Attach network interface, nsg configuratio</li> </ul> </li> <li>Load balancing</li> <li>Application security<ul> <li>Attach application security group</li> </ul> </li> <li>Network manager<ul> <li>Create network manager</li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/settings/#settings","title":"Settings","text":"<ul> <li>Disks<ul> <li>Os disks<ul> <li>Swap os disks<ul> <li>Host caching</li> </ul> </li> </ul> </li> <li>Data disks<ul> <li>Create and attach a new data disks.</li> <li>Storage type</li> <li>Size (4,8,16,32,64,124,256)</li> <li>Encription</li> </ul> </li> </ul> </li> <li>Extentions + applications<ul> <li>Extentions</li> <li>Vm applications</li> </ul> </li> <li>Operating system (only user data can be updated here)<ul> <li>Operating system (cant be updated)</li> <li>SKU (cant be updated)</li> <li>Computer name (cant be updated)</li> <li>Username (cant be updated)</li> <li>Password (cant be updated)</li> <li>User data</li> </ul> </li> <li>Configuration<ul> <li>Proximity placement group</li> <li>Host</li> <li>Security type<ul> <li>Standard</li> <li>Trusted launch virtual machine</li> <li>Confidential virtual machine</li> </ul> </li> <li>Performance nvme</li> <li>Capacity reservation<ul> <li>Capacity reservation group</li> </ul> </li> <li>Advisor recommendations</li> <li>Properties<ul> <li>Change subscriptions</li> <li>Other none changable properties</li> </ul> </li> <li>Locks</li> </ul> </li> <li>Availability + scale<ul> <li>Size (select the vm size, vm will restart if its already running)<ul> <li>D series --&gt; General purpose</li> <li>E series --&gt; High memory</li> <li>B series --&gt; Burstable(Variable cpu performance) </li> <li>F series --&gt; High GPU</li> </ul> </li> <li>Availability + scaling<ul> <li>Availability zones, choose upto three availability zones in a region (Three az's meaning two extra vm cost)</li> <li>Scaling (select -&gt; vmss)</li> <li>Availability set -&gt; make vm part of availablity set</li> </ul> </li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/settings/#security","title":"Security","text":"<ul> <li>Identity<ul> <li>System assigned</li> <li>User assigned</li> </ul> </li> <li>Ms defender for cloud</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/settings/#backup-disaster-recovery","title":"Backup + disaster recovery","text":"<ul> <li>Backup</li> <li>Disaster recovery</li> <li>Restore point</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/settings/#operations","title":"Operations","text":"<ul> <li>Autoshut down<ul> <li>Switch on/off</li> <li>Schedule</li> <li>Notification</li> </ul> </li> <li>Run command (run commands in the vm)</li> <li>Updates (Os updates, schedule updates)</li> <li>Health monitoring (enable)</li> <li>Configuration management (Initiative, definations)</li> <li>Policies</li> <li>Inventory</li> <li>Change tracking</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/settings/#monitoring","title":"Monitoring","text":"<ul> <li>Insights</li> <li>Alerts</li> <li>Metrics</li> <li>Diagnostics settings</li> <li>Logs</li> <li>Workbooks</li> </ul>"},{"location":"tech-notes/Azure/virtual-machines/settings/#automation","title":"Automation","text":"<ul> <li>Task</li> <li>Export templetes</li> </ul>"},{"location":"tech-notes/Azure/vmss/create/","title":"Create VMSS","text":""},{"location":"tech-notes/Azure/vmss/create/#basic","title":"Basic","text":"<pre><code>- Region\n- Az's\n- Orchestration\n    - Uniform\n    - FLexible\n- Security type\n- Scaling mode\n    - Manually update the capacity\n    - Auto scaling based on cpu metrics\n    - No scaling profile\n- Instance count\n- Instance details, architecture, size, username, password\n</code></pre>"},{"location":"tech-notes/Azure/vmss/create/#spot","title":"Spot","text":"<pre><code>- Turn on spot vm's only\n- Eviction type\n- Max price you want to pay per hour\n- Eviction policy\n- Scale with vm's and discounted spot vm's\n- Base vm price \n- Instance distribution\n</code></pre>"},{"location":"tech-notes/Azure/vmss/create/#network","title":"Network","text":"<pre><code>- Lb\n    - None\n    - Loadbalancer\n    - Application gateway\n</code></pre>"},{"location":"tech-notes/Azure/vmss/create/#scaling","title":"Scaling","text":"<pre><code>- Manual\n- Autoscaling(With the conditions)\n</code></pre>"},{"location":"tech-notes/Azure/vmss/create/#networking","title":"Networking","text":""},{"location":"tech-notes/Azure/vmss/create/#management","title":"Management","text":""},{"location":"tech-notes/Azure/vmss/create/#health","title":"Health","text":""},{"location":"tech-notes/Azure/vmss/create/#advance","title":"Advance","text":""},{"location":"tech-notes/Azure/vmss/create/#tags","title":"Tags","text":""},{"location":"tech-notes/Azure/vmss/create/#enable-scaling-beyond-100-instances","title":"Enable scaling beyond 100 instances","text":""},{"location":"tech-notes/Azure/vmss/create/#spreading-algorithm","title":"Spreading algorithm","text":"<pre><code>- Max spreading\n- Fixed spreading\n</code></pre>"},{"location":"tech-notes/Azure/vmss/create/#custom-data","title":"Custom data","text":""},{"location":"tech-notes/Azure/vnet/readme/","title":"Vnet Docs","text":""},{"location":"tech-notes/Azure/vnet/readme/#completed-pages","title":"Completed pages","text":"<ul> <li>[x] Virtual Network Documentation</li> <li>[x] About Virtual Network</li> <li>Qickstart     [x] Create Virtual network - Portal     [x] Create Virtual network - powershell     [x] Create Virtual network - Azure CLI     [x] Create Virtual network - Bicep</li> </ul>"},{"location":"tech-notes/Azure/vnet/readme/#todo","title":"Todo","text":"<ul> <li>[ ] Vnet Training</li> </ul>"},{"location":"tech-notes/Azure/vnet/readme/#vnet-basics","title":"Vnet Basics","text":"<ul> <li> <p>Communication of Azure resources with the internet.</p> <ul> <li>public outbound communication is allowed by default</li> <li>Manage public outbound connections using<ul> <li>public ip address</li> <li>Nat gateway</li> <li>public loadbalancer</li> </ul> </li> <li>Manage inbound connections using<ul> <li>public ip address</li> <li>public loadbalancer</li> </ul> </li> <li>Assigning internal standard loadbalancer will not provide outboud ability to the vnet</li> </ul> </li> <li> <p>Communication between Azure resources.</p> <ul> <li>Virtual network service point<ul> <li>Direct connection to the serverless resources from vnet private endpoint via azure backbone network</li> </ul> </li> <li>Private link<ul> <li>This brings the virtual public service virtualling inside the vnet </li> </ul> </li> <li>Vnet peering<ul> <li>Connectes two vnets(even from different region)</li> </ul> </li> </ul> </li> <li> <p>Communication with on-premises resources.</p> <ul> <li>Point to site VPN<ul> <li>Connection between Vnet and a single computer</li> <li>Connection is done using an encrypted tunner over the internet</li> </ul> </li> <li>Site to site VPN<ul> <li>Connection between Onprem VPN device and VPN gateway in azure network</li> <li>Connection is done using an encrypted tunner over the internet</li> </ul> </li> <li>Azure express route<ul> <li>Onprem to Azure vpn connection using dedicated channel</li> <li>Connection does not route via the internet</li> </ul> </li> </ul> </li> <li> <p>Filtering of network traffic between subnets</p> <ul> <li>Network security groups and application security groups</li> <li>Network virtual appliances<ul> <li>NVA is a VM that performs a Network function(Like firewall or WAN)</li> </ul> </li> </ul> </li> <li> <p>Routing of network traffic.</p> <ul> <li>Routing be done by default, Default rules can be overridden by using below<ul> <li>Rote table, Custom route tables can be created</li> <li>Border gateway protocol (BGP) - Need more understanding</li> </ul> </li> </ul> </li> <li> <p>Integration with Azure services.(Accessing resources privately)</p> <ul> <li>Deploy dedicated instances of the service</li> <li>Azure private link(This is over the auzre backbone network)</li> <li>Service endpoints(This is over public endpoints)</li> </ul> </li> </ul>"},{"location":"tech-notes/Azure/vnet/readme/#imp-points","title":"Imp points","text":"<ul> <li>When moving VM from one vnet to another, VM needs to be deleted and created again in the new vnet</li> <li>There are limits to how many resources can be deployed to the VPN</li> <li>Virtual networks and subnets span all availability zones in a region</li> <li>There is no charge for using the VNET</li> </ul>"}]}